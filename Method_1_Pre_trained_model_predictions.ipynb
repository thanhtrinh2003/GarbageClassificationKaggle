{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Method 1: Pre-trained model predictions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhtrinh2003/GarbageClassificationKaggle/blob/main/Method_1_Pre_trained_model_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIslDXQXgtRx"
      },
      "source": [
        "# Import important libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqDGZIx7GaF5"
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn import model_selection\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeRUSBW7gsjx"
      },
      "source": [
        "#Import and preprocess the datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLnOcctei9u6"
      },
      "source": [
        "The dataset is from Kaggle and can be found in the link: https://www.kaggle.com/asdasdasasdas/garbage-classification \n",
        "\n",
        "In this notebook, I have already downdloaded the datasets and uploaded on my google drive. First, lets run the code below to mount the drive order to gain access to the datasets stored in Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y2Zoe94ivRw",
        "outputId": "7d29537c-299d-4476-868c-6fded22ddb5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrv1N5RVjCB6"
      },
      "source": [
        "After finishing mounting the drives, we will turn our sets of images into a list of arrays [resized_array, class_num] stored in `data`\n",
        "\n",
        "## Class index\n",
        "1. cardboard: 0 (contains 403 images)\n",
        "2. glass: 1 (contains 501 images)\n",
        "3. plastic: 2 (contains 482 images)\n",
        "4. paper: 3 (contains 594 images)\n",
        "5. metal: 4 (contains 410 images)\n",
        "6. trash: 5 (contains 137 images)\n",
        "\n",
        "All of our images will be included in `data` with its class number indicated above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99nC614zV2bY",
        "outputId": "a892d98a-92a8-407e-f694-3464f42e1847"
      },
      "source": [
        "labels = ['cardboard', 'glass','plastic','paper','metal','trash']\n",
        "img_size = 224\n",
        "data_dir ='/content/drive/MyDrive/Lumiere 2021/Code/Garbage classification/'\n",
        "data = []\n",
        "\n",
        "nb = {'cardboard':404, 'glass': 502, 'plastic': 483 , 'paper': 595 , 'metal': 411, 'trash':138}\n",
        "\n",
        "for label in labels:\n",
        "  path = data_dir + label + \"/\" +label\n",
        "  class_num = labels.index(label)\n",
        "  for i in tqdm(range(1,nb[label])):\n",
        "    img_arr = cv.imread(path+str(i)+\".jpg\")[...,::-1]\n",
        "    resized_arr = cv.resize(img_arr, (img_size, img_size))\n",
        "    data.append([resized_arr, class_num])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 403/403 [02:04<00:00,  3.25it/s]\n",
            "100%|██████████| 501/501 [02:23<00:00,  3.48it/s]\n",
            "100%|██████████| 482/482 [02:14<00:00,  3.57it/s]\n",
            "100%|██████████| 594/594 [02:48<00:00,  3.53it/s]\n",
            "100%|██████████| 410/410 [01:57<00:00,  3.49it/s]\n",
            "100%|██████████| 137/137 [00:40<00:00,  3.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt6k5yOtj9ky"
      },
      "source": [
        "## Divide `data` into  training, validation, and test datas \n",
        "\n",
        "- 15% of the total datasets will be our testing datas\n",
        "- 85% of the total datasets will be our training and validations ones\n",
        "  -  15% of these images will be our validations datas\n",
        "  -  The rest will be training datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeY_B4mGWF_g"
      },
      "source": [
        "train, test = model_selection.train_test_split(data, test_size = 0.15)\n",
        "train, val = model_selection.train_test_split(train, test_size = 0.15/0.85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIYA9jMYvkew"
      },
      "source": [
        "Next, we will seperated the data into x and y parts for the convenient for training datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2US-VL8ivitU"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "# x_train = []\n",
        "# y_train = []\n",
        "# x_val = []\n",
        "# y_val = []\n",
        "# x_test = []\n",
        "# y_test = []\n",
        "\n",
        "for feature, label in data:\n",
        "  x.append(feature)\n",
        "  y.append(label)\n",
        "\n",
        "# for feature, label in train:\n",
        "#   x_train.append(feature)\n",
        "#   y_train.append(label)\n",
        "\n",
        "# for feature, label in val:\n",
        "#   x_val.append(feature)\n",
        "#   y_val.append(label)\n",
        "\n",
        "# for feature, label in test:\n",
        "#   x_test.append(feature)\n",
        "#   y_test.append(label)\n",
        "\n",
        "# Normalize the data\n",
        "# x = np.array(x) / 255\n",
        "# x_train = np.array(x_train) / 255\n",
        "# x_val = np.array(x_val) / 255\n",
        "# x_test = np.array(x_test) / 255\n",
        "\n",
        "x = np.array(x) \n",
        "x.reshape(-1, img_size, img_size, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "# x_train.reshape(-1, img_size, img_size, 1)\n",
        "# y_train = np.array(y_train)\n",
        "\n",
        "# x_val.reshape(-1, img_size, img_size, 1)\n",
        "# y_val = np.array(y_val)\n",
        "\n",
        "# x_test.reshape(-1, img_size, img_size, 1)\n",
        "# y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG5FLJ5DmCqm"
      },
      "source": [
        "#Predict with Pretrained ResNet50 models from Keras\n",
        "\n",
        "First, we will try to predict the garbage class based on the pretrained ResNet50 using ImageNet labels\n",
        "\n",
        "We will try to connect the labels of ImageNet to match our 6 labels. Initially, we will expect the following:\n",
        "1. cardboard = carton \n",
        "2. glass = wine_bottle, bear_glasses\n",
        "3. plastic = water_bottle\n",
        "4. paper = binder, book_jacket, comic_book, envelope, notebook, menu, paper_towel\n",
        "5. metal = trash_can \n",
        "6. trash = ?\n",
        "\n",
        "In order to have better matching, we will apply ResNet50 model to our datasets and record all the predicted labels. We will look over the labels and added more ImageNet labels to the Kaggle one. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVrShtY_nwaV"
      },
      "source": [
        "## Import ResNet Model\n",
        "\n",
        "From Keras libraries, we will initallize a model with the trained weights from ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYNwFOHxVvST",
        "outputId": "4f022641-ab87-4c41-9d6c-46278a0624c6"
      },
      "source": [
        "model = ResNet50(weights = 'imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laYyT-Vhw-hT"
      },
      "source": [
        "## Analyzing the ImageNet label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDB2etQgeOP_"
      },
      "source": [
        "After careful choosing, we decide the correct ImageNet label for the Kaggle:\n",
        "- cardboard: carton\n",
        "- glass: beer_bottle, beer_glass, (binoculars), pop_bottle, red_wine, (spot_light), syringe, water_jug, wine_bottle, Petri_dish, (hourglass), perfume,  \n",
        "- plastic: water_bottle, plastic_bag, Petri_dish, bottle_cap(maybe metal), nipple, (syringe),  \n",
        "- paper: paper_towel, menu , envelope, comic_book, book_jacket, packet, paper_towel, toilet_tissue, \n",
        "- metal: bottlecap, combination_lock, Crock_Pot, (accordion), (bolo_tie), can_opener, corkscrew, (drum), (fountain_pen), hook, shield\n",
        "- trash: trash will be the left.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kurhb-yyiK20"
      },
      "source": [
        "cardboard_list = {'carton'}\n",
        "\n",
        "glass_list = {'beer_bottle', 'beer_glass', 'pop_bottle', 'red_wine', 'syringe', 'water_jug', 'wine_bottle', 'Petri_dish', 'hourglass', 'perfume'}\n",
        "\n",
        "plastic_list = {'water_bottle', 'plastic_bag', 'Petri_dish', 'bottle_cap', 'nipple', 'syringe'}\n",
        "\n",
        "paper_list = {\"paper_towel\", \"menu\", \"envelope\", \"comic_book\", \"book_jacket\", \"packet\", \"paper_towel\", \"toilet_tissue\"}\n",
        "\n",
        "metal_list = {'bottlecap', 'combination_lock', 'Crock_Pot', 'can_opener', 'cockscrew', 'hook', 'shield'}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIQegZBdiApb"
      },
      "source": [
        "Now we have chosen the correct ImageNet label for our Kaggle labels. We will try to access the accuracy of Resnet50 based on Kaggle classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UuRVKHmVkeR"
      },
      "source": [
        "## Accuracy using Pretrained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grF0cPGQT2Ob",
        "outputId": "43e73f4c-b9c9-4f1c-a24a-5f37e4ce3cba"
      },
      "source": [
        "current = np.expand_dims(x[i], axis=0)\n",
        "current = preprocess_input(current) \n",
        "preds = model.predict(current)\n",
        "top1 = decode_predictions(preds, top=5)\n",
        "print(top1[0][1][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "studio_couch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tvHLQU2Y0Ob"
      },
      "source": [
        "cardboard_correct = 0\n",
        "glass_correct = 0\n",
        "paper_correct = 0\n",
        "plastic_correct = 0\n",
        "metal_correct = 0\n",
        "trash_correct = 0\n",
        "cardboard_correct_5 = 0\n",
        "glass_correct_5 = 0\n",
        "paper_correct_5 = 0\n",
        "plastic_correct_5 = 0\n",
        "metal_correct_5 = 0\n",
        "trash_correct_5 = 0\n",
        "\n",
        "\n",
        "\n",
        "for i in range(x.shape[0]):\n",
        "  current = np.expand_dims(x[i], axis=0)\n",
        "  current = preprocess_input(current) \n",
        "  preds = model.predict(current)\n",
        "  top5 = decode_predictions(preds, top=5)\n",
        "  label = top5[0][0][1]\n",
        "  #cardboard \n",
        "  if y[i] == 0:\n",
        "    if label in cardboard_list:\n",
        "      cardboard_correct = cardboard_correct +1\n",
        "    for i in range(5):\n",
        "      if top5[0][i][1] in cardboard_list:\n",
        "        cardboard_correct_5 = cardboard_correct_5 +1\n",
        "        break;\n",
        "\n",
        "  #glass\n",
        "  if y[i] == 1:\n",
        "    if label in glass_list:\n",
        "      glass_correct = glass_correct +1\n",
        "    for i in range(5):\n",
        "      if top5[0][i][1] in glass_list:\n",
        "        glass_correct_5 = glass_correct_5 +1\n",
        "        break;\n",
        "\n",
        "  #paper\n",
        "  if y[i] == 2:\n",
        "    if label in paper_list:\n",
        "      paper_correct = paper_correct +1\n",
        "    for i in range(5):\n",
        "      if top5[0][i][1] in paper_list:\n",
        "        paper_correct_5 = paper_correct_5 +1\n",
        "        break;\n",
        "\n",
        "  #plastic\n",
        "  if y[i] == 3:\n",
        "    if label in plastic_list:\n",
        "      plastic_correct = plastic_correct +1\n",
        "    for i in range(5):\n",
        "      if top5[0][i][1] in plastic_list:\n",
        "        plastic_correct_5 = plastic_correct_5 +1\n",
        "        break;\n",
        "\n",
        "  #metal\n",
        "  if y[i] == 4:\n",
        "    if label in metal_list:\n",
        "      metal_correct = metal_correct +1\n",
        "    for i in range(5):\n",
        "      if top5[0][i][1] in metal_list:\n",
        "        metal_correct_5 = metal_correct_5 +1\n",
        "        break;\n",
        "  \n",
        "  #trash\n",
        "  if y[i] == 5:\n",
        "    if not (label in metal_list) and not (label in cardboard_list) and not (label in paper_list) and not (label in plastic_list) and not (label in glass_list):\n",
        "      trash_correct = trash_correct +1\n",
        "    for i in range(5):\n",
        "      current = top5[0][i][1]\n",
        "      if not (current in metal_list) and not (current in cardboard_list) and not (current in paper_list) and not (current in plastic_list) and not (current in glass_list):\n",
        "        trash_correct_5 = trash_correct_5 +1\n",
        "        break;\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y2prXE-Z0IK"
      },
      "source": [
        "top1_acc = (cardboard_correct+ glass_correct + paper_correct + plastic_correct + metal_correct + trash_correct) / 2527\n",
        "top5_acc = (cardboard_correct_5+ glass_correct_5 + paper_correct_5 + plastic_correct_5 + metal_correct_5 + trash_correct_5) / 2527\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TlW8WTkgJ7T",
        "outputId": "49245b51-8723-487e-af48-df2ca674d2ca"
      },
      "source": [
        "print(\"Top 1 accuracy: \" + str(top1_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 accuracy: 0.22793826671943015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag53hur0gNAj",
        "outputId": "40034a45-0b52-4ee1-9f16-453511ec2e06"
      },
      "source": [
        "print(\"Top 5 accuracy: \" + str(top5_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 5 accuracy: 0.7340720221606648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7DISlyqgRdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a260cd3-c65e-4276-ba25-effd14011f5a"
      },
      "source": [
        "print(\"Top 1 cardboard: \" + str(cardboard_correct/nb['cardboard']))\n",
        "print(\"Top 5 cardboard: \"+ str(cardboard_correct_5/nb['cardboard']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 cardboard: 0.5371287128712872\n",
            "Top 5 cardboard: 0.8168316831683168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-dZs8mLwows",
        "outputId": "90f6cea9-6251-4ba4-b210-d55f380285e7"
      },
      "source": [
        "print(\"Top 1 glass: \" + str(glass_correct/nb['glass']))\n",
        "print(\"Top 5 glass: \" + str(glass_correct_5/nb['glass']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 glass: 0.3645418326693227\n",
            "Top 5 glass: 0.6374501992031872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYj8xVe6wrkt",
        "outputId": "9f9b465e-4b13-4226-a21f-28720aba8d3f"
      },
      "source": [
        "print(\"Top 1 plastic: \" + str(plastic_correct/nb['plastic']))\n",
        "print(\"Top 5 plastic: \" + str(plastic_correct_5/nb['plastic']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 plastic: 0.022774327122153208\n",
            "Top 5 plastic: 0.10973084886128365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MbhFN_SwsJQ",
        "outputId": "d2bde4e5-f3f4-4a12-8a75-b837d22b5acc"
      },
      "source": [
        "print(\"Top 1 paper: \" + str(paper_correct/nb['paper']))\n",
        "print(\"Top 5 paper: \" + str(paper_correct_5/nb['paper']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 paper: 0.040336134453781515\n",
            "Top 5 paper: 0.15126050420168066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmPI5asiwsx3",
        "outputId": "4ace46fd-9778-496a-fdc8-8a4f366228a0"
      },
      "source": [
        "print(\"Top 1 metal: \" + str(metal_correct/nb['metal']))\n",
        "print(\"Top 5 metal: \" + str(metal_correct_5/nb['metal']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 metal: 0.12652068126520682\n",
            "Top 5 metal: 0.36253041362530414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXsJbOUjxRIy",
        "outputId": "58fdd641-1c9a-4cec-ed63-6ad74d5d5961"
      },
      "source": [
        "print(\"Top 1 trash: \" + str(trash_correct/nb['trash']))\n",
        "print(\"Top 5 trash: \" + str(trash_correct_5/nb['trash']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 1 trash: 0.644927536231884\n",
            "Top 5 trash: 0.9782608695652174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwwZ-JWc1J46"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}