{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "garbage classification keras version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1piXtvRfrWnSCtsvuUK-QBzWq9j8IAjlQ",
      "authorship_tag": "ABX9TyMgcPzkwAAWUP6B1vrWlf6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhtrinh2003/GarbageClassificationKaggle/blob/main/garbage_classification_keras_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQmyvVfWHV1K"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn import model_selection\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC9LvuZz4NBi"
      },
      "source": [
        "class ResNet:\n",
        "  @staticmethod\n",
        "  def residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "    #the shortcut branch of the Resnet module should be initialize as the input(indentity) data\n",
        "    shortcut = data\n",
        "\n",
        "    #the first block of the Resnet module are the 1*1 CONVs\n",
        "    bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
        "    act1 = Activation(\"relu\")(bn1)\n",
        "    conv1 = Conv2D(int(K*0.25), (1,1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "    #the second block of the ResNet module are the 3x3 CONVs\n",
        "    bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
        "    act2 = Activation(\"relu\")(bn2)\n",
        "    conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
        "\n",
        "    # the third block of the ResNet module is another set of 1x1 CONVs\n",
        "    bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(conv2)\n",
        "    act3 = Activation(\"relu\")(bn3)\n",
        "    conv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "    #if we are to reduce the spatial size, apply a CONV layer to the shortcut\n",
        "    if red:\n",
        "      shortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "    # add together the shortcut and the final CONV\n",
        "    x = add([conv3, shortcut])\n",
        "\n",
        "    # return the addition as the output of the ResNet module\n",
        "    return x\n",
        "\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "    # initialize the input shape to be \"channels last\" and the\n",
        "    # channels dimension itself\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "    \n",
        "    # if we are using \"channels first\", update the input shape\n",
        "    # and channels dimension\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "      inputShape = (depth, height, width)\n",
        "      chanDim = 1\n",
        "\n",
        "    # set the input and apply BN\n",
        "    inputs = Input(shape=inputShape)\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(inputs)\n",
        "    \n",
        "    # apply CONV => BN => ACT => POOL to reduce spatial size\n",
        "    x = Conv2D(filters[0], (5, 5), use_bias=False,padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = ZeroPadding2D((1, 1))(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    \n",
        "    # loop over the number of stages\n",
        "    for i in range(0, len(stages)):\n",
        "      # initialize the stride, then apply a residual module\n",
        "      # used to reduce the spatial size of the input volume\t\n",
        "      print(x)\n",
        "      stride = (1, 1) if i == 0 else (2, 2)\n",
        "      x = ResNet.residual_module(x, filters[i + 1], stride,chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "      \n",
        "      # loop over the number of layers in the stage\n",
        "      for j in range(0, stages[i] - 1):\n",
        "        # apply a ResNet module\n",
        "        x = ResNet.residual_module(x, filters[i + 1],(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "    \n",
        "    # apply BN => ACT => POOL\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    \n",
        "    # softmax classifier\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "    \n",
        "    # create the model\n",
        "    model = Model(inputs, x, name=\"resnet\")\n",
        "    \n",
        "    # return the constructed network architecture\n",
        "    return model\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqmzGkwNLJ3s"
      },
      "source": [
        "INPUT IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgXvPNeJI_ow",
        "outputId": "93a1f881-3147-4756-a8c9-463d856a1b06"
      },
      "source": [
        "labels = ['cardboard', 'glass','plastic','paper','metal','trash']\n",
        "img_size = 224\n",
        "data_dir ='/content/drive/MyDrive/Lumiere 2021/Code/Garbage classification/'\n",
        "data = []\n",
        "\n",
        "nb = {'cardboard':404, 'glass': 502, 'plastic': 483 , 'paper': 595 , 'metal': 411, 'trash':138}\n",
        "\n",
        "for label in labels:\n",
        "  path = data_dir + label + \"/\" +label\n",
        "  class_num = labels.index(label)\n",
        "  for i in tqdm(range(1,nb[label])):\n",
        "    img_arr = cv.imread(path+str(i)+\".jpg\")[...,::-1]\n",
        "    resized_arr = cv.resize(img_arr, (img_size, img_size))\n",
        "    data.append([resized_arr, class_num])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 403/403 [02:16<00:00,  2.95it/s]\n",
            "100%|██████████| 501/501 [02:48<00:00,  2.97it/s]\n",
            "100%|██████████| 482/482 [02:42<00:00,  2.96it/s]\n",
            "100%|██████████| 594/594 [03:22<00:00,  2.93it/s]\n",
            "100%|██████████| 410/410 [02:19<00:00,  2.94it/s]\n",
            "100%|██████████| 137/137 [00:48<00:00,  2.84it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAG9dJShSiQl"
      },
      "source": [
        "train, test = model_selection.train_test_split(data, test_size = 0.15)\n",
        "train, val = model_selection.train_test_split(train, test_size = 0.15/0.85)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "wVW6D7rRN6jz",
        "outputId": "3f4b5ac5-be54-4838-8984-978699610eea"
      },
      "source": [
        "l = []\n",
        "for i in train:\n",
        "    if(i[1] == 0):\n",
        "        l.append(\"cardboard\")\n",
        "    elif(i[1] == 1):\n",
        "        l.append(\"glass\")\n",
        "    elif(i[1] == 2):\n",
        "        l.append(\"plastic\")\n",
        "    elif(i[1] == 3):\n",
        "        l.append(\"paper\")\n",
        "    elif(i[1] == 4):\n",
        "        l.append(\"metal\")\n",
        "    else:\n",
        "        l.append(\"trash\")\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(l)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efc1f804a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Z3uO_2ZJcI"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_val.append(feature)\n",
        "  y_val.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "  x_test.append(feature)\n",
        "  y_test.append(label)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255\n",
        "\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF9HqhN_LLAT",
        "outputId": "3c4e5830-e291-4a5d-f545-fc807b5f99fe"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "def build_model(num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "        \n",
        "    return model\n",
        "\n",
        "\n",
        "net = build_model(num_classes=6)\n",
        "\n",
        "net.compile(optimizer='Adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "net.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 6)            6150        dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,692,038\n",
            "Trainable params: 2,104,326\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpxLlG71q6O1"
      },
      "source": [
        "CURRENT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a7RXrTXq8HB",
        "outputId": "a9df4716-c5fc-4ca7-a4c3-84bd73bacde2"
      },
      "source": [
        "history = net.fit(x_train,y_train,epochs = 1500 , validation_data = (x_val, y_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "56/56 [==============================] - 6s 59ms/step - loss: 1.7701 - accuracy: 0.2805 - val_loss: 1.9592 - val_accuracy: 0.2612\n",
            "Epoch 2/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.6559 - accuracy: 0.3009 - val_loss: 1.6390 - val_accuracy: 0.2691\n",
            "Epoch 3/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.6072 - accuracy: 0.3348 - val_loss: 1.8469 - val_accuracy: 0.2507\n",
            "Epoch 4/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.6109 - accuracy: 0.3360 - val_loss: 1.6121 - val_accuracy: 0.3087\n",
            "Epoch 5/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.5779 - accuracy: 0.3541 - val_loss: 1.6017 - val_accuracy: 0.3641\n",
            "Epoch 6/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.5449 - accuracy: 0.3569 - val_loss: 1.6073 - val_accuracy: 0.2876\n",
            "Epoch 7/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.5380 - accuracy: 0.3552 - val_loss: 1.5914 - val_accuracy: 0.3404\n",
            "Epoch 8/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.5322 - accuracy: 0.3654 - val_loss: 1.5842 - val_accuracy: 0.3034\n",
            "Epoch 9/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.5137 - accuracy: 0.3710 - val_loss: 1.6762 - val_accuracy: 0.3404\n",
            "Epoch 10/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.5111 - accuracy: 0.3824 - val_loss: 1.5182 - val_accuracy: 0.3615\n",
            "Epoch 11/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4799 - accuracy: 0.4005 - val_loss: 1.5337 - val_accuracy: 0.3456\n",
            "Epoch 12/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4578 - accuracy: 0.4055 - val_loss: 1.6171 - val_accuracy: 0.3245\n",
            "Epoch 13/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4732 - accuracy: 0.3948 - val_loss: 1.5595 - val_accuracy: 0.3641\n",
            "Epoch 14/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4312 - accuracy: 0.4259 - val_loss: 1.5428 - val_accuracy: 0.3193\n",
            "Epoch 15/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.4259 - accuracy: 0.4208 - val_loss: 1.5312 - val_accuracy: 0.3430\n",
            "Epoch 16/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4555 - accuracy: 0.4005 - val_loss: 1.4994 - val_accuracy: 0.3668\n",
            "Epoch 17/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4121 - accuracy: 0.4310 - val_loss: 1.5118 - val_accuracy: 0.3588\n",
            "Epoch 18/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4176 - accuracy: 0.4163 - val_loss: 1.4861 - val_accuracy: 0.3562\n",
            "Epoch 19/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.4168 - accuracy: 0.4259 - val_loss: 1.4776 - val_accuracy: 0.3456\n",
            "Epoch 20/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3913 - accuracy: 0.4423 - val_loss: 1.5457 - val_accuracy: 0.3562\n",
            "Epoch 21/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.4003 - accuracy: 0.4344 - val_loss: 1.6681 - val_accuracy: 0.3113\n",
            "Epoch 22/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.4205 - accuracy: 0.4191 - val_loss: 1.5447 - val_accuracy: 0.3668\n",
            "Epoch 23/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3789 - accuracy: 0.4344 - val_loss: 1.5396 - val_accuracy: 0.3720\n",
            "Epoch 24/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.4254 - accuracy: 0.4338 - val_loss: 1.4813 - val_accuracy: 0.3931\n",
            "Epoch 25/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.3796 - accuracy: 0.4361 - val_loss: 1.5184 - val_accuracy: 0.3668\n",
            "Epoch 26/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.3601 - accuracy: 0.4502 - val_loss: 1.5041 - val_accuracy: 0.3483\n",
            "Epoch 27/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3638 - accuracy: 0.4485 - val_loss: 1.5167 - val_accuracy: 0.3747\n",
            "Epoch 28/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.3709 - accuracy: 0.4508 - val_loss: 1.4569 - val_accuracy: 0.3958\n",
            "Epoch 29/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3374 - accuracy: 0.4734 - val_loss: 1.4683 - val_accuracy: 0.4090\n",
            "Epoch 30/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3453 - accuracy: 0.4666 - val_loss: 1.4954 - val_accuracy: 0.3879\n",
            "Epoch 31/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3384 - accuracy: 0.4672 - val_loss: 1.4712 - val_accuracy: 0.4037\n",
            "Epoch 32/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3388 - accuracy: 0.4661 - val_loss: 1.5324 - val_accuracy: 0.3958\n",
            "Epoch 33/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3398 - accuracy: 0.4593 - val_loss: 1.4987 - val_accuracy: 0.3483\n",
            "Epoch 34/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.3463 - accuracy: 0.4497 - val_loss: 1.4861 - val_accuracy: 0.3984\n",
            "Epoch 35/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3361 - accuracy: 0.4751 - val_loss: 1.4725 - val_accuracy: 0.4011\n",
            "Epoch 36/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3115 - accuracy: 0.4943 - val_loss: 1.4856 - val_accuracy: 0.3668\n",
            "Epoch 37/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.3495 - accuracy: 0.4683 - val_loss: 1.5214 - val_accuracy: 0.3773\n",
            "Epoch 38/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3837 - accuracy: 0.4338 - val_loss: 1.4547 - val_accuracy: 0.4011\n",
            "Epoch 39/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.3366 - accuracy: 0.4570 - val_loss: 1.4677 - val_accuracy: 0.4116\n",
            "Epoch 40/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3009 - accuracy: 0.4825 - val_loss: 1.5162 - val_accuracy: 0.3826\n",
            "Epoch 41/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3080 - accuracy: 0.4774 - val_loss: 1.4786 - val_accuracy: 0.3984\n",
            "Epoch 42/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2950 - accuracy: 0.4745 - val_loss: 1.4587 - val_accuracy: 0.4169\n",
            "Epoch 43/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2979 - accuracy: 0.4876 - val_loss: 1.5815 - val_accuracy: 0.3562\n",
            "Epoch 44/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3509 - accuracy: 0.4593 - val_loss: 1.4680 - val_accuracy: 0.3615\n",
            "Epoch 45/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3412 - accuracy: 0.4695 - val_loss: 1.5100 - val_accuracy: 0.4248\n",
            "Epoch 46/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2821 - accuracy: 0.4842 - val_loss: 1.4845 - val_accuracy: 0.4195\n",
            "Epoch 47/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2869 - accuracy: 0.4926 - val_loss: 1.5716 - val_accuracy: 0.3509\n",
            "Epoch 48/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.3247 - accuracy: 0.4734 - val_loss: 1.5246 - val_accuracy: 0.3852\n",
            "Epoch 49/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2960 - accuracy: 0.4825 - val_loss: 1.4685 - val_accuracy: 0.3879\n",
            "Epoch 50/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2662 - accuracy: 0.4966 - val_loss: 1.6864 - val_accuracy: 0.3588\n",
            "Epoch 51/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2772 - accuracy: 0.5011 - val_loss: 1.4381 - val_accuracy: 0.4142\n",
            "Epoch 52/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2746 - accuracy: 0.4972 - val_loss: 1.5401 - val_accuracy: 0.3483\n",
            "Epoch 53/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2913 - accuracy: 0.4802 - val_loss: 1.5048 - val_accuracy: 0.4090\n",
            "Epoch 54/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2820 - accuracy: 0.4825 - val_loss: 1.4756 - val_accuracy: 0.4116\n",
            "Epoch 55/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2491 - accuracy: 0.5164 - val_loss: 1.5533 - val_accuracy: 0.3694\n",
            "Epoch 56/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2952 - accuracy: 0.4847 - val_loss: 1.4773 - val_accuracy: 0.4116\n",
            "Epoch 57/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2787 - accuracy: 0.4870 - val_loss: 1.4883 - val_accuracy: 0.3826\n",
            "Epoch 58/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2543 - accuracy: 0.5107 - val_loss: 1.5005 - val_accuracy: 0.3852\n",
            "Epoch 59/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2488 - accuracy: 0.5028 - val_loss: 1.5145 - val_accuracy: 0.3720\n",
            "Epoch 60/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2488 - accuracy: 0.5085 - val_loss: 1.4791 - val_accuracy: 0.4011\n",
            "Epoch 61/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2488 - accuracy: 0.5136 - val_loss: 1.4447 - val_accuracy: 0.4142\n",
            "Epoch 62/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2561 - accuracy: 0.5164 - val_loss: 1.4948 - val_accuracy: 0.4037\n",
            "Epoch 63/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.2575 - accuracy: 0.4915 - val_loss: 1.4580 - val_accuracy: 0.4142\n",
            "Epoch 64/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2299 - accuracy: 0.5147 - val_loss: 1.5318 - val_accuracy: 0.3747\n",
            "Epoch 65/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2288 - accuracy: 0.5164 - val_loss: 1.5074 - val_accuracy: 0.3958\n",
            "Epoch 66/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2417 - accuracy: 0.5158 - val_loss: 1.4736 - val_accuracy: 0.4327\n",
            "Epoch 67/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2172 - accuracy: 0.5192 - val_loss: 1.4676 - val_accuracy: 0.3747\n",
            "Epoch 68/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2121 - accuracy: 0.5266 - val_loss: 1.4880 - val_accuracy: 0.3958\n",
            "Epoch 69/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2191 - accuracy: 0.5288 - val_loss: 1.5207 - val_accuracy: 0.3852\n",
            "Epoch 70/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2456 - accuracy: 0.4994 - val_loss: 1.4484 - val_accuracy: 0.3931\n",
            "Epoch 71/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2321 - accuracy: 0.5175 - val_loss: 1.6053 - val_accuracy: 0.3984\n",
            "Epoch 72/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2808 - accuracy: 0.4943 - val_loss: 1.4656 - val_accuracy: 0.3931\n",
            "Epoch 73/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2123 - accuracy: 0.5113 - val_loss: 1.4441 - val_accuracy: 0.4380\n",
            "Epoch 74/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2141 - accuracy: 0.5294 - val_loss: 1.4761 - val_accuracy: 0.3668\n",
            "Epoch 75/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2595 - accuracy: 0.5006 - val_loss: 1.4513 - val_accuracy: 0.4195\n",
            "Epoch 76/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2040 - accuracy: 0.5288 - val_loss: 1.4710 - val_accuracy: 0.3852\n",
            "Epoch 77/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1861 - accuracy: 0.5419 - val_loss: 1.4502 - val_accuracy: 0.4222\n",
            "Epoch 78/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2340 - accuracy: 0.5130 - val_loss: 1.5997 - val_accuracy: 0.3694\n",
            "Epoch 79/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2756 - accuracy: 0.5006 - val_loss: 1.4630 - val_accuracy: 0.4037\n",
            "Epoch 80/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1870 - accuracy: 0.5402 - val_loss: 1.4768 - val_accuracy: 0.4142\n",
            "Epoch 81/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2109 - accuracy: 0.5277 - val_loss: 1.4397 - val_accuracy: 0.4169\n",
            "Epoch 82/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2041 - accuracy: 0.5249 - val_loss: 1.5752 - val_accuracy: 0.4116\n",
            "Epoch 83/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1889 - accuracy: 0.5481 - val_loss: 1.4924 - val_accuracy: 0.4195\n",
            "Epoch 84/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1786 - accuracy: 0.5441 - val_loss: 1.5238 - val_accuracy: 0.3852\n",
            "Epoch 85/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1964 - accuracy: 0.5288 - val_loss: 1.4767 - val_accuracy: 0.4169\n",
            "Epoch 86/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1821 - accuracy: 0.5334 - val_loss: 1.4973 - val_accuracy: 0.3958\n",
            "Epoch 87/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.2105 - accuracy: 0.5288 - val_loss: 1.5902 - val_accuracy: 0.3456\n",
            "Epoch 88/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.2249 - accuracy: 0.5153 - val_loss: 1.4273 - val_accuracy: 0.4459\n",
            "Epoch 89/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1665 - accuracy: 0.5464 - val_loss: 1.4598 - val_accuracy: 0.4459\n",
            "Epoch 90/1500\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 1.1894 - accuracy: 0.5226 - val_loss: 1.5383 - val_accuracy: 0.3905\n",
            "Epoch 91/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1824 - accuracy: 0.5452 - val_loss: 1.4718 - val_accuracy: 0.4142\n",
            "Epoch 92/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1601 - accuracy: 0.5549 - val_loss: 1.4728 - val_accuracy: 0.4248\n",
            "Epoch 93/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1511 - accuracy: 0.5611 - val_loss: 1.5210 - val_accuracy: 0.4222\n",
            "Epoch 94/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1879 - accuracy: 0.5356 - val_loss: 1.5711 - val_accuracy: 0.3852\n",
            "Epoch 95/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1894 - accuracy: 0.5322 - val_loss: 1.4472 - val_accuracy: 0.4195\n",
            "Epoch 96/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1581 - accuracy: 0.5441 - val_loss: 1.5444 - val_accuracy: 0.3799\n",
            "Epoch 97/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1689 - accuracy: 0.5345 - val_loss: 1.4720 - val_accuracy: 0.4195\n",
            "Epoch 98/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1797 - accuracy: 0.5334 - val_loss: 1.4402 - val_accuracy: 0.4327\n",
            "Epoch 99/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1560 - accuracy: 0.5436 - val_loss: 1.4538 - val_accuracy: 0.4459\n",
            "Epoch 100/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1386 - accuracy: 0.5628 - val_loss: 1.5094 - val_accuracy: 0.4090\n",
            "Epoch 101/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1706 - accuracy: 0.5362 - val_loss: 1.5000 - val_accuracy: 0.4406\n",
            "Epoch 102/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1611 - accuracy: 0.5543 - val_loss: 1.4839 - val_accuracy: 0.4116\n",
            "Epoch 103/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1152 - accuracy: 0.5645 - val_loss: 1.6100 - val_accuracy: 0.3905\n",
            "Epoch 104/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1428 - accuracy: 0.5594 - val_loss: 1.4850 - val_accuracy: 0.4406\n",
            "Epoch 105/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1487 - accuracy: 0.5583 - val_loss: 1.4941 - val_accuracy: 0.4248\n",
            "Epoch 106/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1781 - accuracy: 0.5458 - val_loss: 1.4394 - val_accuracy: 0.4459\n",
            "Epoch 107/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1224 - accuracy: 0.5650 - val_loss: 1.5512 - val_accuracy: 0.4538\n",
            "Epoch 108/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1174 - accuracy: 0.5775 - val_loss: 1.5387 - val_accuracy: 0.4169\n",
            "Epoch 109/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1635 - accuracy: 0.5436 - val_loss: 1.5245 - val_accuracy: 0.4327\n",
            "Epoch 110/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1711 - accuracy: 0.5328 - val_loss: 1.4781 - val_accuracy: 0.4116\n",
            "Epoch 111/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1640 - accuracy: 0.5402 - val_loss: 1.4713 - val_accuracy: 0.4142\n",
            "Epoch 112/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1608 - accuracy: 0.5481 - val_loss: 1.8613 - val_accuracy: 0.3430\n",
            "Epoch 113/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1799 - accuracy: 0.5492 - val_loss: 1.4700 - val_accuracy: 0.4327\n",
            "Epoch 114/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.1147 - accuracy: 0.5781 - val_loss: 1.4685 - val_accuracy: 0.4274\n",
            "Epoch 115/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1209 - accuracy: 0.5696 - val_loss: 1.4643 - val_accuracy: 0.4485\n",
            "Epoch 116/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.1904 - accuracy: 0.5317 - val_loss: 1.4978 - val_accuracy: 0.3984\n",
            "Epoch 117/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1266 - accuracy: 0.5617 - val_loss: 1.4766 - val_accuracy: 0.4406\n",
            "Epoch 118/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1089 - accuracy: 0.5741 - val_loss: 1.6566 - val_accuracy: 0.4037\n",
            "Epoch 119/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1493 - accuracy: 0.5515 - val_loss: 1.5659 - val_accuracy: 0.4116\n",
            "Epoch 120/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1212 - accuracy: 0.5622 - val_loss: 1.4386 - val_accuracy: 0.4433\n",
            "Epoch 121/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1207 - accuracy: 0.5690 - val_loss: 1.4681 - val_accuracy: 0.4301\n",
            "Epoch 122/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1042 - accuracy: 0.5684 - val_loss: 1.5005 - val_accuracy: 0.4749\n",
            "Epoch 123/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1271 - accuracy: 0.5662 - val_loss: 1.4946 - val_accuracy: 0.4222\n",
            "Epoch 124/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1423 - accuracy: 0.5458 - val_loss: 1.4784 - val_accuracy: 0.4433\n",
            "Epoch 125/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1073 - accuracy: 0.5820 - val_loss: 1.4644 - val_accuracy: 0.4327\n",
            "Epoch 126/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1083 - accuracy: 0.5769 - val_loss: 1.5675 - val_accuracy: 0.3720\n",
            "Epoch 127/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1445 - accuracy: 0.5441 - val_loss: 1.5634 - val_accuracy: 0.3905\n",
            "Epoch 128/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1181 - accuracy: 0.5617 - val_loss: 1.5112 - val_accuracy: 0.4512\n",
            "Epoch 129/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0715 - accuracy: 0.6029 - val_loss: 1.5571 - val_accuracy: 0.4222\n",
            "Epoch 130/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0815 - accuracy: 0.5894 - val_loss: 1.5245 - val_accuracy: 0.4169\n",
            "Epoch 131/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0810 - accuracy: 0.5713 - val_loss: 1.5218 - val_accuracy: 0.4142\n",
            "Epoch 132/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0850 - accuracy: 0.5860 - val_loss: 1.5108 - val_accuracy: 0.4248\n",
            "Epoch 133/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1113 - accuracy: 0.5684 - val_loss: 1.4966 - val_accuracy: 0.4380\n",
            "Epoch 134/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0844 - accuracy: 0.5814 - val_loss: 1.5830 - val_accuracy: 0.4248\n",
            "Epoch 135/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1116 - accuracy: 0.5843 - val_loss: 1.4411 - val_accuracy: 0.4433\n",
            "Epoch 136/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0856 - accuracy: 0.5939 - val_loss: 1.5868 - val_accuracy: 0.4037\n",
            "Epoch 137/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0843 - accuracy: 0.5882 - val_loss: 1.4764 - val_accuracy: 0.4354\n",
            "Epoch 138/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1065 - accuracy: 0.5786 - val_loss: 1.4714 - val_accuracy: 0.4697\n",
            "Epoch 139/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0613 - accuracy: 0.5939 - val_loss: 1.4488 - val_accuracy: 0.4697\n",
            "Epoch 140/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0977 - accuracy: 0.5690 - val_loss: 1.5061 - val_accuracy: 0.4354\n",
            "Epoch 141/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0890 - accuracy: 0.5786 - val_loss: 1.5620 - val_accuracy: 0.3958\n",
            "Epoch 142/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0990 - accuracy: 0.5764 - val_loss: 1.5778 - val_accuracy: 0.4116\n",
            "Epoch 143/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0757 - accuracy: 0.5831 - val_loss: 1.4793 - val_accuracy: 0.4354\n",
            "Epoch 144/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0485 - accuracy: 0.5933 - val_loss: 1.4801 - val_accuracy: 0.4248\n",
            "Epoch 145/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0719 - accuracy: 0.5871 - val_loss: 1.4608 - val_accuracy: 0.4644\n",
            "Epoch 146/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0587 - accuracy: 0.5939 - val_loss: 1.6117 - val_accuracy: 0.4723\n",
            "Epoch 147/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0744 - accuracy: 0.5792 - val_loss: 1.5096 - val_accuracy: 0.4406\n",
            "Epoch 148/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0862 - accuracy: 0.5735 - val_loss: 1.6083 - val_accuracy: 0.4011\n",
            "Epoch 149/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.1026 - accuracy: 0.5650 - val_loss: 1.4717 - val_accuracy: 0.4433\n",
            "Epoch 150/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0631 - accuracy: 0.5945 - val_loss: 1.5050 - val_accuracy: 0.4222\n",
            "Epoch 151/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0780 - accuracy: 0.5831 - val_loss: 1.4804 - val_accuracy: 0.4644\n",
            "Epoch 152/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0565 - accuracy: 0.5973 - val_loss: 1.4967 - val_accuracy: 0.4222\n",
            "Epoch 153/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0640 - accuracy: 0.5967 - val_loss: 1.5683 - val_accuracy: 0.4169\n",
            "Epoch 154/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0798 - accuracy: 0.5860 - val_loss: 1.4368 - val_accuracy: 0.4828\n",
            "Epoch 155/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0979 - accuracy: 0.5764 - val_loss: 1.4755 - val_accuracy: 0.4538\n",
            "Epoch 156/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0999 - accuracy: 0.5781 - val_loss: 1.4856 - val_accuracy: 0.4776\n",
            "Epoch 157/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0726 - accuracy: 0.5837 - val_loss: 1.5506 - val_accuracy: 0.4591\n",
            "Epoch 158/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0656 - accuracy: 0.5826 - val_loss: 1.4361 - val_accuracy: 0.4459\n",
            "Epoch 159/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0279 - accuracy: 0.6097 - val_loss: 1.5117 - val_accuracy: 0.4169\n",
            "Epoch 160/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0779 - accuracy: 0.5922 - val_loss: 1.4609 - val_accuracy: 0.4828\n",
            "Epoch 161/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0317 - accuracy: 0.5967 - val_loss: 1.4948 - val_accuracy: 0.4433\n",
            "Epoch 162/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0443 - accuracy: 0.6086 - val_loss: 1.4804 - val_accuracy: 0.4565\n",
            "Epoch 163/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0271 - accuracy: 0.6103 - val_loss: 1.5792 - val_accuracy: 0.3984\n",
            "Epoch 164/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0365 - accuracy: 0.6035 - val_loss: 1.5672 - val_accuracy: 0.4274\n",
            "Epoch 165/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1080 - accuracy: 0.5690 - val_loss: 1.4901 - val_accuracy: 0.4248\n",
            "Epoch 166/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0415 - accuracy: 0.6024 - val_loss: 1.4986 - val_accuracy: 0.4538\n",
            "Epoch 167/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.1034 - accuracy: 0.5645 - val_loss: 1.5753 - val_accuracy: 0.4169\n",
            "Epoch 168/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0263 - accuracy: 0.6012 - val_loss: 1.5382 - val_accuracy: 0.4248\n",
            "Epoch 169/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0222 - accuracy: 0.6148 - val_loss: 1.4825 - val_accuracy: 0.4327\n",
            "Epoch 170/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0249 - accuracy: 0.6114 - val_loss: 1.5654 - val_accuracy: 0.4248\n",
            "Epoch 171/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0410 - accuracy: 0.5945 - val_loss: 1.5285 - val_accuracy: 0.4406\n",
            "Epoch 172/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0237 - accuracy: 0.6103 - val_loss: 1.5187 - val_accuracy: 0.4248\n",
            "Epoch 173/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0061 - accuracy: 0.6103 - val_loss: 1.5568 - val_accuracy: 0.4406\n",
            "Epoch 174/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0036 - accuracy: 0.6222 - val_loss: 1.5271 - val_accuracy: 0.4301\n",
            "Epoch 175/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0163 - accuracy: 0.6114 - val_loss: 1.4783 - val_accuracy: 0.5013\n",
            "Epoch 176/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0229 - accuracy: 0.6058 - val_loss: 1.4980 - val_accuracy: 0.4538\n",
            "Epoch 177/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9954 - accuracy: 0.6143 - val_loss: 1.5034 - val_accuracy: 0.4406\n",
            "Epoch 178/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 1.0003 - accuracy: 0.6273 - val_loss: 1.5057 - val_accuracy: 0.4802\n",
            "Epoch 179/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0484 - accuracy: 0.5984 - val_loss: 1.5731 - val_accuracy: 0.4195\n",
            "Epoch 180/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0025 - accuracy: 0.6097 - val_loss: 1.5168 - val_accuracy: 0.4248\n",
            "Epoch 181/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0168 - accuracy: 0.6086 - val_loss: 1.6296 - val_accuracy: 0.4248\n",
            "Epoch 182/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0201 - accuracy: 0.6075 - val_loss: 1.4825 - val_accuracy: 0.4802\n",
            "Epoch 183/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9922 - accuracy: 0.6227 - val_loss: 1.6212 - val_accuracy: 0.4169\n",
            "Epoch 184/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0083 - accuracy: 0.6154 - val_loss: 1.4967 - val_accuracy: 0.4934\n",
            "Epoch 185/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0195 - accuracy: 0.6007 - val_loss: 1.5662 - val_accuracy: 0.4354\n",
            "Epoch 186/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0209 - accuracy: 0.6052 - val_loss: 1.5914 - val_accuracy: 0.4116\n",
            "Epoch 187/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0001 - accuracy: 0.6193 - val_loss: 1.5185 - val_accuracy: 0.4380\n",
            "Epoch 188/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0013 - accuracy: 0.6210 - val_loss: 1.5842 - val_accuracy: 0.4195\n",
            "Epoch 189/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9854 - accuracy: 0.6222 - val_loss: 1.5436 - val_accuracy: 0.4433\n",
            "Epoch 190/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9877 - accuracy: 0.6256 - val_loss: 1.5504 - val_accuracy: 0.4433\n",
            "Epoch 191/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9944 - accuracy: 0.6227 - val_loss: 1.5090 - val_accuracy: 0.4723\n",
            "Epoch 192/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9927 - accuracy: 0.6193 - val_loss: 1.4885 - val_accuracy: 0.4776\n",
            "Epoch 193/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0265 - accuracy: 0.6114 - val_loss: 1.4786 - val_accuracy: 0.4485\n",
            "Epoch 194/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9870 - accuracy: 0.6210 - val_loss: 1.5594 - val_accuracy: 0.4908\n",
            "Epoch 195/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 1.0085 - accuracy: 0.6069 - val_loss: 1.5679 - val_accuracy: 0.4169\n",
            "Epoch 196/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0446 - accuracy: 0.6007 - val_loss: 1.5663 - val_accuracy: 0.4301\n",
            "Epoch 197/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0053 - accuracy: 0.6143 - val_loss: 1.5047 - val_accuracy: 0.4538\n",
            "Epoch 198/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0199 - accuracy: 0.6120 - val_loss: 1.4941 - val_accuracy: 0.4485\n",
            "Epoch 199/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9738 - accuracy: 0.6386 - val_loss: 1.4810 - val_accuracy: 0.4960\n",
            "Epoch 200/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9882 - accuracy: 0.6312 - val_loss: 1.5143 - val_accuracy: 0.4459\n",
            "Epoch 201/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9837 - accuracy: 0.6250 - val_loss: 1.5263 - val_accuracy: 0.4512\n",
            "Epoch 202/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9887 - accuracy: 0.6210 - val_loss: 1.5592 - val_accuracy: 0.4538\n",
            "Epoch 203/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9770 - accuracy: 0.6329 - val_loss: 1.5398 - val_accuracy: 0.4723\n",
            "Epoch 204/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9446 - accuracy: 0.6391 - val_loss: 1.5452 - val_accuracy: 0.4538\n",
            "Epoch 205/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9639 - accuracy: 0.6335 - val_loss: 1.5474 - val_accuracy: 0.4406\n",
            "Epoch 206/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0163 - accuracy: 0.6126 - val_loss: 1.5682 - val_accuracy: 0.4538\n",
            "Epoch 207/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0313 - accuracy: 0.6131 - val_loss: 1.5686 - val_accuracy: 0.4248\n",
            "Epoch 208/1500\n",
            "56/56 [==============================] - 3s 47ms/step - loss: 1.0058 - accuracy: 0.6080 - val_loss: 1.5276 - val_accuracy: 0.4697\n",
            "Epoch 209/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9757 - accuracy: 0.6301 - val_loss: 1.7605 - val_accuracy: 0.4142\n",
            "Epoch 210/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 1.0117 - accuracy: 0.6256 - val_loss: 1.6011 - val_accuracy: 0.4697\n",
            "Epoch 211/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9892 - accuracy: 0.6143 - val_loss: 1.5064 - val_accuracy: 0.4406\n",
            "Epoch 212/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9625 - accuracy: 0.6442 - val_loss: 1.5185 - val_accuracy: 0.4565\n",
            "Epoch 213/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9671 - accuracy: 0.6340 - val_loss: 1.5153 - val_accuracy: 0.4723\n",
            "Epoch 214/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9514 - accuracy: 0.6425 - val_loss: 1.6024 - val_accuracy: 0.4090\n",
            "Epoch 215/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9582 - accuracy: 0.6244 - val_loss: 1.5455 - val_accuracy: 0.4327\n",
            "Epoch 216/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9443 - accuracy: 0.6465 - val_loss: 1.5978 - val_accuracy: 0.4433\n",
            "Epoch 217/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9759 - accuracy: 0.6301 - val_loss: 1.6076 - val_accuracy: 0.4380\n",
            "Epoch 218/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 1.0197 - accuracy: 0.5962 - val_loss: 1.5292 - val_accuracy: 0.4301\n",
            "Epoch 219/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9360 - accuracy: 0.6425 - val_loss: 1.5807 - val_accuracy: 0.5119\n",
            "Epoch 220/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9571 - accuracy: 0.6391 - val_loss: 1.5528 - val_accuracy: 0.4670\n",
            "Epoch 221/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9585 - accuracy: 0.6482 - val_loss: 1.6464 - val_accuracy: 0.4670\n",
            "Epoch 222/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9683 - accuracy: 0.6312 - val_loss: 1.6198 - val_accuracy: 0.4617\n",
            "Epoch 223/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9734 - accuracy: 0.6222 - val_loss: 1.5412 - val_accuracy: 0.4433\n",
            "Epoch 224/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9377 - accuracy: 0.6550 - val_loss: 1.5457 - val_accuracy: 0.4459\n",
            "Epoch 225/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9350 - accuracy: 0.6380 - val_loss: 1.6315 - val_accuracy: 0.4459\n",
            "Epoch 226/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9544 - accuracy: 0.6420 - val_loss: 1.5738 - val_accuracy: 0.4327\n",
            "Epoch 227/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9809 - accuracy: 0.6273 - val_loss: 1.5794 - val_accuracy: 0.4274\n",
            "Epoch 228/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9298 - accuracy: 0.6589 - val_loss: 1.5021 - val_accuracy: 0.4459\n",
            "Epoch 229/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9257 - accuracy: 0.6572 - val_loss: 1.5200 - val_accuracy: 0.4802\n",
            "Epoch 230/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9473 - accuracy: 0.6256 - val_loss: 1.5135 - val_accuracy: 0.5198\n",
            "Epoch 231/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9281 - accuracy: 0.6505 - val_loss: 1.5992 - val_accuracy: 0.4354\n",
            "Epoch 232/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9490 - accuracy: 0.6465 - val_loss: 1.5762 - val_accuracy: 0.4512\n",
            "Epoch 233/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9457 - accuracy: 0.6295 - val_loss: 1.7101 - val_accuracy: 0.4142\n",
            "Epoch 234/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9763 - accuracy: 0.6290 - val_loss: 1.6304 - val_accuracy: 0.4274\n",
            "Epoch 235/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9545 - accuracy: 0.6471 - val_loss: 1.5663 - val_accuracy: 0.4538\n",
            "Epoch 236/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9303 - accuracy: 0.6482 - val_loss: 1.6532 - val_accuracy: 0.4354\n",
            "Epoch 237/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9206 - accuracy: 0.6471 - val_loss: 1.6379 - val_accuracy: 0.4433\n",
            "Epoch 238/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9408 - accuracy: 0.6391 - val_loss: 1.5856 - val_accuracy: 0.4908\n",
            "Epoch 239/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9721 - accuracy: 0.6256 - val_loss: 1.5737 - val_accuracy: 0.4327\n",
            "Epoch 240/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9185 - accuracy: 0.6533 - val_loss: 1.5735 - val_accuracy: 0.5040\n",
            "Epoch 241/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9493 - accuracy: 0.6442 - val_loss: 1.4997 - val_accuracy: 0.4828\n",
            "Epoch 242/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9311 - accuracy: 0.6431 - val_loss: 1.6801 - val_accuracy: 0.4169\n",
            "Epoch 243/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9284 - accuracy: 0.6550 - val_loss: 1.5815 - val_accuracy: 0.4644\n",
            "Epoch 244/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9634 - accuracy: 0.6256 - val_loss: 1.5418 - val_accuracy: 0.4828\n",
            "Epoch 245/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8837 - accuracy: 0.6691 - val_loss: 1.5430 - val_accuracy: 0.4828\n",
            "Epoch 246/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.9108 - accuracy: 0.6612 - val_loss: 1.5778 - val_accuracy: 0.4670\n",
            "Epoch 247/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9149 - accuracy: 0.6493 - val_loss: 1.5409 - val_accuracy: 0.4960\n",
            "Epoch 248/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9374 - accuracy: 0.6442 - val_loss: 1.8344 - val_accuracy: 0.3773\n",
            "Epoch 249/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9595 - accuracy: 0.6431 - val_loss: 1.6108 - val_accuracy: 0.4776\n",
            "Epoch 250/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9163 - accuracy: 0.6510 - val_loss: 1.6107 - val_accuracy: 0.4723\n",
            "Epoch 251/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9067 - accuracy: 0.6606 - val_loss: 1.6094 - val_accuracy: 0.4828\n",
            "Epoch 252/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9280 - accuracy: 0.6612 - val_loss: 1.5686 - val_accuracy: 0.4697\n",
            "Epoch 253/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9134 - accuracy: 0.6578 - val_loss: 1.6232 - val_accuracy: 0.4617\n",
            "Epoch 254/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9219 - accuracy: 0.6493 - val_loss: 1.6211 - val_accuracy: 0.4697\n",
            "Epoch 255/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9287 - accuracy: 0.6346 - val_loss: 1.6610 - val_accuracy: 0.4354\n",
            "Epoch 256/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9153 - accuracy: 0.6459 - val_loss: 1.8098 - val_accuracy: 0.3852\n",
            "Epoch 257/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9140 - accuracy: 0.6476 - val_loss: 1.5488 - val_accuracy: 0.4776\n",
            "Epoch 258/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9275 - accuracy: 0.6374 - val_loss: 1.6566 - val_accuracy: 0.4459\n",
            "Epoch 259/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9502 - accuracy: 0.6340 - val_loss: 1.8480 - val_accuracy: 0.3799\n",
            "Epoch 260/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9064 - accuracy: 0.6601 - val_loss: 1.5874 - val_accuracy: 0.4433\n",
            "Epoch 261/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9654 - accuracy: 0.6403 - val_loss: 1.5834 - val_accuracy: 0.4591\n",
            "Epoch 262/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9112 - accuracy: 0.6544 - val_loss: 1.5535 - val_accuracy: 0.4776\n",
            "Epoch 263/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.8850 - accuracy: 0.6691 - val_loss: 1.5946 - val_accuracy: 0.5172\n",
            "Epoch 264/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8970 - accuracy: 0.6640 - val_loss: 1.6037 - val_accuracy: 0.5119\n",
            "Epoch 265/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9164 - accuracy: 0.6623 - val_loss: 1.6412 - val_accuracy: 0.4327\n",
            "Epoch 266/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8948 - accuracy: 0.6499 - val_loss: 1.6668 - val_accuracy: 0.4776\n",
            "Epoch 267/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9241 - accuracy: 0.6578 - val_loss: 1.5875 - val_accuracy: 0.4538\n",
            "Epoch 268/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9092 - accuracy: 0.6595 - val_loss: 1.6282 - val_accuracy: 0.4195\n",
            "Epoch 269/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.9160 - accuracy: 0.6527 - val_loss: 1.5441 - val_accuracy: 0.4934\n",
            "Epoch 270/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8692 - accuracy: 0.6793 - val_loss: 1.6597 - val_accuracy: 0.4934\n",
            "Epoch 271/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9017 - accuracy: 0.6567 - val_loss: 1.5893 - val_accuracy: 0.4433\n",
            "Epoch 272/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8798 - accuracy: 0.6708 - val_loss: 1.5569 - val_accuracy: 0.4960\n",
            "Epoch 273/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.8660 - accuracy: 0.6669 - val_loss: 1.5566 - val_accuracy: 0.4987\n",
            "Epoch 274/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8462 - accuracy: 0.6878 - val_loss: 1.6005 - val_accuracy: 0.4644\n",
            "Epoch 275/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8819 - accuracy: 0.6646 - val_loss: 1.7115 - val_accuracy: 0.4670\n",
            "Epoch 276/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8826 - accuracy: 0.6578 - val_loss: 1.7328 - val_accuracy: 0.4380\n",
            "Epoch 277/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8891 - accuracy: 0.6663 - val_loss: 1.6060 - val_accuracy: 0.4565\n",
            "Epoch 278/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8748 - accuracy: 0.6736 - val_loss: 1.7670 - val_accuracy: 0.4248\n",
            "Epoch 279/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9010 - accuracy: 0.6646 - val_loss: 1.7747 - val_accuracy: 0.4274\n",
            "Epoch 280/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9383 - accuracy: 0.6386 - val_loss: 1.7245 - val_accuracy: 0.4934\n",
            "Epoch 281/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8818 - accuracy: 0.6652 - val_loss: 1.6148 - val_accuracy: 0.4749\n",
            "Epoch 282/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8831 - accuracy: 0.6572 - val_loss: 1.6274 - val_accuracy: 0.5040\n",
            "Epoch 283/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9416 - accuracy: 0.6454 - val_loss: 1.6501 - val_accuracy: 0.4485\n",
            "Epoch 284/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9022 - accuracy: 0.6567 - val_loss: 1.7110 - val_accuracy: 0.4459\n",
            "Epoch 285/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8788 - accuracy: 0.6810 - val_loss: 1.6365 - val_accuracy: 0.4433\n",
            "Epoch 286/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9222 - accuracy: 0.6431 - val_loss: 1.5980 - val_accuracy: 0.4433\n",
            "Epoch 287/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8583 - accuracy: 0.6827 - val_loss: 1.6818 - val_accuracy: 0.4433\n",
            "Epoch 288/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8886 - accuracy: 0.6765 - val_loss: 1.6181 - val_accuracy: 0.4908\n",
            "Epoch 289/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8731 - accuracy: 0.6708 - val_loss: 1.5954 - val_accuracy: 0.4934\n",
            "Epoch 290/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8831 - accuracy: 0.6652 - val_loss: 1.6810 - val_accuracy: 0.5092\n",
            "Epoch 291/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8520 - accuracy: 0.6816 - val_loss: 1.6562 - val_accuracy: 0.4828\n",
            "Epoch 292/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9006 - accuracy: 0.6618 - val_loss: 1.6483 - val_accuracy: 0.4617\n",
            "Epoch 293/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.8864 - accuracy: 0.6742 - val_loss: 1.6318 - val_accuracy: 0.5040\n",
            "Epoch 294/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8611 - accuracy: 0.6833 - val_loss: 1.7903 - val_accuracy: 0.4063\n",
            "Epoch 295/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9121 - accuracy: 0.6465 - val_loss: 1.6593 - val_accuracy: 0.4512\n",
            "Epoch 296/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8935 - accuracy: 0.6589 - val_loss: 1.5923 - val_accuracy: 0.5040\n",
            "Epoch 297/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8643 - accuracy: 0.6804 - val_loss: 1.5907 - val_accuracy: 0.4538\n",
            "Epoch 298/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8540 - accuracy: 0.6736 - val_loss: 1.6634 - val_accuracy: 0.4987\n",
            "Epoch 299/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8930 - accuracy: 0.6516 - val_loss: 1.7833 - val_accuracy: 0.4142\n",
            "Epoch 300/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8960 - accuracy: 0.6787 - val_loss: 1.5724 - val_accuracy: 0.5172\n",
            "Epoch 301/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8400 - accuracy: 0.6867 - val_loss: 1.6766 - val_accuracy: 0.4485\n",
            "Epoch 302/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8750 - accuracy: 0.6702 - val_loss: 1.5923 - val_accuracy: 0.4670\n",
            "Epoch 303/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8952 - accuracy: 0.6544 - val_loss: 1.5703 - val_accuracy: 0.4908\n",
            "Epoch 304/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8480 - accuracy: 0.6872 - val_loss: 1.6864 - val_accuracy: 0.5198\n",
            "Epoch 305/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8687 - accuracy: 0.6787 - val_loss: 1.6383 - val_accuracy: 0.4855\n",
            "Epoch 306/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8311 - accuracy: 0.6968 - val_loss: 1.6262 - val_accuracy: 0.4485\n",
            "Epoch 307/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8240 - accuracy: 0.6923 - val_loss: 1.6312 - val_accuracy: 0.5092\n",
            "Epoch 308/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8630 - accuracy: 0.6765 - val_loss: 1.6266 - val_accuracy: 0.4459\n",
            "Epoch 309/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8728 - accuracy: 0.6567 - val_loss: 1.6274 - val_accuracy: 0.4380\n",
            "Epoch 310/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8120 - accuracy: 0.6889 - val_loss: 1.5957 - val_accuracy: 0.5066\n",
            "Epoch 311/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8328 - accuracy: 0.6816 - val_loss: 1.5803 - val_accuracy: 0.4855\n",
            "Epoch 312/1500\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 0.9224 - accuracy: 0.6708 - val_loss: 1.6676 - val_accuracy: 0.4406\n",
            "Epoch 313/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8425 - accuracy: 0.6883 - val_loss: 1.7695 - val_accuracy: 0.4354\n",
            "Epoch 314/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8317 - accuracy: 0.6946 - val_loss: 1.6039 - val_accuracy: 0.4565\n",
            "Epoch 315/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8293 - accuracy: 0.6838 - val_loss: 1.6908 - val_accuracy: 0.4749\n",
            "Epoch 316/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8432 - accuracy: 0.6833 - val_loss: 1.6693 - val_accuracy: 0.4485\n",
            "Epoch 317/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8745 - accuracy: 0.6736 - val_loss: 1.6038 - val_accuracy: 0.4723\n",
            "Epoch 318/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8261 - accuracy: 0.6991 - val_loss: 1.6544 - val_accuracy: 0.4828\n",
            "Epoch 319/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8518 - accuracy: 0.6816 - val_loss: 1.7760 - val_accuracy: 0.4433\n",
            "Epoch 320/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8361 - accuracy: 0.6889 - val_loss: 1.6172 - val_accuracy: 0.4960\n",
            "Epoch 321/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8644 - accuracy: 0.6708 - val_loss: 1.6726 - val_accuracy: 0.5040\n",
            "Epoch 322/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.9229 - accuracy: 0.6459 - val_loss: 1.6077 - val_accuracy: 0.4723\n",
            "Epoch 323/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8219 - accuracy: 0.6963 - val_loss: 1.6612 - val_accuracy: 0.4459\n",
            "Epoch 324/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.8377 - accuracy: 0.6900 - val_loss: 1.6656 - val_accuracy: 0.4828\n",
            "Epoch 325/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8247 - accuracy: 0.6906 - val_loss: 1.6912 - val_accuracy: 0.4960\n",
            "Epoch 326/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8471 - accuracy: 0.6957 - val_loss: 1.6375 - val_accuracy: 0.4828\n",
            "Epoch 327/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.8312 - accuracy: 0.6838 - val_loss: 1.6496 - val_accuracy: 0.4802\n",
            "Epoch 328/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8256 - accuracy: 0.6991 - val_loss: 1.7011 - val_accuracy: 0.4380\n",
            "Epoch 329/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7958 - accuracy: 0.7093 - val_loss: 1.7132 - val_accuracy: 0.4485\n",
            "Epoch 330/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8366 - accuracy: 0.6929 - val_loss: 1.8288 - val_accuracy: 0.4828\n",
            "Epoch 331/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8791 - accuracy: 0.6686 - val_loss: 1.6222 - val_accuracy: 0.4802\n",
            "Epoch 332/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.8245 - accuracy: 0.6974 - val_loss: 1.6150 - val_accuracy: 0.5145\n",
            "Epoch 333/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8417 - accuracy: 0.6850 - val_loss: 1.6418 - val_accuracy: 0.5119\n",
            "Epoch 334/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8552 - accuracy: 0.6855 - val_loss: 1.6836 - val_accuracy: 0.4512\n",
            "Epoch 335/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8616 - accuracy: 0.6838 - val_loss: 1.6071 - val_accuracy: 0.4617\n",
            "Epoch 336/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8325 - accuracy: 0.6833 - val_loss: 1.6698 - val_accuracy: 0.4881\n",
            "Epoch 337/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8555 - accuracy: 0.6652 - val_loss: 1.6219 - val_accuracy: 0.4960\n",
            "Epoch 338/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.7879 - accuracy: 0.6980 - val_loss: 1.7153 - val_accuracy: 0.4670\n",
            "Epoch 339/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8078 - accuracy: 0.7025 - val_loss: 1.7168 - val_accuracy: 0.4697\n",
            "Epoch 340/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8266 - accuracy: 0.6900 - val_loss: 1.7087 - val_accuracy: 0.4565\n",
            "Epoch 341/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7893 - accuracy: 0.6946 - val_loss: 1.7355 - val_accuracy: 0.4433\n",
            "Epoch 342/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8003 - accuracy: 0.7025 - val_loss: 1.6840 - val_accuracy: 0.4565\n",
            "Epoch 343/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8126 - accuracy: 0.6991 - val_loss: 1.7397 - val_accuracy: 0.4565\n",
            "Epoch 344/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8372 - accuracy: 0.6782 - val_loss: 1.6561 - val_accuracy: 0.4749\n",
            "Epoch 345/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7809 - accuracy: 0.6991 - val_loss: 1.6908 - val_accuracy: 0.4538\n",
            "Epoch 346/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8205 - accuracy: 0.6900 - val_loss: 1.6432 - val_accuracy: 0.5224\n",
            "Epoch 347/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8167 - accuracy: 0.6906 - val_loss: 1.7141 - val_accuracy: 0.4697\n",
            "Epoch 348/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7961 - accuracy: 0.7104 - val_loss: 1.7163 - val_accuracy: 0.5172\n",
            "Epoch 349/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8213 - accuracy: 0.6867 - val_loss: 1.7040 - val_accuracy: 0.4459\n",
            "Epoch 350/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7991 - accuracy: 0.7127 - val_loss: 1.7256 - val_accuracy: 0.4908\n",
            "Epoch 351/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7890 - accuracy: 0.7019 - val_loss: 1.7076 - val_accuracy: 0.4538\n",
            "Epoch 352/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7979 - accuracy: 0.7031 - val_loss: 1.6828 - val_accuracy: 0.4723\n",
            "Epoch 353/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7837 - accuracy: 0.7144 - val_loss: 1.8335 - val_accuracy: 0.4380\n",
            "Epoch 354/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7908 - accuracy: 0.6968 - val_loss: 1.9253 - val_accuracy: 0.4723\n",
            "Epoch 355/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8177 - accuracy: 0.6833 - val_loss: 1.7988 - val_accuracy: 0.4512\n",
            "Epoch 356/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8008 - accuracy: 0.7025 - val_loss: 1.7137 - val_accuracy: 0.4433\n",
            "Epoch 357/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8350 - accuracy: 0.6850 - val_loss: 1.7004 - val_accuracy: 0.4828\n",
            "Epoch 358/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7646 - accuracy: 0.7325 - val_loss: 1.7509 - val_accuracy: 0.4776\n",
            "Epoch 359/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7961 - accuracy: 0.7087 - val_loss: 1.8351 - val_accuracy: 0.4274\n",
            "Epoch 360/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7878 - accuracy: 0.7081 - val_loss: 1.7490 - val_accuracy: 0.4828\n",
            "Epoch 361/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8029 - accuracy: 0.7064 - val_loss: 1.8813 - val_accuracy: 0.4485\n",
            "Epoch 362/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8680 - accuracy: 0.6770 - val_loss: 1.7018 - val_accuracy: 0.4749\n",
            "Epoch 363/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7706 - accuracy: 0.7166 - val_loss: 1.7369 - val_accuracy: 0.5251\n",
            "Epoch 364/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.7898 - accuracy: 0.6946 - val_loss: 1.7413 - val_accuracy: 0.4485\n",
            "Epoch 365/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8169 - accuracy: 0.6804 - val_loss: 1.7954 - val_accuracy: 0.4802\n",
            "Epoch 366/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7905 - accuracy: 0.6951 - val_loss: 2.1149 - val_accuracy: 0.3826\n",
            "Epoch 367/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7884 - accuracy: 0.7098 - val_loss: 1.7131 - val_accuracy: 0.4512\n",
            "Epoch 368/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.7976 - accuracy: 0.7070 - val_loss: 1.7551 - val_accuracy: 0.4776\n",
            "Epoch 369/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7968 - accuracy: 0.7149 - val_loss: 1.8078 - val_accuracy: 0.4670\n",
            "Epoch 370/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8069 - accuracy: 0.7042 - val_loss: 1.7290 - val_accuracy: 0.5092\n",
            "Epoch 371/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8531 - accuracy: 0.6861 - val_loss: 1.7593 - val_accuracy: 0.4538\n",
            "Epoch 372/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7767 - accuracy: 0.7070 - val_loss: 1.9539 - val_accuracy: 0.4248\n",
            "Epoch 373/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7768 - accuracy: 0.7059 - val_loss: 1.6742 - val_accuracy: 0.4908\n",
            "Epoch 374/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7581 - accuracy: 0.7183 - val_loss: 1.7294 - val_accuracy: 0.4776\n",
            "Epoch 375/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7938 - accuracy: 0.6957 - val_loss: 1.7333 - val_accuracy: 0.4406\n",
            "Epoch 376/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7816 - accuracy: 0.7053 - val_loss: 1.6714 - val_accuracy: 0.5092\n",
            "Epoch 377/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7822 - accuracy: 0.7002 - val_loss: 1.8253 - val_accuracy: 0.5013\n",
            "Epoch 378/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7796 - accuracy: 0.7070 - val_loss: 1.7946 - val_accuracy: 0.4301\n",
            "Epoch 379/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7994 - accuracy: 0.7064 - val_loss: 1.7646 - val_accuracy: 0.4670\n",
            "Epoch 380/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7887 - accuracy: 0.7036 - val_loss: 1.7059 - val_accuracy: 0.4749\n",
            "Epoch 381/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7692 - accuracy: 0.7251 - val_loss: 1.8369 - val_accuracy: 0.4776\n",
            "Epoch 382/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7757 - accuracy: 0.7166 - val_loss: 1.6687 - val_accuracy: 0.4908\n",
            "Epoch 383/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7862 - accuracy: 0.7048 - val_loss: 1.7889 - val_accuracy: 0.4855\n",
            "Epoch 384/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7555 - accuracy: 0.7245 - val_loss: 1.7674 - val_accuracy: 0.5198\n",
            "Epoch 385/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7827 - accuracy: 0.7155 - val_loss: 1.8114 - val_accuracy: 0.4512\n",
            "Epoch 386/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7751 - accuracy: 0.7144 - val_loss: 1.6915 - val_accuracy: 0.4881\n",
            "Epoch 387/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7712 - accuracy: 0.7149 - val_loss: 1.8584 - val_accuracy: 0.4459\n",
            "Epoch 388/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7622 - accuracy: 0.7121 - val_loss: 1.8729 - val_accuracy: 0.4776\n",
            "Epoch 389/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7893 - accuracy: 0.7172 - val_loss: 1.6888 - val_accuracy: 0.4828\n",
            "Epoch 390/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7436 - accuracy: 0.7313 - val_loss: 1.7897 - val_accuracy: 0.4908\n",
            "Epoch 391/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7507 - accuracy: 0.7229 - val_loss: 1.6540 - val_accuracy: 0.5224\n",
            "Epoch 392/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7564 - accuracy: 0.7144 - val_loss: 1.9011 - val_accuracy: 0.4617\n",
            "Epoch 393/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7554 - accuracy: 0.7149 - val_loss: 1.7713 - val_accuracy: 0.4987\n",
            "Epoch 394/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7864 - accuracy: 0.7093 - val_loss: 1.8057 - val_accuracy: 0.4617\n",
            "Epoch 395/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7689 - accuracy: 0.7115 - val_loss: 1.9181 - val_accuracy: 0.4512\n",
            "Epoch 396/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7595 - accuracy: 0.7223 - val_loss: 1.7905 - val_accuracy: 0.4591\n",
            "Epoch 397/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7403 - accuracy: 0.7302 - val_loss: 1.7696 - val_accuracy: 0.4485\n",
            "Epoch 398/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7656 - accuracy: 0.7087 - val_loss: 1.7616 - val_accuracy: 0.4828\n",
            "Epoch 399/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7478 - accuracy: 0.7229 - val_loss: 1.9124 - val_accuracy: 0.4591\n",
            "Epoch 400/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7249 - accuracy: 0.7347 - val_loss: 1.7506 - val_accuracy: 0.4960\n",
            "Epoch 401/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7708 - accuracy: 0.7025 - val_loss: 1.6909 - val_accuracy: 0.5145\n",
            "Epoch 402/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7779 - accuracy: 0.7161 - val_loss: 1.8340 - val_accuracy: 0.4881\n",
            "Epoch 403/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7682 - accuracy: 0.7115 - val_loss: 1.7474 - val_accuracy: 0.4855\n",
            "Epoch 404/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8184 - accuracy: 0.7042 - val_loss: 1.7079 - val_accuracy: 0.4855\n",
            "Epoch 405/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7282 - accuracy: 0.7308 - val_loss: 1.9718 - val_accuracy: 0.4565\n",
            "Epoch 406/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7599 - accuracy: 0.7138 - val_loss: 1.8384 - val_accuracy: 0.4538\n",
            "Epoch 407/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.8033 - accuracy: 0.6991 - val_loss: 1.8034 - val_accuracy: 0.4459\n",
            "Epoch 408/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7532 - accuracy: 0.7240 - val_loss: 1.7415 - val_accuracy: 0.4406\n",
            "Epoch 409/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7469 - accuracy: 0.7138 - val_loss: 1.7751 - val_accuracy: 0.4934\n",
            "Epoch 410/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7185 - accuracy: 0.7302 - val_loss: 1.8624 - val_accuracy: 0.4644\n",
            "Epoch 411/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7266 - accuracy: 0.7313 - val_loss: 1.8178 - val_accuracy: 0.4697\n",
            "Epoch 412/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7389 - accuracy: 0.7257 - val_loss: 1.8753 - val_accuracy: 0.4934\n",
            "Epoch 413/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7277 - accuracy: 0.7308 - val_loss: 1.7965 - val_accuracy: 0.4987\n",
            "Epoch 414/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7675 - accuracy: 0.7166 - val_loss: 1.8092 - val_accuracy: 0.4881\n",
            "Epoch 415/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7700 - accuracy: 0.7155 - val_loss: 1.9036 - val_accuracy: 0.4670\n",
            "Epoch 416/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7381 - accuracy: 0.7172 - val_loss: 1.8087 - val_accuracy: 0.4934\n",
            "Epoch 417/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7017 - accuracy: 0.7443 - val_loss: 1.7730 - val_accuracy: 0.4776\n",
            "Epoch 418/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7064 - accuracy: 0.7330 - val_loss: 1.8054 - val_accuracy: 0.4644\n",
            "Epoch 419/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7551 - accuracy: 0.7121 - val_loss: 1.7481 - val_accuracy: 0.4881\n",
            "Epoch 420/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7109 - accuracy: 0.7421 - val_loss: 1.7750 - val_accuracy: 0.4776\n",
            "Epoch 421/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7334 - accuracy: 0.7262 - val_loss: 1.7159 - val_accuracy: 0.4960\n",
            "Epoch 422/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7260 - accuracy: 0.7364 - val_loss: 1.7861 - val_accuracy: 0.4960\n",
            "Epoch 423/1500\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 0.7331 - accuracy: 0.7291 - val_loss: 1.7690 - val_accuracy: 0.4855\n",
            "Epoch 424/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7366 - accuracy: 0.7359 - val_loss: 1.7874 - val_accuracy: 0.4723\n",
            "Epoch 425/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7712 - accuracy: 0.7064 - val_loss: 1.7495 - val_accuracy: 0.5092\n",
            "Epoch 426/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7197 - accuracy: 0.7449 - val_loss: 1.8703 - val_accuracy: 0.4538\n",
            "Epoch 427/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7793 - accuracy: 0.7048 - val_loss: 1.9852 - val_accuracy: 0.4485\n",
            "Epoch 428/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7954 - accuracy: 0.6985 - val_loss: 1.9438 - val_accuracy: 0.4802\n",
            "Epoch 429/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7540 - accuracy: 0.7200 - val_loss: 1.7339 - val_accuracy: 0.4960\n",
            "Epoch 430/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7174 - accuracy: 0.7443 - val_loss: 1.8329 - val_accuracy: 0.5092\n",
            "Epoch 431/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7507 - accuracy: 0.7223 - val_loss: 1.7562 - val_accuracy: 0.4908\n",
            "Epoch 432/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7645 - accuracy: 0.7189 - val_loss: 1.8127 - val_accuracy: 0.4934\n",
            "Epoch 433/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7107 - accuracy: 0.7370 - val_loss: 1.8166 - val_accuracy: 0.4565\n",
            "Epoch 434/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7035 - accuracy: 0.7404 - val_loss: 1.8111 - val_accuracy: 0.5040\n",
            "Epoch 435/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7384 - accuracy: 0.7274 - val_loss: 1.7930 - val_accuracy: 0.4591\n",
            "Epoch 436/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7231 - accuracy: 0.7353 - val_loss: 1.7897 - val_accuracy: 0.4828\n",
            "Epoch 437/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7103 - accuracy: 0.7449 - val_loss: 1.9531 - val_accuracy: 0.4960\n",
            "Epoch 438/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7109 - accuracy: 0.7342 - val_loss: 1.9559 - val_accuracy: 0.4459\n",
            "Epoch 439/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7259 - accuracy: 0.7398 - val_loss: 2.0198 - val_accuracy: 0.4644\n",
            "Epoch 440/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7344 - accuracy: 0.7223 - val_loss: 1.8550 - val_accuracy: 0.4908\n",
            "Epoch 441/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7321 - accuracy: 0.7336 - val_loss: 1.9851 - val_accuracy: 0.4248\n",
            "Epoch 442/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.7331 - accuracy: 0.7336 - val_loss: 1.8350 - val_accuracy: 0.5092\n",
            "Epoch 443/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7209 - accuracy: 0.7404 - val_loss: 2.0201 - val_accuracy: 0.4327\n",
            "Epoch 444/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7377 - accuracy: 0.7240 - val_loss: 1.8299 - val_accuracy: 0.4723\n",
            "Epoch 445/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6964 - accuracy: 0.7410 - val_loss: 1.8161 - val_accuracy: 0.4828\n",
            "Epoch 446/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6889 - accuracy: 0.7534 - val_loss: 1.7877 - val_accuracy: 0.4828\n",
            "Epoch 447/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7097 - accuracy: 0.7557 - val_loss: 1.8186 - val_accuracy: 0.4881\n",
            "Epoch 448/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7027 - accuracy: 0.7472 - val_loss: 1.7987 - val_accuracy: 0.4697\n",
            "Epoch 449/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7765 - accuracy: 0.7008 - val_loss: 1.9001 - val_accuracy: 0.4406\n",
            "Epoch 450/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7125 - accuracy: 0.7330 - val_loss: 1.8356 - val_accuracy: 0.5198\n",
            "Epoch 451/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7407 - accuracy: 0.7330 - val_loss: 1.9565 - val_accuracy: 0.4538\n",
            "Epoch 452/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7200 - accuracy: 0.7410 - val_loss: 1.9158 - val_accuracy: 0.4459\n",
            "Epoch 453/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7425 - accuracy: 0.7195 - val_loss: 1.8490 - val_accuracy: 0.4855\n",
            "Epoch 454/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7363 - accuracy: 0.7268 - val_loss: 1.8750 - val_accuracy: 0.4881\n",
            "Epoch 455/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7057 - accuracy: 0.7347 - val_loss: 1.8241 - val_accuracy: 0.4934\n",
            "Epoch 456/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7045 - accuracy: 0.7443 - val_loss: 1.8471 - val_accuracy: 0.4855\n",
            "Epoch 457/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6793 - accuracy: 0.7534 - val_loss: 1.8780 - val_accuracy: 0.4644\n",
            "Epoch 458/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7327 - accuracy: 0.7296 - val_loss: 1.8669 - val_accuracy: 0.4934\n",
            "Epoch 459/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6792 - accuracy: 0.7489 - val_loss: 2.0254 - val_accuracy: 0.4433\n",
            "Epoch 460/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6834 - accuracy: 0.7534 - val_loss: 1.8824 - val_accuracy: 0.4855\n",
            "Epoch 461/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7013 - accuracy: 0.7528 - val_loss: 1.9912 - val_accuracy: 0.4908\n",
            "Epoch 462/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7360 - accuracy: 0.7325 - val_loss: 1.8816 - val_accuracy: 0.4987\n",
            "Epoch 463/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7161 - accuracy: 0.7426 - val_loss: 1.8218 - val_accuracy: 0.4987\n",
            "Epoch 464/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7020 - accuracy: 0.7342 - val_loss: 1.7882 - val_accuracy: 0.5013\n",
            "Epoch 465/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7236 - accuracy: 0.7234 - val_loss: 1.8168 - val_accuracy: 0.4908\n",
            "Epoch 466/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6766 - accuracy: 0.7613 - val_loss: 1.8103 - val_accuracy: 0.5066\n",
            "Epoch 467/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6726 - accuracy: 0.7568 - val_loss: 1.8230 - val_accuracy: 0.4670\n",
            "Epoch 468/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6853 - accuracy: 0.7494 - val_loss: 1.8334 - val_accuracy: 0.4828\n",
            "Epoch 469/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6768 - accuracy: 0.7607 - val_loss: 1.9011 - val_accuracy: 0.4855\n",
            "Epoch 470/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6808 - accuracy: 0.7523 - val_loss: 2.2005 - val_accuracy: 0.4301\n",
            "Epoch 471/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7578 - accuracy: 0.7189 - val_loss: 2.0124 - val_accuracy: 0.4538\n",
            "Epoch 472/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7718 - accuracy: 0.7144 - val_loss: 1.8318 - val_accuracy: 0.4565\n",
            "Epoch 473/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7273 - accuracy: 0.7274 - val_loss: 2.1822 - val_accuracy: 0.4301\n",
            "Epoch 474/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7155 - accuracy: 0.7381 - val_loss: 1.9491 - val_accuracy: 0.4433\n",
            "Epoch 475/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6997 - accuracy: 0.7359 - val_loss: 1.9459 - val_accuracy: 0.4855\n",
            "Epoch 476/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7146 - accuracy: 0.7347 - val_loss: 1.9391 - val_accuracy: 0.4828\n",
            "Epoch 477/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6742 - accuracy: 0.7477 - val_loss: 2.0423 - val_accuracy: 0.4380\n",
            "Epoch 478/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6955 - accuracy: 0.7353 - val_loss: 1.8531 - val_accuracy: 0.5066\n",
            "Epoch 479/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6959 - accuracy: 0.7545 - val_loss: 1.9148 - val_accuracy: 0.4644\n",
            "Epoch 480/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6718 - accuracy: 0.7534 - val_loss: 1.8894 - val_accuracy: 0.4723\n",
            "Epoch 481/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7001 - accuracy: 0.7410 - val_loss: 1.8668 - val_accuracy: 0.4776\n",
            "Epoch 482/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7036 - accuracy: 0.7404 - val_loss: 1.9081 - val_accuracy: 0.4670\n",
            "Epoch 483/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7158 - accuracy: 0.7296 - val_loss: 1.8280 - val_accuracy: 0.5145\n",
            "Epoch 484/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6702 - accuracy: 0.7540 - val_loss: 1.8291 - val_accuracy: 0.5066\n",
            "Epoch 485/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6882 - accuracy: 0.7421 - val_loss: 1.9289 - val_accuracy: 0.4828\n",
            "Epoch 486/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7121 - accuracy: 0.7410 - val_loss: 1.8189 - val_accuracy: 0.5066\n",
            "Epoch 487/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6732 - accuracy: 0.7477 - val_loss: 1.8354 - val_accuracy: 0.5172\n",
            "Epoch 488/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6409 - accuracy: 0.7596 - val_loss: 1.8455 - val_accuracy: 0.4828\n",
            "Epoch 489/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6702 - accuracy: 0.7528 - val_loss: 1.8499 - val_accuracy: 0.4855\n",
            "Epoch 490/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6566 - accuracy: 0.7726 - val_loss: 1.9016 - val_accuracy: 0.4538\n",
            "Epoch 491/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6636 - accuracy: 0.7562 - val_loss: 1.9129 - val_accuracy: 0.4459\n",
            "Epoch 492/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6518 - accuracy: 0.7602 - val_loss: 1.9070 - val_accuracy: 0.4644\n",
            "Epoch 493/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.6382 - accuracy: 0.7760 - val_loss: 1.9274 - val_accuracy: 0.4934\n",
            "Epoch 494/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6702 - accuracy: 0.7619 - val_loss: 1.9440 - val_accuracy: 0.4591\n",
            "Epoch 495/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6645 - accuracy: 0.7534 - val_loss: 2.0374 - val_accuracy: 0.4459\n",
            "Epoch 496/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6591 - accuracy: 0.7636 - val_loss: 2.0715 - val_accuracy: 0.4459\n",
            "Epoch 497/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7006 - accuracy: 0.7590 - val_loss: 1.9431 - val_accuracy: 0.4987\n",
            "Epoch 498/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6645 - accuracy: 0.7551 - val_loss: 1.9983 - val_accuracy: 0.4881\n",
            "Epoch 499/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6712 - accuracy: 0.7500 - val_loss: 2.0061 - val_accuracy: 0.4433\n",
            "Epoch 500/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6990 - accuracy: 0.7528 - val_loss: 1.8987 - val_accuracy: 0.4881\n",
            "Epoch 501/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6253 - accuracy: 0.7907 - val_loss: 2.0715 - val_accuracy: 0.4301\n",
            "Epoch 502/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6440 - accuracy: 0.7670 - val_loss: 1.8846 - val_accuracy: 0.4881\n",
            "Epoch 503/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7121 - accuracy: 0.7325 - val_loss: 2.0386 - val_accuracy: 0.4591\n",
            "Epoch 504/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6842 - accuracy: 0.7511 - val_loss: 2.2740 - val_accuracy: 0.4802\n",
            "Epoch 505/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7148 - accuracy: 0.7455 - val_loss: 1.9483 - val_accuracy: 0.4855\n",
            "Epoch 506/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6805 - accuracy: 0.7466 - val_loss: 1.8678 - val_accuracy: 0.5066\n",
            "Epoch 507/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6631 - accuracy: 0.7551 - val_loss: 1.9703 - val_accuracy: 0.4881\n",
            "Epoch 508/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6572 - accuracy: 0.7590 - val_loss: 2.0432 - val_accuracy: 0.4591\n",
            "Epoch 509/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6463 - accuracy: 0.7692 - val_loss: 2.0508 - val_accuracy: 0.4485\n",
            "Epoch 510/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7020 - accuracy: 0.7449 - val_loss: 1.9032 - val_accuracy: 0.5013\n",
            "Epoch 511/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6681 - accuracy: 0.7511 - val_loss: 1.9133 - val_accuracy: 0.4908\n",
            "Epoch 512/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6599 - accuracy: 0.7590 - val_loss: 2.0342 - val_accuracy: 0.4776\n",
            "Epoch 513/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6722 - accuracy: 0.7551 - val_loss: 1.9127 - val_accuracy: 0.5040\n",
            "Epoch 514/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6602 - accuracy: 0.7540 - val_loss: 1.9315 - val_accuracy: 0.5172\n",
            "Epoch 515/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6405 - accuracy: 0.7698 - val_loss: 1.8861 - val_accuracy: 0.4828\n",
            "Epoch 516/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6245 - accuracy: 0.7732 - val_loss: 1.9053 - val_accuracy: 0.5092\n",
            "Epoch 517/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6491 - accuracy: 0.7619 - val_loss: 1.9118 - val_accuracy: 0.5092\n",
            "Epoch 518/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6339 - accuracy: 0.7687 - val_loss: 1.9530 - val_accuracy: 0.5172\n",
            "Epoch 519/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6573 - accuracy: 0.7675 - val_loss: 1.9859 - val_accuracy: 0.4485\n",
            "Epoch 520/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6552 - accuracy: 0.7619 - val_loss: 1.8830 - val_accuracy: 0.4987\n",
            "Epoch 521/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6448 - accuracy: 0.7607 - val_loss: 2.1032 - val_accuracy: 0.4485\n",
            "Epoch 522/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6241 - accuracy: 0.7828 - val_loss: 1.9672 - val_accuracy: 0.5066\n",
            "Epoch 523/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6556 - accuracy: 0.7590 - val_loss: 1.9379 - val_accuracy: 0.4670\n",
            "Epoch 524/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6604 - accuracy: 0.7511 - val_loss: 1.9398 - val_accuracy: 0.4538\n",
            "Epoch 525/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6164 - accuracy: 0.7687 - val_loss: 2.2167 - val_accuracy: 0.4433\n",
            "Epoch 526/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7049 - accuracy: 0.7381 - val_loss: 1.9114 - val_accuracy: 0.4960\n",
            "Epoch 527/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.6497 - accuracy: 0.7687 - val_loss: 1.9735 - val_accuracy: 0.4776\n",
            "Epoch 528/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6297 - accuracy: 0.7698 - val_loss: 1.9316 - val_accuracy: 0.4802\n",
            "Epoch 529/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6217 - accuracy: 0.7805 - val_loss: 2.0294 - val_accuracy: 0.4934\n",
            "Epoch 530/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6313 - accuracy: 0.7715 - val_loss: 1.9755 - val_accuracy: 0.5013\n",
            "Epoch 531/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6176 - accuracy: 0.7760 - val_loss: 1.9870 - val_accuracy: 0.4776\n",
            "Epoch 532/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6800 - accuracy: 0.7574 - val_loss: 2.0123 - val_accuracy: 0.5198\n",
            "Epoch 533/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6102 - accuracy: 0.7783 - val_loss: 2.1993 - val_accuracy: 0.4670\n",
            "Epoch 534/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6687 - accuracy: 0.7489 - val_loss: 1.9035 - val_accuracy: 0.4960\n",
            "Epoch 535/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6559 - accuracy: 0.7675 - val_loss: 1.9082 - val_accuracy: 0.5092\n",
            "Epoch 536/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6123 - accuracy: 0.7811 - val_loss: 2.0806 - val_accuracy: 0.4697\n",
            "Epoch 537/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6344 - accuracy: 0.7681 - val_loss: 1.9275 - val_accuracy: 0.5119\n",
            "Epoch 538/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6672 - accuracy: 0.7596 - val_loss: 1.9457 - val_accuracy: 0.5013\n",
            "Epoch 539/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6389 - accuracy: 0.7709 - val_loss: 2.0102 - val_accuracy: 0.4776\n",
            "Epoch 540/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6338 - accuracy: 0.7771 - val_loss: 1.9618 - val_accuracy: 0.5040\n",
            "Epoch 541/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6272 - accuracy: 0.7766 - val_loss: 2.1783 - val_accuracy: 0.4327\n",
            "Epoch 542/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6147 - accuracy: 0.7834 - val_loss: 1.9877 - val_accuracy: 0.4908\n",
            "Epoch 543/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5905 - accuracy: 0.7907 - val_loss: 2.0367 - val_accuracy: 0.5092\n",
            "Epoch 544/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6430 - accuracy: 0.7607 - val_loss: 2.1699 - val_accuracy: 0.4380\n",
            "Epoch 545/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6496 - accuracy: 0.7749 - val_loss: 1.9289 - val_accuracy: 0.4749\n",
            "Epoch 546/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6250 - accuracy: 0.7766 - val_loss: 2.0266 - val_accuracy: 0.4828\n",
            "Epoch 547/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6734 - accuracy: 0.7500 - val_loss: 1.9693 - val_accuracy: 0.4934\n",
            "Epoch 548/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6426 - accuracy: 0.7624 - val_loss: 2.1509 - val_accuracy: 0.4354\n",
            "Epoch 549/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6347 - accuracy: 0.7647 - val_loss: 2.0184 - val_accuracy: 0.4723\n",
            "Epoch 550/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.6728 - accuracy: 0.7551 - val_loss: 1.9985 - val_accuracy: 0.4855\n",
            "Epoch 551/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6127 - accuracy: 0.7856 - val_loss: 1.9784 - val_accuracy: 0.4828\n",
            "Epoch 552/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6211 - accuracy: 0.7822 - val_loss: 1.9034 - val_accuracy: 0.5066\n",
            "Epoch 553/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6130 - accuracy: 0.7822 - val_loss: 2.1812 - val_accuracy: 0.4406\n",
            "Epoch 554/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6416 - accuracy: 0.7726 - val_loss: 1.9315 - val_accuracy: 0.4934\n",
            "Epoch 555/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6158 - accuracy: 0.7715 - val_loss: 2.0569 - val_accuracy: 0.4538\n",
            "Epoch 556/1500\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 0.6200 - accuracy: 0.7738 - val_loss: 2.2470 - val_accuracy: 0.5040\n",
            "Epoch 557/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6526 - accuracy: 0.7590 - val_loss: 1.9998 - val_accuracy: 0.4881\n",
            "Epoch 558/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6583 - accuracy: 0.7579 - val_loss: 1.9938 - val_accuracy: 0.4881\n",
            "Epoch 559/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6318 - accuracy: 0.7596 - val_loss: 2.3519 - val_accuracy: 0.4459\n",
            "Epoch 560/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6716 - accuracy: 0.7574 - val_loss: 1.9650 - val_accuracy: 0.5013\n",
            "Epoch 561/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.6052 - accuracy: 0.7839 - val_loss: 2.0016 - val_accuracy: 0.4855\n",
            "Epoch 562/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5890 - accuracy: 0.7879 - val_loss: 2.0192 - val_accuracy: 0.4934\n",
            "Epoch 563/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6424 - accuracy: 0.7624 - val_loss: 2.0448 - val_accuracy: 0.4617\n",
            "Epoch 564/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6213 - accuracy: 0.7675 - val_loss: 2.0360 - val_accuracy: 0.4670\n",
            "Epoch 565/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6145 - accuracy: 0.7851 - val_loss: 2.0374 - val_accuracy: 0.4776\n",
            "Epoch 566/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5964 - accuracy: 0.7839 - val_loss: 2.0249 - val_accuracy: 0.4908\n",
            "Epoch 567/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5864 - accuracy: 0.7941 - val_loss: 2.1168 - val_accuracy: 0.4776\n",
            "Epoch 568/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5816 - accuracy: 0.7856 - val_loss: 2.1114 - val_accuracy: 0.4934\n",
            "Epoch 569/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6391 - accuracy: 0.7681 - val_loss: 2.0320 - val_accuracy: 0.5040\n",
            "Epoch 570/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6111 - accuracy: 0.7749 - val_loss: 2.1274 - val_accuracy: 0.4776\n",
            "Epoch 571/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6057 - accuracy: 0.7856 - val_loss: 2.1585 - val_accuracy: 0.4670\n",
            "Epoch 572/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6745 - accuracy: 0.7410 - val_loss: 2.1841 - val_accuracy: 0.4617\n",
            "Epoch 573/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6006 - accuracy: 0.7896 - val_loss: 1.9979 - val_accuracy: 0.5092\n",
            "Epoch 574/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5891 - accuracy: 0.7992 - val_loss: 2.0147 - val_accuracy: 0.5198\n",
            "Epoch 575/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6224 - accuracy: 0.7607 - val_loss: 1.9730 - val_accuracy: 0.4855\n",
            "Epoch 576/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5873 - accuracy: 0.7839 - val_loss: 2.0244 - val_accuracy: 0.4908\n",
            "Epoch 577/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6090 - accuracy: 0.7817 - val_loss: 2.0016 - val_accuracy: 0.5145\n",
            "Epoch 578/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.5887 - accuracy: 0.7862 - val_loss: 2.0631 - val_accuracy: 0.4802\n",
            "Epoch 579/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6007 - accuracy: 0.7760 - val_loss: 2.0944 - val_accuracy: 0.4855\n",
            "Epoch 580/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6401 - accuracy: 0.7647 - val_loss: 2.0140 - val_accuracy: 0.5013\n",
            "Epoch 581/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6517 - accuracy: 0.7596 - val_loss: 2.0340 - val_accuracy: 0.4855\n",
            "Epoch 582/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6017 - accuracy: 0.7839 - val_loss: 1.9871 - val_accuracy: 0.5040\n",
            "Epoch 583/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6125 - accuracy: 0.7788 - val_loss: 2.1002 - val_accuracy: 0.4776\n",
            "Epoch 584/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6762 - accuracy: 0.7393 - val_loss: 2.0858 - val_accuracy: 0.4723\n",
            "Epoch 585/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6458 - accuracy: 0.7562 - val_loss: 2.0008 - val_accuracy: 0.5066\n",
            "Epoch 586/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6308 - accuracy: 0.7630 - val_loss: 2.1722 - val_accuracy: 0.4697\n",
            "Epoch 587/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5954 - accuracy: 0.7828 - val_loss: 2.0390 - val_accuracy: 0.4776\n",
            "Epoch 588/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6182 - accuracy: 0.7658 - val_loss: 2.3617 - val_accuracy: 0.4433\n",
            "Epoch 589/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6330 - accuracy: 0.7664 - val_loss: 2.0567 - val_accuracy: 0.4802\n",
            "Epoch 590/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6138 - accuracy: 0.7794 - val_loss: 2.0646 - val_accuracy: 0.4987\n",
            "Epoch 591/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5986 - accuracy: 0.7856 - val_loss: 2.0148 - val_accuracy: 0.4855\n",
            "Epoch 592/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5934 - accuracy: 0.7896 - val_loss: 2.1228 - val_accuracy: 0.5040\n",
            "Epoch 593/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5843 - accuracy: 0.7913 - val_loss: 2.0198 - val_accuracy: 0.4960\n",
            "Epoch 594/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5492 - accuracy: 0.8003 - val_loss: 2.0600 - val_accuracy: 0.4934\n",
            "Epoch 595/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5858 - accuracy: 0.7862 - val_loss: 2.0907 - val_accuracy: 0.5013\n",
            "Epoch 596/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5589 - accuracy: 0.8003 - val_loss: 1.9849 - val_accuracy: 0.4908\n",
            "Epoch 597/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5976 - accuracy: 0.7738 - val_loss: 2.2430 - val_accuracy: 0.4538\n",
            "Epoch 598/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6235 - accuracy: 0.7670 - val_loss: 2.1076 - val_accuracy: 0.4591\n",
            "Epoch 599/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5809 - accuracy: 0.7913 - val_loss: 2.0702 - val_accuracy: 0.4855\n",
            "Epoch 600/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5846 - accuracy: 0.7885 - val_loss: 2.0635 - val_accuracy: 0.4987\n",
            "Epoch 601/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5680 - accuracy: 0.7913 - val_loss: 2.1121 - val_accuracy: 0.4670\n",
            "Epoch 602/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.5875 - accuracy: 0.7981 - val_loss: 2.2130 - val_accuracy: 0.4723\n",
            "Epoch 603/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6022 - accuracy: 0.7783 - val_loss: 2.0411 - val_accuracy: 0.5013\n",
            "Epoch 604/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5719 - accuracy: 0.8020 - val_loss: 2.0065 - val_accuracy: 0.5040\n",
            "Epoch 605/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5394 - accuracy: 0.8105 - val_loss: 2.1731 - val_accuracy: 0.4617\n",
            "Epoch 606/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6246 - accuracy: 0.7755 - val_loss: 2.0412 - val_accuracy: 0.5251\n",
            "Epoch 607/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6078 - accuracy: 0.7851 - val_loss: 2.0842 - val_accuracy: 0.5119\n",
            "Epoch 608/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6169 - accuracy: 0.7721 - val_loss: 2.1119 - val_accuracy: 0.4987\n",
            "Epoch 609/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5960 - accuracy: 0.7794 - val_loss: 2.0327 - val_accuracy: 0.5119\n",
            "Epoch 610/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6167 - accuracy: 0.7766 - val_loss: 2.1834 - val_accuracy: 0.4776\n",
            "Epoch 611/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6410 - accuracy: 0.7636 - val_loss: 2.2423 - val_accuracy: 0.4380\n",
            "Epoch 612/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6279 - accuracy: 0.7687 - val_loss: 2.1216 - val_accuracy: 0.4749\n",
            "Epoch 613/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5776 - accuracy: 0.7868 - val_loss: 2.0746 - val_accuracy: 0.4749\n",
            "Epoch 614/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5397 - accuracy: 0.8026 - val_loss: 2.2180 - val_accuracy: 0.4591\n",
            "Epoch 615/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5571 - accuracy: 0.7964 - val_loss: 2.2375 - val_accuracy: 0.4960\n",
            "Epoch 616/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5567 - accuracy: 0.8094 - val_loss: 2.0422 - val_accuracy: 0.5092\n",
            "Epoch 617/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5799 - accuracy: 0.7896 - val_loss: 2.1370 - val_accuracy: 0.4591\n",
            "Epoch 618/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5873 - accuracy: 0.7873 - val_loss: 2.1771 - val_accuracy: 0.5066\n",
            "Epoch 619/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5757 - accuracy: 0.7907 - val_loss: 2.1344 - val_accuracy: 0.4828\n",
            "Epoch 620/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5958 - accuracy: 0.7788 - val_loss: 2.1534 - val_accuracy: 0.5013\n",
            "Epoch 621/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5839 - accuracy: 0.7907 - val_loss: 2.2956 - val_accuracy: 0.4749\n",
            "Epoch 622/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6026 - accuracy: 0.7834 - val_loss: 2.0649 - val_accuracy: 0.4934\n",
            "Epoch 623/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.6014 - accuracy: 0.7777 - val_loss: 2.1549 - val_accuracy: 0.4802\n",
            "Epoch 624/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5527 - accuracy: 0.8105 - val_loss: 2.3030 - val_accuracy: 0.4512\n",
            "Epoch 625/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6480 - accuracy: 0.7658 - val_loss: 2.1251 - val_accuracy: 0.4617\n",
            "Epoch 626/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5790 - accuracy: 0.7868 - val_loss: 2.1360 - val_accuracy: 0.5145\n",
            "Epoch 627/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5850 - accuracy: 0.7936 - val_loss: 2.1178 - val_accuracy: 0.4934\n",
            "Epoch 628/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5508 - accuracy: 0.8026 - val_loss: 2.2078 - val_accuracy: 0.4644\n",
            "Epoch 629/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5716 - accuracy: 0.7828 - val_loss: 2.1701 - val_accuracy: 0.4802\n",
            "Epoch 630/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5786 - accuracy: 0.7890 - val_loss: 2.1051 - val_accuracy: 0.4855\n",
            "Epoch 631/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5494 - accuracy: 0.8003 - val_loss: 2.2090 - val_accuracy: 0.4617\n",
            "Epoch 632/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5785 - accuracy: 0.7896 - val_loss: 2.1266 - val_accuracy: 0.5092\n",
            "Epoch 633/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5617 - accuracy: 0.7969 - val_loss: 2.1804 - val_accuracy: 0.4960\n",
            "Epoch 634/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5648 - accuracy: 0.7851 - val_loss: 2.1675 - val_accuracy: 0.4697\n",
            "Epoch 635/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5619 - accuracy: 0.7986 - val_loss: 2.0674 - val_accuracy: 0.4934\n",
            "Epoch 636/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5858 - accuracy: 0.7851 - val_loss: 2.3349 - val_accuracy: 0.4301\n",
            "Epoch 637/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6413 - accuracy: 0.7658 - val_loss: 2.0910 - val_accuracy: 0.4908\n",
            "Epoch 638/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5467 - accuracy: 0.8077 - val_loss: 2.0863 - val_accuracy: 0.4802\n",
            "Epoch 639/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5274 - accuracy: 0.8105 - val_loss: 2.1943 - val_accuracy: 0.4960\n",
            "Epoch 640/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5449 - accuracy: 0.8100 - val_loss: 2.1373 - val_accuracy: 0.4802\n",
            "Epoch 641/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5366 - accuracy: 0.8026 - val_loss: 2.1635 - val_accuracy: 0.5092\n",
            "Epoch 642/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5838 - accuracy: 0.7941 - val_loss: 2.2336 - val_accuracy: 0.5066\n",
            "Epoch 643/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5523 - accuracy: 0.8077 - val_loss: 2.2619 - val_accuracy: 0.4723\n",
            "Epoch 644/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5963 - accuracy: 0.7805 - val_loss: 2.1906 - val_accuracy: 0.4934\n",
            "Epoch 645/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5367 - accuracy: 0.8156 - val_loss: 2.2652 - val_accuracy: 0.4855\n",
            "Epoch 646/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5945 - accuracy: 0.7856 - val_loss: 2.2394 - val_accuracy: 0.4881\n",
            "Epoch 647/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6032 - accuracy: 0.7766 - val_loss: 2.1361 - val_accuracy: 0.4908\n",
            "Epoch 648/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5854 - accuracy: 0.7851 - val_loss: 2.0704 - val_accuracy: 0.5251\n",
            "Epoch 649/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5624 - accuracy: 0.7919 - val_loss: 2.1325 - val_accuracy: 0.5013\n",
            "Epoch 650/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5495 - accuracy: 0.7969 - val_loss: 2.1807 - val_accuracy: 0.5119\n",
            "Epoch 651/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5710 - accuracy: 0.7868 - val_loss: 2.0832 - val_accuracy: 0.5145\n",
            "Epoch 652/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5282 - accuracy: 0.8100 - val_loss: 2.3021 - val_accuracy: 0.4591\n",
            "Epoch 653/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5650 - accuracy: 0.7958 - val_loss: 2.2228 - val_accuracy: 0.4881\n",
            "Epoch 654/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5912 - accuracy: 0.7930 - val_loss: 2.1750 - val_accuracy: 0.5013\n",
            "Epoch 655/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.5569 - accuracy: 0.8020 - val_loss: 2.2691 - val_accuracy: 0.4934\n",
            "Epoch 656/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5399 - accuracy: 0.7981 - val_loss: 2.2556 - val_accuracy: 0.4644\n",
            "Epoch 657/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5632 - accuracy: 0.7890 - val_loss: 2.1858 - val_accuracy: 0.4881\n",
            "Epoch 658/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5675 - accuracy: 0.7998 - val_loss: 2.2626 - val_accuracy: 0.4617\n",
            "Epoch 659/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5625 - accuracy: 0.7958 - val_loss: 2.2346 - val_accuracy: 0.5330\n",
            "Epoch 660/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6310 - accuracy: 0.7675 - val_loss: 2.2107 - val_accuracy: 0.4802\n",
            "Epoch 661/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5302 - accuracy: 0.8145 - val_loss: 2.2267 - val_accuracy: 0.4644\n",
            "Epoch 662/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5755 - accuracy: 0.8003 - val_loss: 2.1884 - val_accuracy: 0.5040\n",
            "Epoch 663/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5476 - accuracy: 0.8003 - val_loss: 2.2652 - val_accuracy: 0.4538\n",
            "Epoch 664/1500\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 0.5575 - accuracy: 0.8003 - val_loss: 2.3942 - val_accuracy: 0.4512\n",
            "Epoch 665/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5364 - accuracy: 0.8077 - val_loss: 2.1933 - val_accuracy: 0.4881\n",
            "Epoch 666/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6251 - accuracy: 0.7749 - val_loss: 2.2472 - val_accuracy: 0.5092\n",
            "Epoch 667/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5426 - accuracy: 0.8100 - val_loss: 2.2403 - val_accuracy: 0.4908\n",
            "Epoch 668/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5312 - accuracy: 0.8167 - val_loss: 2.1733 - val_accuracy: 0.5040\n",
            "Epoch 669/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5569 - accuracy: 0.7913 - val_loss: 2.0966 - val_accuracy: 0.5119\n",
            "Epoch 670/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5137 - accuracy: 0.8128 - val_loss: 2.2908 - val_accuracy: 0.4697\n",
            "Epoch 671/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5780 - accuracy: 0.7924 - val_loss: 2.2311 - val_accuracy: 0.4855\n",
            "Epoch 672/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5353 - accuracy: 0.8066 - val_loss: 2.1206 - val_accuracy: 0.5119\n",
            "Epoch 673/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5252 - accuracy: 0.8150 - val_loss: 2.4090 - val_accuracy: 0.4485\n",
            "Epoch 674/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5281 - accuracy: 0.8122 - val_loss: 2.2129 - val_accuracy: 0.4828\n",
            "Epoch 675/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5249 - accuracy: 0.8088 - val_loss: 2.2577 - val_accuracy: 0.4855\n",
            "Epoch 676/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5398 - accuracy: 0.8037 - val_loss: 2.3219 - val_accuracy: 0.4749\n",
            "Epoch 677/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5369 - accuracy: 0.8083 - val_loss: 2.1358 - val_accuracy: 0.5040\n",
            "Epoch 678/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5298 - accuracy: 0.7998 - val_loss: 2.2173 - val_accuracy: 0.5092\n",
            "Epoch 679/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5477 - accuracy: 0.7958 - val_loss: 2.1074 - val_accuracy: 0.5251\n",
            "Epoch 680/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5398 - accuracy: 0.8083 - val_loss: 2.4796 - val_accuracy: 0.4433\n",
            "Epoch 681/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5825 - accuracy: 0.7890 - val_loss: 2.2023 - val_accuracy: 0.4828\n",
            "Epoch 682/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5122 - accuracy: 0.8196 - val_loss: 2.2191 - val_accuracy: 0.4802\n",
            "Epoch 683/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5099 - accuracy: 0.8224 - val_loss: 2.3310 - val_accuracy: 0.4960\n",
            "Epoch 684/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5978 - accuracy: 0.7845 - val_loss: 2.4835 - val_accuracy: 0.5040\n",
            "Epoch 685/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5336 - accuracy: 0.8190 - val_loss: 2.2060 - val_accuracy: 0.5119\n",
            "Epoch 686/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5310 - accuracy: 0.8049 - val_loss: 2.3813 - val_accuracy: 0.4802\n",
            "Epoch 687/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5154 - accuracy: 0.8179 - val_loss: 2.2500 - val_accuracy: 0.5092\n",
            "Epoch 688/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5174 - accuracy: 0.8150 - val_loss: 2.3958 - val_accuracy: 0.4749\n",
            "Epoch 689/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5192 - accuracy: 0.8077 - val_loss: 2.2794 - val_accuracy: 0.4987\n",
            "Epoch 690/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5153 - accuracy: 0.8077 - val_loss: 2.2401 - val_accuracy: 0.4828\n",
            "Epoch 691/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5268 - accuracy: 0.8133 - val_loss: 2.1606 - val_accuracy: 0.5040\n",
            "Epoch 692/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5561 - accuracy: 0.7992 - val_loss: 2.7014 - val_accuracy: 0.4617\n",
            "Epoch 693/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5627 - accuracy: 0.7998 - val_loss: 2.3009 - val_accuracy: 0.4802\n",
            "Epoch 694/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5418 - accuracy: 0.7975 - val_loss: 2.2759 - val_accuracy: 0.4776\n",
            "Epoch 695/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5297 - accuracy: 0.8020 - val_loss: 2.2207 - val_accuracy: 0.4828\n",
            "Epoch 696/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5194 - accuracy: 0.8060 - val_loss: 2.1482 - val_accuracy: 0.4828\n",
            "Epoch 697/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5622 - accuracy: 0.7907 - val_loss: 2.2097 - val_accuracy: 0.5172\n",
            "Epoch 698/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5387 - accuracy: 0.8049 - val_loss: 2.3797 - val_accuracy: 0.4828\n",
            "Epoch 699/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5450 - accuracy: 0.8088 - val_loss: 2.2930 - val_accuracy: 0.5013\n",
            "Epoch 700/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5445 - accuracy: 0.8066 - val_loss: 2.2898 - val_accuracy: 0.4960\n",
            "Epoch 701/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5118 - accuracy: 0.8100 - val_loss: 2.5749 - val_accuracy: 0.4433\n",
            "Epoch 702/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5237 - accuracy: 0.8094 - val_loss: 2.3477 - val_accuracy: 0.5172\n",
            "Epoch 703/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5293 - accuracy: 0.8111 - val_loss: 2.4158 - val_accuracy: 0.4512\n",
            "Epoch 704/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5397 - accuracy: 0.8077 - val_loss: 2.2411 - val_accuracy: 0.5198\n",
            "Epoch 705/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5126 - accuracy: 0.8167 - val_loss: 2.3174 - val_accuracy: 0.5013\n",
            "Epoch 706/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5179 - accuracy: 0.8117 - val_loss: 2.2765 - val_accuracy: 0.4749\n",
            "Epoch 707/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6094 - accuracy: 0.7704 - val_loss: 2.1878 - val_accuracy: 0.4960\n",
            "Epoch 708/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4845 - accuracy: 0.8326 - val_loss: 2.2961 - val_accuracy: 0.4934\n",
            "Epoch 709/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5471 - accuracy: 0.8020 - val_loss: 2.2839 - val_accuracy: 0.4828\n",
            "Epoch 710/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5569 - accuracy: 0.7907 - val_loss: 2.3602 - val_accuracy: 0.4828\n",
            "Epoch 711/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5042 - accuracy: 0.8213 - val_loss: 2.4603 - val_accuracy: 0.4670\n",
            "Epoch 712/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4963 - accuracy: 0.8264 - val_loss: 2.2862 - val_accuracy: 0.4960\n",
            "Epoch 713/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4938 - accuracy: 0.8264 - val_loss: 2.3486 - val_accuracy: 0.5040\n",
            "Epoch 714/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4943 - accuracy: 0.8201 - val_loss: 2.3467 - val_accuracy: 0.4749\n",
            "Epoch 715/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.5557 - accuracy: 0.8049 - val_loss: 2.2965 - val_accuracy: 0.4538\n",
            "Epoch 716/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5493 - accuracy: 0.8015 - val_loss: 2.3941 - val_accuracy: 0.4828\n",
            "Epoch 717/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5297 - accuracy: 0.8077 - val_loss: 2.2442 - val_accuracy: 0.5251\n",
            "Epoch 718/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5104 - accuracy: 0.8241 - val_loss: 2.3690 - val_accuracy: 0.4855\n",
            "Epoch 719/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5017 - accuracy: 0.8201 - val_loss: 2.3089 - val_accuracy: 0.5013\n",
            "Epoch 720/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4918 - accuracy: 0.8348 - val_loss: 2.3505 - val_accuracy: 0.4776\n",
            "Epoch 721/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5246 - accuracy: 0.8173 - val_loss: 2.6062 - val_accuracy: 0.4617\n",
            "Epoch 722/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5099 - accuracy: 0.8167 - val_loss: 2.3583 - val_accuracy: 0.4960\n",
            "Epoch 723/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4968 - accuracy: 0.8247 - val_loss: 2.3311 - val_accuracy: 0.4908\n",
            "Epoch 724/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5005 - accuracy: 0.8235 - val_loss: 2.3200 - val_accuracy: 0.4934\n",
            "Epoch 725/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4952 - accuracy: 0.8298 - val_loss: 2.3362 - val_accuracy: 0.5013\n",
            "Epoch 726/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5041 - accuracy: 0.8230 - val_loss: 2.3254 - val_accuracy: 0.4802\n",
            "Epoch 727/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5059 - accuracy: 0.8100 - val_loss: 2.3444 - val_accuracy: 0.4960\n",
            "Epoch 728/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5563 - accuracy: 0.7947 - val_loss: 2.3655 - val_accuracy: 0.4776\n",
            "Epoch 729/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5482 - accuracy: 0.7981 - val_loss: 2.6571 - val_accuracy: 0.4406\n",
            "Epoch 730/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5412 - accuracy: 0.8066 - val_loss: 2.2098 - val_accuracy: 0.5356\n",
            "Epoch 731/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5111 - accuracy: 0.8235 - val_loss: 2.3972 - val_accuracy: 0.4776\n",
            "Epoch 732/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4935 - accuracy: 0.8235 - val_loss: 2.3655 - val_accuracy: 0.4960\n",
            "Epoch 733/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5204 - accuracy: 0.8139 - val_loss: 2.4911 - val_accuracy: 0.4512\n",
            "Epoch 734/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4976 - accuracy: 0.8275 - val_loss: 2.4401 - val_accuracy: 0.5040\n",
            "Epoch 735/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5041 - accuracy: 0.8128 - val_loss: 2.4235 - val_accuracy: 0.4776\n",
            "Epoch 736/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5044 - accuracy: 0.8117 - val_loss: 2.2991 - val_accuracy: 0.5013\n",
            "Epoch 737/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4767 - accuracy: 0.8269 - val_loss: 2.3054 - val_accuracy: 0.5224\n",
            "Epoch 738/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5358 - accuracy: 0.8032 - val_loss: 2.3385 - val_accuracy: 0.4908\n",
            "Epoch 739/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5060 - accuracy: 0.8224 - val_loss: 2.6158 - val_accuracy: 0.4485\n",
            "Epoch 740/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.7275 - accuracy: 0.7364 - val_loss: 2.5852 - val_accuracy: 0.4354\n",
            "Epoch 741/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5161 - accuracy: 0.8162 - val_loss: 2.4495 - val_accuracy: 0.4697\n",
            "Epoch 742/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5323 - accuracy: 0.8071 - val_loss: 2.4383 - val_accuracy: 0.4855\n",
            "Epoch 743/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4996 - accuracy: 0.8292 - val_loss: 2.5512 - val_accuracy: 0.4485\n",
            "Epoch 744/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.5039 - accuracy: 0.8218 - val_loss: 2.4102 - val_accuracy: 0.4723\n",
            "Epoch 745/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4977 - accuracy: 0.8264 - val_loss: 2.3662 - val_accuracy: 0.4908\n",
            "Epoch 746/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4839 - accuracy: 0.8343 - val_loss: 2.3262 - val_accuracy: 0.5119\n",
            "Epoch 747/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4656 - accuracy: 0.8382 - val_loss: 2.3900 - val_accuracy: 0.4802\n",
            "Epoch 748/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5307 - accuracy: 0.8020 - val_loss: 2.4071 - val_accuracy: 0.4960\n",
            "Epoch 749/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5533 - accuracy: 0.8015 - val_loss: 2.4334 - val_accuracy: 0.4617\n",
            "Epoch 750/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4724 - accuracy: 0.8286 - val_loss: 2.5068 - val_accuracy: 0.4828\n",
            "Epoch 751/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5040 - accuracy: 0.8269 - val_loss: 2.3258 - val_accuracy: 0.4934\n",
            "Epoch 752/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5506 - accuracy: 0.7981 - val_loss: 2.3762 - val_accuracy: 0.4908\n",
            "Epoch 753/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4950 - accuracy: 0.8264 - val_loss: 2.4621 - val_accuracy: 0.5198\n",
            "Epoch 754/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5169 - accuracy: 0.8201 - val_loss: 2.3249 - val_accuracy: 0.4934\n",
            "Epoch 755/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4869 - accuracy: 0.8258 - val_loss: 2.4055 - val_accuracy: 0.5040\n",
            "Epoch 756/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4566 - accuracy: 0.8388 - val_loss: 2.2972 - val_accuracy: 0.5066\n",
            "Epoch 757/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4918 - accuracy: 0.8162 - val_loss: 2.6599 - val_accuracy: 0.4565\n",
            "Epoch 758/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.6068 - accuracy: 0.7777 - val_loss: 2.3946 - val_accuracy: 0.5092\n",
            "Epoch 759/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5096 - accuracy: 0.8060 - val_loss: 2.4550 - val_accuracy: 0.4723\n",
            "Epoch 760/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5556 - accuracy: 0.7992 - val_loss: 2.3340 - val_accuracy: 0.4828\n",
            "Epoch 761/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4940 - accuracy: 0.8252 - val_loss: 2.3864 - val_accuracy: 0.4960\n",
            "Epoch 762/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4697 - accuracy: 0.8314 - val_loss: 2.3217 - val_accuracy: 0.4828\n",
            "Epoch 763/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4775 - accuracy: 0.8331 - val_loss: 2.5110 - val_accuracy: 0.4855\n",
            "Epoch 764/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4749 - accuracy: 0.8258 - val_loss: 2.3574 - val_accuracy: 0.5145\n",
            "Epoch 765/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4778 - accuracy: 0.8230 - val_loss: 2.2687 - val_accuracy: 0.5198\n",
            "Epoch 766/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4642 - accuracy: 0.8331 - val_loss: 2.4487 - val_accuracy: 0.4697\n",
            "Epoch 767/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5092 - accuracy: 0.8167 - val_loss: 2.5843 - val_accuracy: 0.4934\n",
            "Epoch 768/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5378 - accuracy: 0.8088 - val_loss: 2.4688 - val_accuracy: 0.4855\n",
            "Epoch 769/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4902 - accuracy: 0.8235 - val_loss: 2.3083 - val_accuracy: 0.4828\n",
            "Epoch 770/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4641 - accuracy: 0.8371 - val_loss: 2.5722 - val_accuracy: 0.4697\n",
            "Epoch 771/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4845 - accuracy: 0.8241 - val_loss: 2.2990 - val_accuracy: 0.5145\n",
            "Epoch 772/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5587 - accuracy: 0.7924 - val_loss: 2.5922 - val_accuracy: 0.4697\n",
            "Epoch 773/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4929 - accuracy: 0.8213 - val_loss: 2.2473 - val_accuracy: 0.4987\n",
            "Epoch 774/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4905 - accuracy: 0.8258 - val_loss: 2.3725 - val_accuracy: 0.5013\n",
            "Epoch 775/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4859 - accuracy: 0.8241 - val_loss: 2.5676 - val_accuracy: 0.4565\n",
            "Epoch 776/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5051 - accuracy: 0.8105 - val_loss: 2.3979 - val_accuracy: 0.5066\n",
            "Epoch 777/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4622 - accuracy: 0.8377 - val_loss: 2.8474 - val_accuracy: 0.4697\n",
            "Epoch 778/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5388 - accuracy: 0.8122 - val_loss: 2.3763 - val_accuracy: 0.5013\n",
            "Epoch 779/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4833 - accuracy: 0.8241 - val_loss: 2.4267 - val_accuracy: 0.4591\n",
            "Epoch 780/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5096 - accuracy: 0.8094 - val_loss: 2.3493 - val_accuracy: 0.5145\n",
            "Epoch 781/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4984 - accuracy: 0.8269 - val_loss: 2.4186 - val_accuracy: 0.5092\n",
            "Epoch 782/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4438 - accuracy: 0.8450 - val_loss: 2.4160 - val_accuracy: 0.5303\n",
            "Epoch 783/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4328 - accuracy: 0.8490 - val_loss: 2.3721 - val_accuracy: 0.5066\n",
            "Epoch 784/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4491 - accuracy: 0.8428 - val_loss: 2.3011 - val_accuracy: 0.5277\n",
            "Epoch 785/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4469 - accuracy: 0.8439 - val_loss: 2.6081 - val_accuracy: 0.4591\n",
            "Epoch 786/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4694 - accuracy: 0.8365 - val_loss: 2.5525 - val_accuracy: 0.4670\n",
            "Epoch 787/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4868 - accuracy: 0.8275 - val_loss: 2.3195 - val_accuracy: 0.5198\n",
            "Epoch 788/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4614 - accuracy: 0.8462 - val_loss: 2.4578 - val_accuracy: 0.5013\n",
            "Epoch 789/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4704 - accuracy: 0.8394 - val_loss: 2.4006 - val_accuracy: 0.4960\n",
            "Epoch 790/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4751 - accuracy: 0.8286 - val_loss: 2.4927 - val_accuracy: 0.4723\n",
            "Epoch 791/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4498 - accuracy: 0.8512 - val_loss: 2.4127 - val_accuracy: 0.4881\n",
            "Epoch 792/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4939 - accuracy: 0.8264 - val_loss: 2.5063 - val_accuracy: 0.5013\n",
            "Epoch 793/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.5448 - accuracy: 0.7941 - val_loss: 2.3097 - val_accuracy: 0.5277\n",
            "Epoch 794/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4714 - accuracy: 0.8286 - val_loss: 2.3740 - val_accuracy: 0.4881\n",
            "Epoch 795/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4855 - accuracy: 0.8286 - val_loss: 2.3516 - val_accuracy: 0.4802\n",
            "Epoch 796/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4353 - accuracy: 0.8428 - val_loss: 2.6484 - val_accuracy: 0.4617\n",
            "Epoch 797/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4705 - accuracy: 0.8394 - val_loss: 2.4414 - val_accuracy: 0.4960\n",
            "Epoch 798/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4586 - accuracy: 0.8337 - val_loss: 2.4684 - val_accuracy: 0.4802\n",
            "Epoch 799/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4666 - accuracy: 0.8348 - val_loss: 2.4636 - val_accuracy: 0.4644\n",
            "Epoch 800/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5268 - accuracy: 0.8088 - val_loss: 2.3443 - val_accuracy: 0.5066\n",
            "Epoch 801/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4612 - accuracy: 0.8422 - val_loss: 2.4960 - val_accuracy: 0.5013\n",
            "Epoch 802/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5358 - accuracy: 0.7992 - val_loss: 2.5550 - val_accuracy: 0.4697\n",
            "Epoch 803/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4846 - accuracy: 0.8156 - val_loss: 2.4174 - val_accuracy: 0.5040\n",
            "Epoch 804/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4388 - accuracy: 0.8479 - val_loss: 2.4062 - val_accuracy: 0.4828\n",
            "Epoch 805/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4581 - accuracy: 0.8450 - val_loss: 2.4229 - val_accuracy: 0.5145\n",
            "Epoch 806/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4403 - accuracy: 0.8473 - val_loss: 2.3856 - val_accuracy: 0.5277\n",
            "Epoch 807/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5037 - accuracy: 0.8179 - val_loss: 2.5740 - val_accuracy: 0.4749\n",
            "Epoch 808/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4526 - accuracy: 0.8439 - val_loss: 2.3520 - val_accuracy: 0.5409\n",
            "Epoch 809/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4688 - accuracy: 0.8303 - val_loss: 2.4344 - val_accuracy: 0.4960\n",
            "Epoch 810/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4528 - accuracy: 0.8365 - val_loss: 2.3872 - val_accuracy: 0.5066\n",
            "Epoch 811/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4513 - accuracy: 0.8365 - val_loss: 2.4306 - val_accuracy: 0.4934\n",
            "Epoch 812/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4684 - accuracy: 0.8337 - val_loss: 2.6317 - val_accuracy: 0.4670\n",
            "Epoch 813/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4455 - accuracy: 0.8467 - val_loss: 2.4991 - val_accuracy: 0.4908\n",
            "Epoch 814/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4498 - accuracy: 0.8405 - val_loss: 2.4248 - val_accuracy: 0.5119\n",
            "Epoch 815/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4986 - accuracy: 0.8230 - val_loss: 2.4975 - val_accuracy: 0.5119\n",
            "Epoch 816/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4842 - accuracy: 0.8252 - val_loss: 2.3928 - val_accuracy: 0.5066\n",
            "Epoch 817/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4784 - accuracy: 0.8314 - val_loss: 2.7732 - val_accuracy: 0.4881\n",
            "Epoch 818/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5824 - accuracy: 0.7913 - val_loss: 2.3529 - val_accuracy: 0.5330\n",
            "Epoch 819/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4783 - accuracy: 0.8218 - val_loss: 2.6117 - val_accuracy: 0.4617\n",
            "Epoch 820/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4652 - accuracy: 0.8326 - val_loss: 2.5363 - val_accuracy: 0.4749\n",
            "Epoch 821/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5019 - accuracy: 0.8269 - val_loss: 2.4719 - val_accuracy: 0.4960\n",
            "Epoch 822/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4225 - accuracy: 0.8603 - val_loss: 2.4647 - val_accuracy: 0.4881\n",
            "Epoch 823/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4782 - accuracy: 0.8207 - val_loss: 2.5438 - val_accuracy: 0.4881\n",
            "Epoch 824/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4590 - accuracy: 0.8433 - val_loss: 2.5898 - val_accuracy: 0.4855\n",
            "Epoch 825/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.4220 - accuracy: 0.8524 - val_loss: 2.4623 - val_accuracy: 0.4987\n",
            "Epoch 826/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4475 - accuracy: 0.8343 - val_loss: 2.4072 - val_accuracy: 0.5251\n",
            "Epoch 827/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4560 - accuracy: 0.8382 - val_loss: 2.8060 - val_accuracy: 0.4301\n",
            "Epoch 828/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4830 - accuracy: 0.8258 - val_loss: 2.4868 - val_accuracy: 0.5092\n",
            "Epoch 829/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4229 - accuracy: 0.8507 - val_loss: 2.4104 - val_accuracy: 0.5145\n",
            "Epoch 830/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4890 - accuracy: 0.8286 - val_loss: 2.4393 - val_accuracy: 0.5066\n",
            "Epoch 831/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5094 - accuracy: 0.8150 - val_loss: 2.3911 - val_accuracy: 0.5198\n",
            "Epoch 832/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5163 - accuracy: 0.8037 - val_loss: 2.4820 - val_accuracy: 0.5198\n",
            "Epoch 833/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4501 - accuracy: 0.8439 - val_loss: 2.4636 - val_accuracy: 0.4934\n",
            "Epoch 834/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4350 - accuracy: 0.8422 - val_loss: 2.4929 - val_accuracy: 0.5040\n",
            "Epoch 835/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4354 - accuracy: 0.8456 - val_loss: 2.4992 - val_accuracy: 0.4828\n",
            "Epoch 836/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4083 - accuracy: 0.8586 - val_loss: 2.5370 - val_accuracy: 0.4776\n",
            "Epoch 837/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4446 - accuracy: 0.8382 - val_loss: 2.4784 - val_accuracy: 0.4802\n",
            "Epoch 838/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4375 - accuracy: 0.8445 - val_loss: 2.4854 - val_accuracy: 0.5145\n",
            "Epoch 839/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4525 - accuracy: 0.8467 - val_loss: 2.4109 - val_accuracy: 0.5092\n",
            "Epoch 840/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4453 - accuracy: 0.8258 - val_loss: 2.4088 - val_accuracy: 0.4881\n",
            "Epoch 841/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4799 - accuracy: 0.8292 - val_loss: 2.4500 - val_accuracy: 0.4934\n",
            "Epoch 842/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4457 - accuracy: 0.8331 - val_loss: 2.5141 - val_accuracy: 0.4723\n",
            "Epoch 843/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4951 - accuracy: 0.8145 - val_loss: 2.5117 - val_accuracy: 0.4987\n",
            "Epoch 844/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4797 - accuracy: 0.8167 - val_loss: 2.4155 - val_accuracy: 0.5013\n",
            "Epoch 845/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4403 - accuracy: 0.8394 - val_loss: 2.5971 - val_accuracy: 0.4485\n",
            "Epoch 846/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4738 - accuracy: 0.8247 - val_loss: 2.5484 - val_accuracy: 0.4828\n",
            "Epoch 847/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4419 - accuracy: 0.8535 - val_loss: 2.7513 - val_accuracy: 0.4565\n",
            "Epoch 848/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4813 - accuracy: 0.8179 - val_loss: 2.5694 - val_accuracy: 0.4934\n",
            "Epoch 849/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4675 - accuracy: 0.8326 - val_loss: 2.5354 - val_accuracy: 0.4934\n",
            "Epoch 850/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4709 - accuracy: 0.8286 - val_loss: 2.4635 - val_accuracy: 0.5172\n",
            "Epoch 851/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4305 - accuracy: 0.8512 - val_loss: 2.4356 - val_accuracy: 0.4881\n",
            "Epoch 852/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4259 - accuracy: 0.8450 - val_loss: 2.6143 - val_accuracy: 0.5013\n",
            "Epoch 853/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4527 - accuracy: 0.8422 - val_loss: 2.4262 - val_accuracy: 0.5066\n",
            "Epoch 854/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4537 - accuracy: 0.8439 - val_loss: 2.4112 - val_accuracy: 0.4934\n",
            "Epoch 855/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4949 - accuracy: 0.8184 - val_loss: 2.5344 - val_accuracy: 0.4723\n",
            "Epoch 856/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4785 - accuracy: 0.8360 - val_loss: 2.5683 - val_accuracy: 0.4591\n",
            "Epoch 857/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4317 - accuracy: 0.8479 - val_loss: 2.7361 - val_accuracy: 0.4802\n",
            "Epoch 858/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4575 - accuracy: 0.8394 - val_loss: 2.5692 - val_accuracy: 0.4617\n",
            "Epoch 859/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4701 - accuracy: 0.8337 - val_loss: 2.4327 - val_accuracy: 0.5092\n",
            "Epoch 860/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4147 - accuracy: 0.8597 - val_loss: 2.5221 - val_accuracy: 0.4644\n",
            "Epoch 861/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4515 - accuracy: 0.8399 - val_loss: 2.8026 - val_accuracy: 0.4354\n",
            "Epoch 862/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5018 - accuracy: 0.8117 - val_loss: 2.6226 - val_accuracy: 0.4776\n",
            "Epoch 863/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4639 - accuracy: 0.8382 - val_loss: 2.5309 - val_accuracy: 0.4802\n",
            "Epoch 864/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4121 - accuracy: 0.8558 - val_loss: 2.5071 - val_accuracy: 0.5224\n",
            "Epoch 865/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4420 - accuracy: 0.8518 - val_loss: 2.6036 - val_accuracy: 0.4723\n",
            "Epoch 866/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4328 - accuracy: 0.8456 - val_loss: 2.5723 - val_accuracy: 0.4855\n",
            "Epoch 867/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5193 - accuracy: 0.8173 - val_loss: 2.6979 - val_accuracy: 0.4802\n",
            "Epoch 868/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4545 - accuracy: 0.8405 - val_loss: 2.5068 - val_accuracy: 0.4881\n",
            "Epoch 869/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4288 - accuracy: 0.8433 - val_loss: 2.7621 - val_accuracy: 0.4538\n",
            "Epoch 870/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4555 - accuracy: 0.8456 - val_loss: 2.6411 - val_accuracy: 0.4802\n",
            "Epoch 871/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4552 - accuracy: 0.8411 - val_loss: 2.5596 - val_accuracy: 0.4908\n",
            "Epoch 872/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4736 - accuracy: 0.8326 - val_loss: 2.5705 - val_accuracy: 0.4749\n",
            "Epoch 873/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4349 - accuracy: 0.8507 - val_loss: 2.6026 - val_accuracy: 0.5092\n",
            "Epoch 874/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4350 - accuracy: 0.8394 - val_loss: 2.4747 - val_accuracy: 0.5092\n",
            "Epoch 875/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4105 - accuracy: 0.8586 - val_loss: 2.6684 - val_accuracy: 0.4934\n",
            "Epoch 876/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4014 - accuracy: 0.8592 - val_loss: 2.4262 - val_accuracy: 0.5330\n",
            "Epoch 877/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4516 - accuracy: 0.8399 - val_loss: 2.6273 - val_accuracy: 0.4960\n",
            "Epoch 878/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4267 - accuracy: 0.8563 - val_loss: 2.5264 - val_accuracy: 0.5066\n",
            "Epoch 879/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4184 - accuracy: 0.8422 - val_loss: 2.5484 - val_accuracy: 0.4802\n",
            "Epoch 880/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4588 - accuracy: 0.8422 - val_loss: 2.6037 - val_accuracy: 0.4960\n",
            "Epoch 881/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5083 - accuracy: 0.8117 - val_loss: 2.7494 - val_accuracy: 0.4485\n",
            "Epoch 882/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4658 - accuracy: 0.8337 - val_loss: 2.8232 - val_accuracy: 0.4327\n",
            "Epoch 883/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4647 - accuracy: 0.8331 - val_loss: 2.4724 - val_accuracy: 0.5040\n",
            "Epoch 884/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4206 - accuracy: 0.8479 - val_loss: 2.5465 - val_accuracy: 0.4987\n",
            "Epoch 885/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3881 - accuracy: 0.8609 - val_loss: 2.5175 - val_accuracy: 0.5198\n",
            "Epoch 886/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4039 - accuracy: 0.8631 - val_loss: 2.5075 - val_accuracy: 0.5013\n",
            "Epoch 887/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3951 - accuracy: 0.8620 - val_loss: 2.6173 - val_accuracy: 0.4538\n",
            "Epoch 888/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4264 - accuracy: 0.8552 - val_loss: 2.7008 - val_accuracy: 0.4881\n",
            "Epoch 889/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4134 - accuracy: 0.8575 - val_loss: 2.6523 - val_accuracy: 0.4987\n",
            "Epoch 890/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4833 - accuracy: 0.8286 - val_loss: 2.4694 - val_accuracy: 0.5013\n",
            "Epoch 891/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4385 - accuracy: 0.8479 - val_loss: 2.6570 - val_accuracy: 0.5277\n",
            "Epoch 892/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4165 - accuracy: 0.8563 - val_loss: 2.6505 - val_accuracy: 0.4697\n",
            "Epoch 893/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4696 - accuracy: 0.8314 - val_loss: 2.5489 - val_accuracy: 0.5013\n",
            "Epoch 894/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4013 - accuracy: 0.8603 - val_loss: 2.5573 - val_accuracy: 0.4960\n",
            "Epoch 895/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4124 - accuracy: 0.8648 - val_loss: 2.6186 - val_accuracy: 0.4908\n",
            "Epoch 896/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4287 - accuracy: 0.8422 - val_loss: 2.6309 - val_accuracy: 0.4881\n",
            "Epoch 897/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4411 - accuracy: 0.8439 - val_loss: 2.6752 - val_accuracy: 0.4802\n",
            "Epoch 898/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4538 - accuracy: 0.8269 - val_loss: 2.6733 - val_accuracy: 0.5040\n",
            "Epoch 899/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4254 - accuracy: 0.8575 - val_loss: 2.6155 - val_accuracy: 0.4987\n",
            "Epoch 900/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3875 - accuracy: 0.8727 - val_loss: 2.6627 - val_accuracy: 0.5013\n",
            "Epoch 901/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4130 - accuracy: 0.8575 - val_loss: 2.6337 - val_accuracy: 0.5013\n",
            "Epoch 902/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4227 - accuracy: 0.8490 - val_loss: 2.6540 - val_accuracy: 0.4908\n",
            "Epoch 903/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4628 - accuracy: 0.8303 - val_loss: 2.8929 - val_accuracy: 0.4274\n",
            "Epoch 904/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4765 - accuracy: 0.8292 - val_loss: 2.6211 - val_accuracy: 0.5198\n",
            "Epoch 905/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4792 - accuracy: 0.8224 - val_loss: 2.6041 - val_accuracy: 0.5198\n",
            "Epoch 906/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4149 - accuracy: 0.8580 - val_loss: 2.6539 - val_accuracy: 0.4934\n",
            "Epoch 907/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4205 - accuracy: 0.8507 - val_loss: 2.8852 - val_accuracy: 0.4433\n",
            "Epoch 908/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4489 - accuracy: 0.8377 - val_loss: 2.5199 - val_accuracy: 0.5172\n",
            "Epoch 909/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4581 - accuracy: 0.8331 - val_loss: 2.5810 - val_accuracy: 0.5066\n",
            "Epoch 910/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4067 - accuracy: 0.8501 - val_loss: 2.5176 - val_accuracy: 0.4987\n",
            "Epoch 911/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4354 - accuracy: 0.8394 - val_loss: 2.6825 - val_accuracy: 0.5224\n",
            "Epoch 912/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4331 - accuracy: 0.8473 - val_loss: 2.6907 - val_accuracy: 0.5040\n",
            "Epoch 913/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3943 - accuracy: 0.8637 - val_loss: 2.5861 - val_accuracy: 0.5172\n",
            "Epoch 914/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3904 - accuracy: 0.8563 - val_loss: 2.7326 - val_accuracy: 0.4855\n",
            "Epoch 915/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4714 - accuracy: 0.8292 - val_loss: 2.7259 - val_accuracy: 0.4697\n",
            "Epoch 916/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4356 - accuracy: 0.8456 - val_loss: 2.5648 - val_accuracy: 0.5040\n",
            "Epoch 917/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3902 - accuracy: 0.8660 - val_loss: 2.7183 - val_accuracy: 0.5198\n",
            "Epoch 918/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4400 - accuracy: 0.8405 - val_loss: 2.8444 - val_accuracy: 0.4828\n",
            "Epoch 919/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4609 - accuracy: 0.8388 - val_loss: 2.8799 - val_accuracy: 0.4512\n",
            "Epoch 920/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4375 - accuracy: 0.8439 - val_loss: 2.7916 - val_accuracy: 0.4776\n",
            "Epoch 921/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4087 - accuracy: 0.8535 - val_loss: 2.6927 - val_accuracy: 0.5066\n",
            "Epoch 922/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4219 - accuracy: 0.8580 - val_loss: 2.5646 - val_accuracy: 0.4934\n",
            "Epoch 923/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4488 - accuracy: 0.8365 - val_loss: 2.6021 - val_accuracy: 0.4881\n",
            "Epoch 924/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4574 - accuracy: 0.8439 - val_loss: 2.8046 - val_accuracy: 0.4749\n",
            "Epoch 925/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4180 - accuracy: 0.8569 - val_loss: 2.5712 - val_accuracy: 0.5013\n",
            "Epoch 926/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4008 - accuracy: 0.8541 - val_loss: 2.7637 - val_accuracy: 0.4723\n",
            "Epoch 927/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4397 - accuracy: 0.8365 - val_loss: 2.7218 - val_accuracy: 0.4406\n",
            "Epoch 928/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4141 - accuracy: 0.8546 - val_loss: 2.5519 - val_accuracy: 0.5013\n",
            "Epoch 929/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4355 - accuracy: 0.8456 - val_loss: 2.7836 - val_accuracy: 0.5119\n",
            "Epoch 930/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4601 - accuracy: 0.8298 - val_loss: 2.6753 - val_accuracy: 0.4723\n",
            "Epoch 931/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4456 - accuracy: 0.8343 - val_loss: 2.7496 - val_accuracy: 0.4908\n",
            "Epoch 932/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4201 - accuracy: 0.8428 - val_loss: 2.5379 - val_accuracy: 0.4987\n",
            "Epoch 933/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4182 - accuracy: 0.8479 - val_loss: 2.5348 - val_accuracy: 0.5092\n",
            "Epoch 934/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4082 - accuracy: 0.8626 - val_loss: 2.6311 - val_accuracy: 0.4802\n",
            "Epoch 935/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4080 - accuracy: 0.8529 - val_loss: 2.6047 - val_accuracy: 0.5013\n",
            "Epoch 936/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4478 - accuracy: 0.8416 - val_loss: 3.1095 - val_accuracy: 0.4670\n",
            "Epoch 937/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4110 - accuracy: 0.8529 - val_loss: 2.7470 - val_accuracy: 0.4749\n",
            "Epoch 938/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4213 - accuracy: 0.8484 - val_loss: 2.6195 - val_accuracy: 0.5066\n",
            "Epoch 939/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3949 - accuracy: 0.8637 - val_loss: 2.6681 - val_accuracy: 0.5040\n",
            "Epoch 940/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4028 - accuracy: 0.8569 - val_loss: 2.7081 - val_accuracy: 0.4828\n",
            "Epoch 941/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4386 - accuracy: 0.8439 - val_loss: 2.7410 - val_accuracy: 0.4828\n",
            "Epoch 942/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.5152 - accuracy: 0.8122 - val_loss: 2.6968 - val_accuracy: 0.4802\n",
            "Epoch 943/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4280 - accuracy: 0.8382 - val_loss: 2.5821 - val_accuracy: 0.5277\n",
            "Epoch 944/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4370 - accuracy: 0.8354 - val_loss: 2.6485 - val_accuracy: 0.5092\n",
            "Epoch 945/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4626 - accuracy: 0.8184 - val_loss: 2.6126 - val_accuracy: 0.4987\n",
            "Epoch 946/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4212 - accuracy: 0.8575 - val_loss: 2.6245 - val_accuracy: 0.4802\n",
            "Epoch 947/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3968 - accuracy: 0.8626 - val_loss: 2.7474 - val_accuracy: 0.4828\n",
            "Epoch 948/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3838 - accuracy: 0.8733 - val_loss: 2.6698 - val_accuracy: 0.5092\n",
            "Epoch 949/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3854 - accuracy: 0.8620 - val_loss: 2.7100 - val_accuracy: 0.5040\n",
            "Epoch 950/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4138 - accuracy: 0.8575 - val_loss: 2.6767 - val_accuracy: 0.5145\n",
            "Epoch 951/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4075 - accuracy: 0.8479 - val_loss: 2.6421 - val_accuracy: 0.5040\n",
            "Epoch 952/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3609 - accuracy: 0.8688 - val_loss: 2.7156 - val_accuracy: 0.4908\n",
            "Epoch 953/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4194 - accuracy: 0.8462 - val_loss: 2.6947 - val_accuracy: 0.5066\n",
            "Epoch 954/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3901 - accuracy: 0.8648 - val_loss: 2.6457 - val_accuracy: 0.5092\n",
            "Epoch 955/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3868 - accuracy: 0.8643 - val_loss: 2.6794 - val_accuracy: 0.4855\n",
            "Epoch 956/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.4057 - accuracy: 0.8569 - val_loss: 2.7334 - val_accuracy: 0.4934\n",
            "Epoch 957/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4087 - accuracy: 0.8507 - val_loss: 2.7431 - val_accuracy: 0.5040\n",
            "Epoch 958/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3982 - accuracy: 0.8609 - val_loss: 2.9390 - val_accuracy: 0.4538\n",
            "Epoch 959/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4421 - accuracy: 0.8445 - val_loss: 2.9104 - val_accuracy: 0.4723\n",
            "Epoch 960/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3966 - accuracy: 0.8552 - val_loss: 2.8421 - val_accuracy: 0.4749\n",
            "Epoch 961/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3902 - accuracy: 0.8529 - val_loss: 2.8134 - val_accuracy: 0.4802\n",
            "Epoch 962/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4011 - accuracy: 0.8569 - val_loss: 2.7741 - val_accuracy: 0.4802\n",
            "Epoch 963/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4043 - accuracy: 0.8524 - val_loss: 2.7431 - val_accuracy: 0.4908\n",
            "Epoch 964/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3703 - accuracy: 0.8739 - val_loss: 2.7780 - val_accuracy: 0.4881\n",
            "Epoch 965/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3946 - accuracy: 0.8637 - val_loss: 2.7235 - val_accuracy: 0.5145\n",
            "Epoch 966/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4154 - accuracy: 0.8518 - val_loss: 2.6771 - val_accuracy: 0.4881\n",
            "Epoch 967/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4035 - accuracy: 0.8575 - val_loss: 2.7505 - val_accuracy: 0.4644\n",
            "Epoch 968/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3832 - accuracy: 0.8620 - val_loss: 2.8760 - val_accuracy: 0.4512\n",
            "Epoch 969/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4510 - accuracy: 0.8467 - val_loss: 2.8409 - val_accuracy: 0.4670\n",
            "Epoch 970/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4142 - accuracy: 0.8558 - val_loss: 2.8556 - val_accuracy: 0.5145\n",
            "Epoch 971/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3755 - accuracy: 0.8767 - val_loss: 2.7984 - val_accuracy: 0.4749\n",
            "Epoch 972/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3814 - accuracy: 0.8654 - val_loss: 2.7671 - val_accuracy: 0.4855\n",
            "Epoch 973/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3980 - accuracy: 0.8512 - val_loss: 2.7353 - val_accuracy: 0.4987\n",
            "Epoch 974/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3909 - accuracy: 0.8592 - val_loss: 2.7745 - val_accuracy: 0.4828\n",
            "Epoch 975/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3717 - accuracy: 0.8643 - val_loss: 2.6815 - val_accuracy: 0.5040\n",
            "Epoch 976/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4496 - accuracy: 0.8371 - val_loss: 2.7985 - val_accuracy: 0.4855\n",
            "Epoch 977/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4035 - accuracy: 0.8558 - val_loss: 2.7855 - val_accuracy: 0.5013\n",
            "Epoch 978/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3982 - accuracy: 0.8586 - val_loss: 3.0337 - val_accuracy: 0.4327\n",
            "Epoch 979/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4016 - accuracy: 0.8512 - val_loss: 2.9156 - val_accuracy: 0.5040\n",
            "Epoch 980/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3790 - accuracy: 0.8693 - val_loss: 2.8183 - val_accuracy: 0.4802\n",
            "Epoch 981/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4342 - accuracy: 0.8456 - val_loss: 2.7325 - val_accuracy: 0.5119\n",
            "Epoch 982/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3737 - accuracy: 0.8795 - val_loss: 2.8566 - val_accuracy: 0.4855\n",
            "Epoch 983/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3987 - accuracy: 0.8569 - val_loss: 2.7765 - val_accuracy: 0.5092\n",
            "Epoch 984/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3622 - accuracy: 0.8722 - val_loss: 2.6904 - val_accuracy: 0.5172\n",
            "Epoch 985/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4003 - accuracy: 0.8693 - val_loss: 2.9066 - val_accuracy: 0.4908\n",
            "Epoch 986/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3683 - accuracy: 0.8699 - val_loss: 2.6914 - val_accuracy: 0.5092\n",
            "Epoch 987/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3788 - accuracy: 0.8671 - val_loss: 2.7254 - val_accuracy: 0.5092\n",
            "Epoch 988/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4947 - accuracy: 0.8252 - val_loss: 2.8721 - val_accuracy: 0.4749\n",
            "Epoch 989/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4043 - accuracy: 0.8609 - val_loss: 2.7985 - val_accuracy: 0.4908\n",
            "Epoch 990/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3797 - accuracy: 0.8727 - val_loss: 2.8672 - val_accuracy: 0.4908\n",
            "Epoch 991/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3764 - accuracy: 0.8648 - val_loss: 2.7555 - val_accuracy: 0.4881\n",
            "Epoch 992/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3553 - accuracy: 0.8824 - val_loss: 2.8564 - val_accuracy: 0.4987\n",
            "Epoch 993/1500\n",
            "56/56 [==============================] - 3s 49ms/step - loss: 0.3713 - accuracy: 0.8693 - val_loss: 2.7903 - val_accuracy: 0.4934\n",
            "Epoch 994/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3729 - accuracy: 0.8739 - val_loss: 2.9274 - val_accuracy: 0.4855\n",
            "Epoch 995/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3777 - accuracy: 0.8761 - val_loss: 2.6735 - val_accuracy: 0.5198\n",
            "Epoch 996/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3816 - accuracy: 0.8620 - val_loss: 2.7500 - val_accuracy: 0.5066\n",
            "Epoch 997/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3571 - accuracy: 0.8750 - val_loss: 2.7410 - val_accuracy: 0.5013\n",
            "Epoch 998/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3846 - accuracy: 0.8682 - val_loss: 2.8585 - val_accuracy: 0.5013\n",
            "Epoch 999/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3692 - accuracy: 0.8818 - val_loss: 2.9145 - val_accuracy: 0.4802\n",
            "Epoch 1000/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4191 - accuracy: 0.8490 - val_loss: 3.0992 - val_accuracy: 0.4670\n",
            "Epoch 1001/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4061 - accuracy: 0.8524 - val_loss: 2.8250 - val_accuracy: 0.4960\n",
            "Epoch 1002/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3933 - accuracy: 0.8546 - val_loss: 2.8843 - val_accuracy: 0.5119\n",
            "Epoch 1003/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4031 - accuracy: 0.8501 - val_loss: 2.9316 - val_accuracy: 0.4749\n",
            "Epoch 1004/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4252 - accuracy: 0.8394 - val_loss: 2.7585 - val_accuracy: 0.5092\n",
            "Epoch 1005/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4170 - accuracy: 0.8518 - val_loss: 2.7953 - val_accuracy: 0.5119\n",
            "Epoch 1006/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3789 - accuracy: 0.8688 - val_loss: 2.8171 - val_accuracy: 0.5066\n",
            "Epoch 1007/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3990 - accuracy: 0.8518 - val_loss: 2.8065 - val_accuracy: 0.5172\n",
            "Epoch 1008/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3730 - accuracy: 0.8699 - val_loss: 2.7127 - val_accuracy: 0.5092\n",
            "Epoch 1009/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3889 - accuracy: 0.8580 - val_loss: 2.9718 - val_accuracy: 0.5119\n",
            "Epoch 1010/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3956 - accuracy: 0.8643 - val_loss: 2.7276 - val_accuracy: 0.4987\n",
            "Epoch 1011/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4860 - accuracy: 0.8247 - val_loss: 2.9098 - val_accuracy: 0.4776\n",
            "Epoch 1012/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3934 - accuracy: 0.8727 - val_loss: 2.7253 - val_accuracy: 0.5066\n",
            "Epoch 1013/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3952 - accuracy: 0.8541 - val_loss: 3.0502 - val_accuracy: 0.4881\n",
            "Epoch 1014/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4008 - accuracy: 0.8575 - val_loss: 2.9881 - val_accuracy: 0.4908\n",
            "Epoch 1015/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3859 - accuracy: 0.8699 - val_loss: 2.9991 - val_accuracy: 0.4881\n",
            "Epoch 1016/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4594 - accuracy: 0.8416 - val_loss: 2.8713 - val_accuracy: 0.4644\n",
            "Epoch 1017/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4010 - accuracy: 0.8569 - val_loss: 2.7262 - val_accuracy: 0.5066\n",
            "Epoch 1018/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3985 - accuracy: 0.8552 - val_loss: 2.8239 - val_accuracy: 0.5172\n",
            "Epoch 1019/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3884 - accuracy: 0.8603 - val_loss: 2.8109 - val_accuracy: 0.5172\n",
            "Epoch 1020/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3852 - accuracy: 0.8676 - val_loss: 2.8529 - val_accuracy: 0.4908\n",
            "Epoch 1021/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3480 - accuracy: 0.8739 - val_loss: 2.8384 - val_accuracy: 0.5303\n",
            "Epoch 1022/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3642 - accuracy: 0.8750 - val_loss: 2.8254 - val_accuracy: 0.5145\n",
            "Epoch 1023/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3351 - accuracy: 0.8874 - val_loss: 2.8488 - val_accuracy: 0.4960\n",
            "Epoch 1024/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3933 - accuracy: 0.8631 - val_loss: 2.8735 - val_accuracy: 0.5092\n",
            "Epoch 1025/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3734 - accuracy: 0.8671 - val_loss: 2.8229 - val_accuracy: 0.5119\n",
            "Epoch 1026/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3561 - accuracy: 0.8750 - val_loss: 2.8978 - val_accuracy: 0.4934\n",
            "Epoch 1027/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3731 - accuracy: 0.8716 - val_loss: 2.7826 - val_accuracy: 0.5172\n",
            "Epoch 1028/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3835 - accuracy: 0.8676 - val_loss: 2.8564 - val_accuracy: 0.4855\n",
            "Epoch 1029/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4531 - accuracy: 0.8411 - val_loss: 2.8318 - val_accuracy: 0.4670\n",
            "Epoch 1030/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3788 - accuracy: 0.8654 - val_loss: 3.0079 - val_accuracy: 0.4855\n",
            "Epoch 1031/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3576 - accuracy: 0.8739 - val_loss: 2.8727 - val_accuracy: 0.4987\n",
            "Epoch 1032/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4448 - accuracy: 0.8433 - val_loss: 2.8245 - val_accuracy: 0.4934\n",
            "Epoch 1033/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3990 - accuracy: 0.8592 - val_loss: 2.7845 - val_accuracy: 0.4776\n",
            "Epoch 1034/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3478 - accuracy: 0.8824 - val_loss: 2.8438 - val_accuracy: 0.4776\n",
            "Epoch 1035/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3632 - accuracy: 0.8761 - val_loss: 2.9702 - val_accuracy: 0.4908\n",
            "Epoch 1036/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3437 - accuracy: 0.8818 - val_loss: 2.9046 - val_accuracy: 0.4776\n",
            "Epoch 1037/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3595 - accuracy: 0.8818 - val_loss: 2.7820 - val_accuracy: 0.5277\n",
            "Epoch 1038/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3544 - accuracy: 0.8761 - val_loss: 2.9535 - val_accuracy: 0.4644\n",
            "Epoch 1039/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3591 - accuracy: 0.8778 - val_loss: 2.8565 - val_accuracy: 0.4934\n",
            "Epoch 1040/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3805 - accuracy: 0.8682 - val_loss: 2.9628 - val_accuracy: 0.4670\n",
            "Epoch 1041/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3801 - accuracy: 0.8654 - val_loss: 3.1724 - val_accuracy: 0.4670\n",
            "Epoch 1042/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4191 - accuracy: 0.8467 - val_loss: 2.8602 - val_accuracy: 0.5066\n",
            "Epoch 1043/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3474 - accuracy: 0.8790 - val_loss: 2.8702 - val_accuracy: 0.5224\n",
            "Epoch 1044/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4247 - accuracy: 0.8388 - val_loss: 2.8429 - val_accuracy: 0.4723\n",
            "Epoch 1045/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3889 - accuracy: 0.8637 - val_loss: 2.8473 - val_accuracy: 0.5198\n",
            "Epoch 1046/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4266 - accuracy: 0.8495 - val_loss: 2.9133 - val_accuracy: 0.5092\n",
            "Epoch 1047/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3813 - accuracy: 0.8682 - val_loss: 2.9409 - val_accuracy: 0.4828\n",
            "Epoch 1048/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4020 - accuracy: 0.8688 - val_loss: 2.9216 - val_accuracy: 0.4776\n",
            "Epoch 1049/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3469 - accuracy: 0.8790 - val_loss: 2.8720 - val_accuracy: 0.5172\n",
            "Epoch 1050/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3535 - accuracy: 0.8824 - val_loss: 2.9433 - val_accuracy: 0.4828\n",
            "Epoch 1051/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4031 - accuracy: 0.8614 - val_loss: 2.9976 - val_accuracy: 0.4749\n",
            "Epoch 1052/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3618 - accuracy: 0.8739 - val_loss: 2.8886 - val_accuracy: 0.5119\n",
            "Epoch 1053/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4056 - accuracy: 0.8631 - val_loss: 2.8398 - val_accuracy: 0.5119\n",
            "Epoch 1054/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4754 - accuracy: 0.8377 - val_loss: 2.8221 - val_accuracy: 0.4855\n",
            "Epoch 1055/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3535 - accuracy: 0.8863 - val_loss: 2.8495 - val_accuracy: 0.4881\n",
            "Epoch 1056/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3536 - accuracy: 0.8761 - val_loss: 3.0382 - val_accuracy: 0.5119\n",
            "Epoch 1057/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3569 - accuracy: 0.8778 - val_loss: 2.9936 - val_accuracy: 0.4828\n",
            "Epoch 1058/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3639 - accuracy: 0.8699 - val_loss: 2.9667 - val_accuracy: 0.4802\n",
            "Epoch 1059/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3640 - accuracy: 0.8705 - val_loss: 2.8028 - val_accuracy: 0.5145\n",
            "Epoch 1060/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3640 - accuracy: 0.8750 - val_loss: 2.8304 - val_accuracy: 0.5040\n",
            "Epoch 1061/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3609 - accuracy: 0.8744 - val_loss: 2.9326 - val_accuracy: 0.5013\n",
            "Epoch 1062/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3964 - accuracy: 0.8597 - val_loss: 2.9859 - val_accuracy: 0.4591\n",
            "Epoch 1063/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3659 - accuracy: 0.8693 - val_loss: 2.8184 - val_accuracy: 0.4987\n",
            "Epoch 1064/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3998 - accuracy: 0.8479 - val_loss: 2.9261 - val_accuracy: 0.4881\n",
            "Epoch 1065/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3353 - accuracy: 0.8857 - val_loss: 2.8388 - val_accuracy: 0.4881\n",
            "Epoch 1066/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3397 - accuracy: 0.8852 - val_loss: 3.2347 - val_accuracy: 0.4697\n",
            "Epoch 1067/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3865 - accuracy: 0.8614 - val_loss: 2.9619 - val_accuracy: 0.4802\n",
            "Epoch 1068/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3482 - accuracy: 0.8829 - val_loss: 2.8120 - val_accuracy: 0.5040\n",
            "Epoch 1069/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3525 - accuracy: 0.8812 - val_loss: 2.9206 - val_accuracy: 0.5092\n",
            "Epoch 1070/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3434 - accuracy: 0.8818 - val_loss: 2.8724 - val_accuracy: 0.4960\n",
            "Epoch 1071/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3666 - accuracy: 0.8609 - val_loss: 3.0040 - val_accuracy: 0.4776\n",
            "Epoch 1072/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4014 - accuracy: 0.8603 - val_loss: 2.8780 - val_accuracy: 0.4908\n",
            "Epoch 1073/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4149 - accuracy: 0.8563 - val_loss: 2.9205 - val_accuracy: 0.4960\n",
            "Epoch 1074/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4223 - accuracy: 0.8439 - val_loss: 2.9210 - val_accuracy: 0.5013\n",
            "Epoch 1075/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3477 - accuracy: 0.8795 - val_loss: 2.9129 - val_accuracy: 0.5013\n",
            "Epoch 1076/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3545 - accuracy: 0.8750 - val_loss: 2.9125 - val_accuracy: 0.5040\n",
            "Epoch 1077/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4292 - accuracy: 0.8388 - val_loss: 2.8399 - val_accuracy: 0.5277\n",
            "Epoch 1078/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4031 - accuracy: 0.8586 - val_loss: 3.1428 - val_accuracy: 0.4908\n",
            "Epoch 1079/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3564 - accuracy: 0.8671 - val_loss: 2.9144 - val_accuracy: 0.4855\n",
            "Epoch 1080/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3571 - accuracy: 0.8778 - val_loss: 2.8807 - val_accuracy: 0.4987\n",
            "Epoch 1081/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3832 - accuracy: 0.8631 - val_loss: 2.9550 - val_accuracy: 0.5013\n",
            "Epoch 1082/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3550 - accuracy: 0.8750 - val_loss: 3.0514 - val_accuracy: 0.4749\n",
            "Epoch 1083/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3681 - accuracy: 0.8682 - val_loss: 2.9612 - val_accuracy: 0.5066\n",
            "Epoch 1084/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3600 - accuracy: 0.8778 - val_loss: 2.9561 - val_accuracy: 0.4960\n",
            "Epoch 1085/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3696 - accuracy: 0.8654 - val_loss: 2.9345 - val_accuracy: 0.5198\n",
            "Epoch 1086/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4039 - accuracy: 0.8586 - val_loss: 3.2003 - val_accuracy: 0.4617\n",
            "Epoch 1087/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4776 - accuracy: 0.8360 - val_loss: 2.9606 - val_accuracy: 0.4670\n",
            "Epoch 1088/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3831 - accuracy: 0.8626 - val_loss: 3.0676 - val_accuracy: 0.4802\n",
            "Epoch 1089/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3580 - accuracy: 0.8620 - val_loss: 2.9078 - val_accuracy: 0.4960\n",
            "Epoch 1090/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3312 - accuracy: 0.8880 - val_loss: 3.1163 - val_accuracy: 0.4776\n",
            "Epoch 1091/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3418 - accuracy: 0.8874 - val_loss: 3.0382 - val_accuracy: 0.4934\n",
            "Epoch 1092/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3949 - accuracy: 0.8518 - val_loss: 3.1030 - val_accuracy: 0.4934\n",
            "Epoch 1093/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3768 - accuracy: 0.8643 - val_loss: 2.8658 - val_accuracy: 0.5119\n",
            "Epoch 1094/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3549 - accuracy: 0.8739 - val_loss: 2.9068 - val_accuracy: 0.4908\n",
            "Epoch 1095/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3885 - accuracy: 0.8609 - val_loss: 3.1245 - val_accuracy: 0.4591\n",
            "Epoch 1096/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3835 - accuracy: 0.8586 - val_loss: 3.1411 - val_accuracy: 0.4802\n",
            "Epoch 1097/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3829 - accuracy: 0.8648 - val_loss: 2.9539 - val_accuracy: 0.5066\n",
            "Epoch 1098/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3515 - accuracy: 0.8795 - val_loss: 2.9295 - val_accuracy: 0.4960\n",
            "Epoch 1099/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3600 - accuracy: 0.8688 - val_loss: 3.0272 - val_accuracy: 0.4828\n",
            "Epoch 1100/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3195 - accuracy: 0.8903 - val_loss: 2.9814 - val_accuracy: 0.5092\n",
            "Epoch 1101/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3164 - accuracy: 0.8942 - val_loss: 3.0254 - val_accuracy: 0.4670\n",
            "Epoch 1102/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3003 - accuracy: 0.9027 - val_loss: 2.9439 - val_accuracy: 0.5172\n",
            "Epoch 1103/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3717 - accuracy: 0.8597 - val_loss: 3.0045 - val_accuracy: 0.5119\n",
            "Epoch 1104/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3926 - accuracy: 0.8671 - val_loss: 3.0302 - val_accuracy: 0.4749\n",
            "Epoch 1105/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3449 - accuracy: 0.8784 - val_loss: 3.0354 - val_accuracy: 0.4934\n",
            "Epoch 1106/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3332 - accuracy: 0.8857 - val_loss: 3.0199 - val_accuracy: 0.4881\n",
            "Epoch 1107/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3526 - accuracy: 0.8676 - val_loss: 2.9263 - val_accuracy: 0.4749\n",
            "Epoch 1108/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3336 - accuracy: 0.8829 - val_loss: 3.0102 - val_accuracy: 0.5066\n",
            "Epoch 1109/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3337 - accuracy: 0.8807 - val_loss: 2.9502 - val_accuracy: 0.5092\n",
            "Epoch 1110/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3418 - accuracy: 0.8784 - val_loss: 3.4311 - val_accuracy: 0.4591\n",
            "Epoch 1111/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3815 - accuracy: 0.8637 - val_loss: 3.0519 - val_accuracy: 0.4749\n",
            "Epoch 1112/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3668 - accuracy: 0.8660 - val_loss: 3.0220 - val_accuracy: 0.4749\n",
            "Epoch 1113/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4139 - accuracy: 0.8518 - val_loss: 3.0475 - val_accuracy: 0.5224\n",
            "Epoch 1114/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3353 - accuracy: 0.8767 - val_loss: 2.9347 - val_accuracy: 0.5119\n",
            "Epoch 1115/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3214 - accuracy: 0.8914 - val_loss: 2.8800 - val_accuracy: 0.4934\n",
            "Epoch 1116/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3352 - accuracy: 0.8767 - val_loss: 3.1470 - val_accuracy: 0.4934\n",
            "Epoch 1117/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4174 - accuracy: 0.8495 - val_loss: 3.0953 - val_accuracy: 0.4908\n",
            "Epoch 1118/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3662 - accuracy: 0.8750 - val_loss: 2.9767 - val_accuracy: 0.4960\n",
            "Epoch 1119/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3831 - accuracy: 0.8609 - val_loss: 3.4752 - val_accuracy: 0.4538\n",
            "Epoch 1120/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4083 - accuracy: 0.8507 - val_loss: 2.9931 - val_accuracy: 0.5040\n",
            "Epoch 1121/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3454 - accuracy: 0.8807 - val_loss: 3.0476 - val_accuracy: 0.4960\n",
            "Epoch 1122/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3694 - accuracy: 0.8739 - val_loss: 3.0604 - val_accuracy: 0.4908\n",
            "Epoch 1123/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3729 - accuracy: 0.8688 - val_loss: 3.0643 - val_accuracy: 0.4828\n",
            "Epoch 1124/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3346 - accuracy: 0.8852 - val_loss: 3.0303 - val_accuracy: 0.5145\n",
            "Epoch 1125/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3153 - accuracy: 0.8914 - val_loss: 2.9738 - val_accuracy: 0.5013\n",
            "Epoch 1126/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3365 - accuracy: 0.8801 - val_loss: 3.1063 - val_accuracy: 0.4723\n",
            "Epoch 1127/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3319 - accuracy: 0.8778 - val_loss: 3.1129 - val_accuracy: 0.4881\n",
            "Epoch 1128/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3423 - accuracy: 0.8767 - val_loss: 2.9818 - val_accuracy: 0.4987\n",
            "Epoch 1129/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3544 - accuracy: 0.8807 - val_loss: 2.9971 - val_accuracy: 0.4987\n",
            "Epoch 1130/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3372 - accuracy: 0.8852 - val_loss: 2.9425 - val_accuracy: 0.5224\n",
            "Epoch 1131/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3945 - accuracy: 0.8654 - val_loss: 3.0351 - val_accuracy: 0.4670\n",
            "Epoch 1132/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4273 - accuracy: 0.8524 - val_loss: 3.0720 - val_accuracy: 0.4934\n",
            "Epoch 1133/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4084 - accuracy: 0.8490 - val_loss: 2.9066 - val_accuracy: 0.4828\n",
            "Epoch 1134/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3468 - accuracy: 0.8824 - val_loss: 2.9914 - val_accuracy: 0.5092\n",
            "Epoch 1135/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3163 - accuracy: 0.8908 - val_loss: 3.0248 - val_accuracy: 0.5013\n",
            "Epoch 1136/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3557 - accuracy: 0.8733 - val_loss: 3.1771 - val_accuracy: 0.4855\n",
            "Epoch 1137/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4182 - accuracy: 0.8456 - val_loss: 3.0016 - val_accuracy: 0.4723\n",
            "Epoch 1138/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3728 - accuracy: 0.8733 - val_loss: 3.0791 - val_accuracy: 0.5224\n",
            "Epoch 1139/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3634 - accuracy: 0.8626 - val_loss: 3.0785 - val_accuracy: 0.4908\n",
            "Epoch 1140/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3256 - accuracy: 0.8829 - val_loss: 2.9814 - val_accuracy: 0.5172\n",
            "Epoch 1141/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3305 - accuracy: 0.8829 - val_loss: 3.1019 - val_accuracy: 0.4960\n",
            "Epoch 1142/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4160 - accuracy: 0.8394 - val_loss: 2.9865 - val_accuracy: 0.5092\n",
            "Epoch 1143/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3260 - accuracy: 0.8886 - val_loss: 3.0723 - val_accuracy: 0.4644\n",
            "Epoch 1144/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3582 - accuracy: 0.8643 - val_loss: 3.0812 - val_accuracy: 0.4960\n",
            "Epoch 1145/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3244 - accuracy: 0.8790 - val_loss: 2.9608 - val_accuracy: 0.5224\n",
            "Epoch 1146/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3667 - accuracy: 0.8699 - val_loss: 3.0711 - val_accuracy: 0.5092\n",
            "Epoch 1147/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3738 - accuracy: 0.8693 - val_loss: 3.1269 - val_accuracy: 0.4881\n",
            "Epoch 1148/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3320 - accuracy: 0.8756 - val_loss: 3.0935 - val_accuracy: 0.4749\n",
            "Epoch 1149/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3841 - accuracy: 0.8722 - val_loss: 2.8882 - val_accuracy: 0.5251\n",
            "Epoch 1150/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3341 - accuracy: 0.8829 - val_loss: 2.9530 - val_accuracy: 0.5013\n",
            "Epoch 1151/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3647 - accuracy: 0.8671 - val_loss: 3.0487 - val_accuracy: 0.4802\n",
            "Epoch 1152/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3591 - accuracy: 0.8756 - val_loss: 3.0304 - val_accuracy: 0.4802\n",
            "Epoch 1153/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3260 - accuracy: 0.8931 - val_loss: 3.0634 - val_accuracy: 0.4960\n",
            "Epoch 1154/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3538 - accuracy: 0.8727 - val_loss: 3.2544 - val_accuracy: 0.4723\n",
            "Epoch 1155/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3913 - accuracy: 0.8609 - val_loss: 3.0313 - val_accuracy: 0.4960\n",
            "Epoch 1156/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3115 - accuracy: 0.8959 - val_loss: 3.2498 - val_accuracy: 0.4723\n",
            "Epoch 1157/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3621 - accuracy: 0.8795 - val_loss: 3.0204 - val_accuracy: 0.4828\n",
            "Epoch 1158/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3158 - accuracy: 0.8908 - val_loss: 3.0310 - val_accuracy: 0.4828\n",
            "Epoch 1159/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3243 - accuracy: 0.8891 - val_loss: 3.0598 - val_accuracy: 0.5013\n",
            "Epoch 1160/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2933 - accuracy: 0.9021 - val_loss: 2.9770 - val_accuracy: 0.5013\n",
            "Epoch 1161/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3609 - accuracy: 0.8733 - val_loss: 3.1149 - val_accuracy: 0.5092\n",
            "Epoch 1162/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3432 - accuracy: 0.8756 - val_loss: 3.3101 - val_accuracy: 0.4565\n",
            "Epoch 1163/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3338 - accuracy: 0.8829 - val_loss: 3.0710 - val_accuracy: 0.4855\n",
            "Epoch 1164/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3042 - accuracy: 0.8937 - val_loss: 3.2056 - val_accuracy: 0.5013\n",
            "Epoch 1165/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3013 - accuracy: 0.9021 - val_loss: 3.0113 - val_accuracy: 0.5119\n",
            "Epoch 1166/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3158 - accuracy: 0.9021 - val_loss: 3.1121 - val_accuracy: 0.4934\n",
            "Epoch 1167/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3238 - accuracy: 0.8807 - val_loss: 3.4157 - val_accuracy: 0.4485\n",
            "Epoch 1168/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4274 - accuracy: 0.8490 - val_loss: 3.6147 - val_accuracy: 0.4591\n",
            "Epoch 1169/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4094 - accuracy: 0.8558 - val_loss: 3.0123 - val_accuracy: 0.4934\n",
            "Epoch 1170/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3794 - accuracy: 0.8563 - val_loss: 3.0316 - val_accuracy: 0.4934\n",
            "Epoch 1171/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3328 - accuracy: 0.8874 - val_loss: 3.0002 - val_accuracy: 0.4960\n",
            "Epoch 1172/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3563 - accuracy: 0.8761 - val_loss: 3.1727 - val_accuracy: 0.5013\n",
            "Epoch 1173/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4115 - accuracy: 0.8382 - val_loss: 3.5733 - val_accuracy: 0.4644\n",
            "Epoch 1174/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4720 - accuracy: 0.8230 - val_loss: 3.0989 - val_accuracy: 0.5040\n",
            "Epoch 1175/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3674 - accuracy: 0.8716 - val_loss: 3.1518 - val_accuracy: 0.5092\n",
            "Epoch 1176/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3483 - accuracy: 0.8778 - val_loss: 3.0996 - val_accuracy: 0.4881\n",
            "Epoch 1177/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3984 - accuracy: 0.8524 - val_loss: 2.9525 - val_accuracy: 0.5119\n",
            "Epoch 1178/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3100 - accuracy: 0.8891 - val_loss: 3.0674 - val_accuracy: 0.5145\n",
            "Epoch 1179/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2865 - accuracy: 0.9033 - val_loss: 3.1154 - val_accuracy: 0.4987\n",
            "Epoch 1180/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2930 - accuracy: 0.8999 - val_loss: 3.0737 - val_accuracy: 0.4960\n",
            "Epoch 1181/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3142 - accuracy: 0.8903 - val_loss: 3.0936 - val_accuracy: 0.4802\n",
            "Epoch 1182/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3606 - accuracy: 0.8710 - val_loss: 3.1881 - val_accuracy: 0.4881\n",
            "Epoch 1183/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3050 - accuracy: 0.8993 - val_loss: 3.0118 - val_accuracy: 0.5145\n",
            "Epoch 1184/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3029 - accuracy: 0.9021 - val_loss: 3.4551 - val_accuracy: 0.4881\n",
            "Epoch 1185/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3976 - accuracy: 0.8524 - val_loss: 2.9558 - val_accuracy: 0.4802\n",
            "Epoch 1186/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3431 - accuracy: 0.8824 - val_loss: 3.1401 - val_accuracy: 0.4881\n",
            "Epoch 1187/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3125 - accuracy: 0.8942 - val_loss: 2.9687 - val_accuracy: 0.4802\n",
            "Epoch 1188/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3363 - accuracy: 0.8807 - val_loss: 2.9739 - val_accuracy: 0.5119\n",
            "Epoch 1189/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3466 - accuracy: 0.8818 - val_loss: 3.0388 - val_accuracy: 0.5198\n",
            "Epoch 1190/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3219 - accuracy: 0.8857 - val_loss: 3.3467 - val_accuracy: 0.4433\n",
            "Epoch 1191/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3781 - accuracy: 0.8626 - val_loss: 3.1271 - val_accuracy: 0.4987\n",
            "Epoch 1192/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3683 - accuracy: 0.8665 - val_loss: 3.3425 - val_accuracy: 0.5066\n",
            "Epoch 1193/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3215 - accuracy: 0.8880 - val_loss: 3.2434 - val_accuracy: 0.4960\n",
            "Epoch 1194/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3424 - accuracy: 0.8812 - val_loss: 2.9919 - val_accuracy: 0.4828\n",
            "Epoch 1195/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2832 - accuracy: 0.9061 - val_loss: 3.0584 - val_accuracy: 0.4855\n",
            "Epoch 1196/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2993 - accuracy: 0.8920 - val_loss: 3.2143 - val_accuracy: 0.4855\n",
            "Epoch 1197/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3271 - accuracy: 0.8846 - val_loss: 3.1088 - val_accuracy: 0.4670\n",
            "Epoch 1198/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3311 - accuracy: 0.8846 - val_loss: 3.0809 - val_accuracy: 0.4855\n",
            "Epoch 1199/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3056 - accuracy: 0.8925 - val_loss: 3.3379 - val_accuracy: 0.4934\n",
            "Epoch 1200/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3320 - accuracy: 0.8824 - val_loss: 3.1617 - val_accuracy: 0.4881\n",
            "Epoch 1201/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3477 - accuracy: 0.8784 - val_loss: 3.0103 - val_accuracy: 0.5040\n",
            "Epoch 1202/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3309 - accuracy: 0.8818 - val_loss: 3.0160 - val_accuracy: 0.5277\n",
            "Epoch 1203/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3138 - accuracy: 0.8908 - val_loss: 3.2051 - val_accuracy: 0.4828\n",
            "Epoch 1204/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3152 - accuracy: 0.8835 - val_loss: 3.0149 - val_accuracy: 0.5198\n",
            "Epoch 1205/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3221 - accuracy: 0.8891 - val_loss: 3.0868 - val_accuracy: 0.5145\n",
            "Epoch 1206/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2797 - accuracy: 0.9112 - val_loss: 3.0237 - val_accuracy: 0.5013\n",
            "Epoch 1207/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3234 - accuracy: 0.8931 - val_loss: 3.0210 - val_accuracy: 0.4723\n",
            "Epoch 1208/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3310 - accuracy: 0.8795 - val_loss: 3.1595 - val_accuracy: 0.4960\n",
            "Epoch 1209/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3035 - accuracy: 0.8942 - val_loss: 3.1595 - val_accuracy: 0.5172\n",
            "Epoch 1210/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3195 - accuracy: 0.8857 - val_loss: 3.0792 - val_accuracy: 0.4960\n",
            "Epoch 1211/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3358 - accuracy: 0.8840 - val_loss: 3.5454 - val_accuracy: 0.4565\n",
            "Epoch 1212/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3761 - accuracy: 0.8688 - val_loss: 3.0911 - val_accuracy: 0.4987\n",
            "Epoch 1213/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3166 - accuracy: 0.8908 - val_loss: 3.3967 - val_accuracy: 0.4591\n",
            "Epoch 1214/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3022 - accuracy: 0.8959 - val_loss: 3.0516 - val_accuracy: 0.5092\n",
            "Epoch 1215/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3073 - accuracy: 0.9021 - val_loss: 3.0432 - val_accuracy: 0.5092\n",
            "Epoch 1216/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3114 - accuracy: 0.8863 - val_loss: 3.5366 - val_accuracy: 0.4802\n",
            "Epoch 1217/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3377 - accuracy: 0.8767 - val_loss: 3.2130 - val_accuracy: 0.4934\n",
            "Epoch 1218/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3347 - accuracy: 0.8818 - val_loss: 3.3394 - val_accuracy: 0.4670\n",
            "Epoch 1219/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4246 - accuracy: 0.8456 - val_loss: 3.2921 - val_accuracy: 0.4749\n",
            "Epoch 1220/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3093 - accuracy: 0.8920 - val_loss: 3.0861 - val_accuracy: 0.5251\n",
            "Epoch 1221/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3026 - accuracy: 0.8982 - val_loss: 3.2297 - val_accuracy: 0.5040\n",
            "Epoch 1222/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4081 - accuracy: 0.8563 - val_loss: 3.1934 - val_accuracy: 0.4802\n",
            "Epoch 1223/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3048 - accuracy: 0.8937 - val_loss: 3.2074 - val_accuracy: 0.5119\n",
            "Epoch 1224/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2888 - accuracy: 0.9038 - val_loss: 3.3173 - val_accuracy: 0.5172\n",
            "Epoch 1225/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3377 - accuracy: 0.8767 - val_loss: 3.7927 - val_accuracy: 0.4485\n",
            "Epoch 1226/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3900 - accuracy: 0.8637 - val_loss: 3.3511 - val_accuracy: 0.5040\n",
            "Epoch 1227/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3638 - accuracy: 0.8693 - val_loss: 3.4162 - val_accuracy: 0.4512\n",
            "Epoch 1228/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3856 - accuracy: 0.8592 - val_loss: 3.1433 - val_accuracy: 0.5013\n",
            "Epoch 1229/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3288 - accuracy: 0.8852 - val_loss: 3.2148 - val_accuracy: 0.4960\n",
            "Epoch 1230/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3805 - accuracy: 0.8654 - val_loss: 3.1712 - val_accuracy: 0.4960\n",
            "Epoch 1231/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3078 - accuracy: 0.8988 - val_loss: 3.1486 - val_accuracy: 0.5198\n",
            "Epoch 1232/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2779 - accuracy: 0.9118 - val_loss: 3.2476 - val_accuracy: 0.4828\n",
            "Epoch 1233/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3426 - accuracy: 0.8790 - val_loss: 3.3505 - val_accuracy: 0.4855\n",
            "Epoch 1234/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3253 - accuracy: 0.8891 - val_loss: 3.2770 - val_accuracy: 0.4723\n",
            "Epoch 1235/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3180 - accuracy: 0.8920 - val_loss: 3.0968 - val_accuracy: 0.5224\n",
            "Epoch 1236/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3196 - accuracy: 0.8908 - val_loss: 3.1865 - val_accuracy: 0.5092\n",
            "Epoch 1237/1500\n",
            "56/56 [==============================] - 3s 47ms/step - loss: 0.3412 - accuracy: 0.8744 - val_loss: 3.1842 - val_accuracy: 0.5040\n",
            "Epoch 1238/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.2832 - accuracy: 0.9005 - val_loss: 3.3048 - val_accuracy: 0.4934\n",
            "Epoch 1239/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2714 - accuracy: 0.9123 - val_loss: 3.1673 - val_accuracy: 0.5066\n",
            "Epoch 1240/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2983 - accuracy: 0.8993 - val_loss: 3.2488 - val_accuracy: 0.4644\n",
            "Epoch 1241/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3167 - accuracy: 0.8942 - val_loss: 3.2687 - val_accuracy: 0.4881\n",
            "Epoch 1242/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.2995 - accuracy: 0.8937 - val_loss: 3.0691 - val_accuracy: 0.5277\n",
            "Epoch 1243/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3007 - accuracy: 0.8959 - val_loss: 3.3382 - val_accuracy: 0.4644\n",
            "Epoch 1244/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3274 - accuracy: 0.8824 - val_loss: 3.2775 - val_accuracy: 0.4749\n",
            "Epoch 1245/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3199 - accuracy: 0.8795 - val_loss: 3.1063 - val_accuracy: 0.5119\n",
            "Epoch 1246/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.3694 - accuracy: 0.8637 - val_loss: 3.0685 - val_accuracy: 0.5066\n",
            "Epoch 1247/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.3146 - accuracy: 0.8925 - val_loss: 3.2666 - val_accuracy: 0.4828\n",
            "Epoch 1248/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2976 - accuracy: 0.9033 - val_loss: 3.2004 - val_accuracy: 0.5040\n",
            "Epoch 1249/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3642 - accuracy: 0.8597 - val_loss: 3.1903 - val_accuracy: 0.4697\n",
            "Epoch 1250/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2965 - accuracy: 0.8954 - val_loss: 3.2903 - val_accuracy: 0.4802\n",
            "Epoch 1251/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3056 - accuracy: 0.8937 - val_loss: 3.2082 - val_accuracy: 0.4855\n",
            "Epoch 1252/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.3107 - accuracy: 0.8931 - val_loss: 3.1769 - val_accuracy: 0.5066\n",
            "Epoch 1253/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.2781 - accuracy: 0.9016 - val_loss: 3.1735 - val_accuracy: 0.5172\n",
            "Epoch 1254/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2981 - accuracy: 0.8965 - val_loss: 3.1673 - val_accuracy: 0.5198\n",
            "Epoch 1255/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3253 - accuracy: 0.8824 - val_loss: 3.5567 - val_accuracy: 0.4327\n",
            "Epoch 1256/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 0.3468 - accuracy: 0.8778 - val_loss: 3.4417 - val_accuracy: 0.4723\n",
            "Epoch 1257/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3295 - accuracy: 0.8756 - val_loss: 3.3814 - val_accuracy: 0.4697\n",
            "Epoch 1258/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3432 - accuracy: 0.8835 - val_loss: 3.4258 - val_accuracy: 0.4776\n",
            "Epoch 1259/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3770 - accuracy: 0.8586 - val_loss: 3.3250 - val_accuracy: 0.4802\n",
            "Epoch 1260/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.3545 - accuracy: 0.8710 - val_loss: 3.2017 - val_accuracy: 0.5172\n",
            "Epoch 1261/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3984 - accuracy: 0.8552 - val_loss: 3.2092 - val_accuracy: 0.5172\n",
            "Epoch 1262/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3333 - accuracy: 0.8937 - val_loss: 3.1374 - val_accuracy: 0.4960\n",
            "Epoch 1263/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3373 - accuracy: 0.8744 - val_loss: 3.3331 - val_accuracy: 0.4723\n",
            "Epoch 1264/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3325 - accuracy: 0.8801 - val_loss: 3.2112 - val_accuracy: 0.4960\n",
            "Epoch 1265/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3335 - accuracy: 0.8857 - val_loss: 3.3303 - val_accuracy: 0.4802\n",
            "Epoch 1266/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2724 - accuracy: 0.9118 - val_loss: 3.3012 - val_accuracy: 0.5066\n",
            "Epoch 1267/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3543 - accuracy: 0.8676 - val_loss: 3.1954 - val_accuracy: 0.4881\n",
            "Epoch 1268/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2864 - accuracy: 0.9010 - val_loss: 3.2140 - val_accuracy: 0.5172\n",
            "Epoch 1269/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2940 - accuracy: 0.8999 - val_loss: 3.2843 - val_accuracy: 0.4934\n",
            "Epoch 1270/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3124 - accuracy: 0.8790 - val_loss: 3.2259 - val_accuracy: 0.5013\n",
            "Epoch 1271/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.2978 - accuracy: 0.8993 - val_loss: 3.1287 - val_accuracy: 0.4960\n",
            "Epoch 1272/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3412 - accuracy: 0.8761 - val_loss: 3.1857 - val_accuracy: 0.5040\n",
            "Epoch 1273/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3141 - accuracy: 0.8863 - val_loss: 3.3634 - val_accuracy: 0.4855\n",
            "Epoch 1274/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2693 - accuracy: 0.9112 - val_loss: 3.2559 - val_accuracy: 0.5066\n",
            "Epoch 1275/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3206 - accuracy: 0.8863 - val_loss: 3.1760 - val_accuracy: 0.4908\n",
            "Epoch 1276/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3595 - accuracy: 0.8676 - val_loss: 3.2448 - val_accuracy: 0.4749\n",
            "Epoch 1277/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3411 - accuracy: 0.8722 - val_loss: 3.2739 - val_accuracy: 0.5013\n",
            "Epoch 1278/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2993 - accuracy: 0.8982 - val_loss: 3.2134 - val_accuracy: 0.4960\n",
            "Epoch 1279/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2879 - accuracy: 0.9010 - val_loss: 3.5008 - val_accuracy: 0.4433\n",
            "Epoch 1280/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3003 - accuracy: 0.8920 - val_loss: 3.1858 - val_accuracy: 0.5013\n",
            "Epoch 1281/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2707 - accuracy: 0.9027 - val_loss: 3.2392 - val_accuracy: 0.4908\n",
            "Epoch 1282/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2984 - accuracy: 0.8976 - val_loss: 3.2427 - val_accuracy: 0.4960\n",
            "Epoch 1283/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3049 - accuracy: 0.8965 - val_loss: 3.1564 - val_accuracy: 0.5040\n",
            "Epoch 1284/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2973 - accuracy: 0.9016 - val_loss: 3.4715 - val_accuracy: 0.4697\n",
            "Epoch 1285/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3852 - accuracy: 0.8586 - val_loss: 3.4178 - val_accuracy: 0.4723\n",
            "Epoch 1286/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.4557 - accuracy: 0.8450 - val_loss: 3.2864 - val_accuracy: 0.5172\n",
            "Epoch 1287/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2934 - accuracy: 0.9005 - val_loss: 3.1909 - val_accuracy: 0.5277\n",
            "Epoch 1288/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2649 - accuracy: 0.9146 - val_loss: 3.1611 - val_accuracy: 0.5013\n",
            "Epoch 1289/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3094 - accuracy: 0.8886 - val_loss: 3.3579 - val_accuracy: 0.5092\n",
            "Epoch 1290/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2850 - accuracy: 0.9005 - val_loss: 3.2704 - val_accuracy: 0.5092\n",
            "Epoch 1291/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3010 - accuracy: 0.8914 - val_loss: 3.1930 - val_accuracy: 0.4987\n",
            "Epoch 1292/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3334 - accuracy: 0.8869 - val_loss: 3.2612 - val_accuracy: 0.4908\n",
            "Epoch 1293/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3102 - accuracy: 0.8914 - val_loss: 3.3915 - val_accuracy: 0.4697\n",
            "Epoch 1294/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2976 - accuracy: 0.9033 - val_loss: 3.3065 - val_accuracy: 0.4960\n",
            "Epoch 1295/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3012 - accuracy: 0.8920 - val_loss: 3.4284 - val_accuracy: 0.4433\n",
            "Epoch 1296/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2933 - accuracy: 0.8897 - val_loss: 3.2251 - val_accuracy: 0.5066\n",
            "Epoch 1297/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3131 - accuracy: 0.8874 - val_loss: 3.3197 - val_accuracy: 0.5040\n",
            "Epoch 1298/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2856 - accuracy: 0.9033 - val_loss: 3.2351 - val_accuracy: 0.5013\n",
            "Epoch 1299/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2897 - accuracy: 0.9055 - val_loss: 3.2732 - val_accuracy: 0.5224\n",
            "Epoch 1300/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3429 - accuracy: 0.8699 - val_loss: 3.3446 - val_accuracy: 0.4749\n",
            "Epoch 1301/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3090 - accuracy: 0.8886 - val_loss: 3.3388 - val_accuracy: 0.4881\n",
            "Epoch 1302/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2584 - accuracy: 0.9152 - val_loss: 3.1800 - val_accuracy: 0.4828\n",
            "Epoch 1303/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3166 - accuracy: 0.8908 - val_loss: 3.2100 - val_accuracy: 0.4960\n",
            "Epoch 1304/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3008 - accuracy: 0.8920 - val_loss: 3.3279 - val_accuracy: 0.4881\n",
            "Epoch 1305/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3079 - accuracy: 0.8886 - val_loss: 3.1899 - val_accuracy: 0.5066\n",
            "Epoch 1306/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3593 - accuracy: 0.8626 - val_loss: 3.3861 - val_accuracy: 0.4855\n",
            "Epoch 1307/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3483 - accuracy: 0.8733 - val_loss: 3.5287 - val_accuracy: 0.4987\n",
            "Epoch 1308/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3128 - accuracy: 0.8795 - val_loss: 3.2352 - val_accuracy: 0.4960\n",
            "Epoch 1309/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3136 - accuracy: 0.8965 - val_loss: 3.2991 - val_accuracy: 0.4802\n",
            "Epoch 1310/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2976 - accuracy: 0.8880 - val_loss: 3.6018 - val_accuracy: 0.4802\n",
            "Epoch 1311/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3799 - accuracy: 0.8631 - val_loss: 3.3640 - val_accuracy: 0.4749\n",
            "Epoch 1312/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3030 - accuracy: 0.8948 - val_loss: 3.2826 - val_accuracy: 0.5172\n",
            "Epoch 1313/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2576 - accuracy: 0.9118 - val_loss: 3.2577 - val_accuracy: 0.4960\n",
            "Epoch 1314/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2526 - accuracy: 0.9174 - val_loss: 3.3485 - val_accuracy: 0.4723\n",
            "Epoch 1315/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3051 - accuracy: 0.8908 - val_loss: 3.4128 - val_accuracy: 0.4881\n",
            "Epoch 1316/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2750 - accuracy: 0.8988 - val_loss: 3.3327 - val_accuracy: 0.4881\n",
            "Epoch 1317/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2649 - accuracy: 0.9123 - val_loss: 3.2270 - val_accuracy: 0.4881\n",
            "Epoch 1318/1500\n",
            "56/56 [==============================] - 2s 44ms/step - loss: 0.2926 - accuracy: 0.8937 - val_loss: 3.3378 - val_accuracy: 0.5040\n",
            "Epoch 1319/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2739 - accuracy: 0.9106 - val_loss: 3.4743 - val_accuracy: 0.4644\n",
            "Epoch 1320/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2987 - accuracy: 0.8954 - val_loss: 3.3333 - val_accuracy: 0.4934\n",
            "Epoch 1321/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3083 - accuracy: 0.8925 - val_loss: 3.3419 - val_accuracy: 0.4776\n",
            "Epoch 1322/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2778 - accuracy: 0.9101 - val_loss: 3.1241 - val_accuracy: 0.5092\n",
            "Epoch 1323/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2488 - accuracy: 0.9180 - val_loss: 3.2784 - val_accuracy: 0.4908\n",
            "Epoch 1324/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2722 - accuracy: 0.9072 - val_loss: 3.2868 - val_accuracy: 0.5251\n",
            "Epoch 1325/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2723 - accuracy: 0.9095 - val_loss: 3.7230 - val_accuracy: 0.4195\n",
            "Epoch 1326/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3971 - accuracy: 0.8495 - val_loss: 3.4437 - val_accuracy: 0.5172\n",
            "Epoch 1327/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4006 - accuracy: 0.8428 - val_loss: 3.1445 - val_accuracy: 0.4670\n",
            "Epoch 1328/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3063 - accuracy: 0.8920 - val_loss: 3.4248 - val_accuracy: 0.4802\n",
            "Epoch 1329/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3753 - accuracy: 0.8597 - val_loss: 3.4554 - val_accuracy: 0.4459\n",
            "Epoch 1330/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3355 - accuracy: 0.8773 - val_loss: 3.2919 - val_accuracy: 0.5119\n",
            "Epoch 1331/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3093 - accuracy: 0.8965 - val_loss: 3.2915 - val_accuracy: 0.5198\n",
            "Epoch 1332/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3850 - accuracy: 0.8631 - val_loss: 3.3356 - val_accuracy: 0.4776\n",
            "Epoch 1333/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3448 - accuracy: 0.8761 - val_loss: 3.5186 - val_accuracy: 0.4881\n",
            "Epoch 1334/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3656 - accuracy: 0.8682 - val_loss: 3.2972 - val_accuracy: 0.4802\n",
            "Epoch 1335/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3356 - accuracy: 0.8750 - val_loss: 3.3908 - val_accuracy: 0.5040\n",
            "Epoch 1336/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2977 - accuracy: 0.8965 - val_loss: 3.5286 - val_accuracy: 0.4855\n",
            "Epoch 1337/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2665 - accuracy: 0.9163 - val_loss: 3.3814 - val_accuracy: 0.4776\n",
            "Epoch 1338/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2596 - accuracy: 0.9191 - val_loss: 3.4073 - val_accuracy: 0.4776\n",
            "Epoch 1339/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3194 - accuracy: 0.8897 - val_loss: 3.2511 - val_accuracy: 0.5251\n",
            "Epoch 1340/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2788 - accuracy: 0.9050 - val_loss: 3.4221 - val_accuracy: 0.5092\n",
            "Epoch 1341/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2977 - accuracy: 0.8976 - val_loss: 3.3544 - val_accuracy: 0.5198\n",
            "Epoch 1342/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3123 - accuracy: 0.8840 - val_loss: 3.3361 - val_accuracy: 0.4644\n",
            "Epoch 1343/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2820 - accuracy: 0.9016 - val_loss: 3.2917 - val_accuracy: 0.5172\n",
            "Epoch 1344/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2799 - accuracy: 0.9078 - val_loss: 3.2387 - val_accuracy: 0.5251\n",
            "Epoch 1345/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3474 - accuracy: 0.8795 - val_loss: 3.3540 - val_accuracy: 0.4749\n",
            "Epoch 1346/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2525 - accuracy: 0.9191 - val_loss: 3.3123 - val_accuracy: 0.4749\n",
            "Epoch 1347/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2972 - accuracy: 0.8954 - val_loss: 3.2531 - val_accuracy: 0.5013\n",
            "Epoch 1348/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2617 - accuracy: 0.9072 - val_loss: 3.3120 - val_accuracy: 0.4802\n",
            "Epoch 1349/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2384 - accuracy: 0.9180 - val_loss: 3.4694 - val_accuracy: 0.4776\n",
            "Epoch 1350/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3342 - accuracy: 0.8846 - val_loss: 3.2627 - val_accuracy: 0.5040\n",
            "Epoch 1351/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3101 - accuracy: 0.8880 - val_loss: 3.3427 - val_accuracy: 0.4723\n",
            "Epoch 1352/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2769 - accuracy: 0.9089 - val_loss: 3.3893 - val_accuracy: 0.4987\n",
            "Epoch 1353/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2796 - accuracy: 0.8993 - val_loss: 3.3997 - val_accuracy: 0.4565\n",
            "Epoch 1354/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2662 - accuracy: 0.9055 - val_loss: 3.2533 - val_accuracy: 0.4987\n",
            "Epoch 1355/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2898 - accuracy: 0.8971 - val_loss: 3.4200 - val_accuracy: 0.4934\n",
            "Epoch 1356/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3014 - accuracy: 0.8920 - val_loss: 3.4956 - val_accuracy: 0.4617\n",
            "Epoch 1357/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3680 - accuracy: 0.8688 - val_loss: 3.3890 - val_accuracy: 0.4828\n",
            "Epoch 1358/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2534 - accuracy: 0.9186 - val_loss: 3.4859 - val_accuracy: 0.4776\n",
            "Epoch 1359/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2843 - accuracy: 0.9016 - val_loss: 3.3072 - val_accuracy: 0.4776\n",
            "Epoch 1360/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2936 - accuracy: 0.8993 - val_loss: 3.5767 - val_accuracy: 0.4591\n",
            "Epoch 1361/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3127 - accuracy: 0.8824 - val_loss: 3.3378 - val_accuracy: 0.4802\n",
            "Epoch 1362/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2753 - accuracy: 0.9044 - val_loss: 3.4469 - val_accuracy: 0.5092\n",
            "Epoch 1363/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2986 - accuracy: 0.9010 - val_loss: 3.6435 - val_accuracy: 0.5013\n",
            "Epoch 1364/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3276 - accuracy: 0.8891 - val_loss: 3.2814 - val_accuracy: 0.5119\n",
            "Epoch 1365/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2607 - accuracy: 0.9106 - val_loss: 3.4810 - val_accuracy: 0.4723\n",
            "Epoch 1366/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3000 - accuracy: 0.8971 - val_loss: 3.4036 - val_accuracy: 0.5013\n",
            "Epoch 1367/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3782 - accuracy: 0.8603 - val_loss: 3.4174 - val_accuracy: 0.4987\n",
            "Epoch 1368/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4519 - accuracy: 0.8371 - val_loss: 3.3587 - val_accuracy: 0.4934\n",
            "Epoch 1369/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3357 - accuracy: 0.8852 - val_loss: 3.2983 - val_accuracy: 0.5092\n",
            "Epoch 1370/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2481 - accuracy: 0.9152 - val_loss: 3.4497 - val_accuracy: 0.4908\n",
            "Epoch 1371/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2629 - accuracy: 0.9163 - val_loss: 3.5424 - val_accuracy: 0.4987\n",
            "Epoch 1372/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2764 - accuracy: 0.9033 - val_loss: 3.4940 - val_accuracy: 0.4776\n",
            "Epoch 1373/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2772 - accuracy: 0.9016 - val_loss: 3.3441 - val_accuracy: 0.5013\n",
            "Epoch 1374/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2791 - accuracy: 0.9027 - val_loss: 3.5133 - val_accuracy: 0.4828\n",
            "Epoch 1375/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2890 - accuracy: 0.8948 - val_loss: 3.4472 - val_accuracy: 0.4934\n",
            "Epoch 1376/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3535 - accuracy: 0.8773 - val_loss: 3.4376 - val_accuracy: 0.4828\n",
            "Epoch 1377/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2922 - accuracy: 0.8925 - val_loss: 3.3953 - val_accuracy: 0.4802\n",
            "Epoch 1378/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2510 - accuracy: 0.9174 - val_loss: 3.5609 - val_accuracy: 0.4828\n",
            "Epoch 1379/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2760 - accuracy: 0.9044 - val_loss: 3.2702 - val_accuracy: 0.5145\n",
            "Epoch 1380/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2910 - accuracy: 0.8993 - val_loss: 3.5345 - val_accuracy: 0.4960\n",
            "Epoch 1381/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2649 - accuracy: 0.9078 - val_loss: 3.2587 - val_accuracy: 0.5066\n",
            "Epoch 1382/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2720 - accuracy: 0.9084 - val_loss: 3.4486 - val_accuracy: 0.4987\n",
            "Epoch 1383/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2478 - accuracy: 0.9095 - val_loss: 3.3692 - val_accuracy: 0.5145\n",
            "Epoch 1384/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3166 - accuracy: 0.8880 - val_loss: 3.6258 - val_accuracy: 0.4644\n",
            "Epoch 1385/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3497 - accuracy: 0.8665 - val_loss: 3.2292 - val_accuracy: 0.5172\n",
            "Epoch 1386/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2861 - accuracy: 0.8999 - val_loss: 3.6447 - val_accuracy: 0.4828\n",
            "Epoch 1387/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2645 - accuracy: 0.9089 - val_loss: 3.3789 - val_accuracy: 0.4987\n",
            "Epoch 1388/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2521 - accuracy: 0.9146 - val_loss: 3.4833 - val_accuracy: 0.4749\n",
            "Epoch 1389/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2718 - accuracy: 0.9027 - val_loss: 3.2728 - val_accuracy: 0.5277\n",
            "Epoch 1390/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2627 - accuracy: 0.9067 - val_loss: 3.3383 - val_accuracy: 0.5066\n",
            "Epoch 1391/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2478 - accuracy: 0.9191 - val_loss: 3.3034 - val_accuracy: 0.5066\n",
            "Epoch 1392/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2650 - accuracy: 0.9157 - val_loss: 3.3331 - val_accuracy: 0.5092\n",
            "Epoch 1393/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2661 - accuracy: 0.9055 - val_loss: 3.3845 - val_accuracy: 0.4881\n",
            "Epoch 1394/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2559 - accuracy: 0.9055 - val_loss: 3.3610 - val_accuracy: 0.4908\n",
            "Epoch 1395/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2861 - accuracy: 0.8942 - val_loss: 3.5360 - val_accuracy: 0.4485\n",
            "Epoch 1396/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2803 - accuracy: 0.9078 - val_loss: 3.6720 - val_accuracy: 0.4802\n",
            "Epoch 1397/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3001 - accuracy: 0.8925 - val_loss: 3.3671 - val_accuracy: 0.5092\n",
            "Epoch 1398/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3275 - accuracy: 0.8773 - val_loss: 3.6493 - val_accuracy: 0.4617\n",
            "Epoch 1399/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3461 - accuracy: 0.8784 - val_loss: 3.8379 - val_accuracy: 0.4591\n",
            "Epoch 1400/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3313 - accuracy: 0.8835 - val_loss: 3.3403 - val_accuracy: 0.5092\n",
            "Epoch 1401/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2860 - accuracy: 0.8976 - val_loss: 3.4363 - val_accuracy: 0.4828\n",
            "Epoch 1402/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2555 - accuracy: 0.9129 - val_loss: 3.3945 - val_accuracy: 0.5092\n",
            "Epoch 1403/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4004 - accuracy: 0.8552 - val_loss: 3.2760 - val_accuracy: 0.4987\n",
            "Epoch 1404/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3032 - accuracy: 0.8976 - val_loss: 3.3972 - val_accuracy: 0.4987\n",
            "Epoch 1405/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2906 - accuracy: 0.8937 - val_loss: 3.5309 - val_accuracy: 0.4802\n",
            "Epoch 1406/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3504 - accuracy: 0.8790 - val_loss: 3.1856 - val_accuracy: 0.4987\n",
            "Epoch 1407/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2735 - accuracy: 0.9027 - val_loss: 3.4951 - val_accuracy: 0.4828\n",
            "Epoch 1408/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2867 - accuracy: 0.8988 - val_loss: 3.4258 - val_accuracy: 0.4855\n",
            "Epoch 1409/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3381 - accuracy: 0.8824 - val_loss: 3.6632 - val_accuracy: 0.4908\n",
            "Epoch 1410/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3501 - accuracy: 0.8874 - val_loss: 3.3778 - val_accuracy: 0.5066\n",
            "Epoch 1411/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2635 - accuracy: 0.9061 - val_loss: 3.3632 - val_accuracy: 0.5040\n",
            "Epoch 1412/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2782 - accuracy: 0.8999 - val_loss: 3.4483 - val_accuracy: 0.5172\n",
            "Epoch 1413/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2685 - accuracy: 0.9101 - val_loss: 3.3664 - val_accuracy: 0.4934\n",
            "Epoch 1414/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2883 - accuracy: 0.8954 - val_loss: 3.3378 - val_accuracy: 0.5013\n",
            "Epoch 1415/1500\n",
            "56/56 [==============================] - 3s 46ms/step - loss: 0.2751 - accuracy: 0.9027 - val_loss: 3.6228 - val_accuracy: 0.5145\n",
            "Epoch 1416/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2628 - accuracy: 0.9118 - val_loss: 3.5012 - val_accuracy: 0.4855\n",
            "Epoch 1417/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2564 - accuracy: 0.9067 - val_loss: 3.4001 - val_accuracy: 0.4855\n",
            "Epoch 1418/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2461 - accuracy: 0.9219 - val_loss: 3.4767 - val_accuracy: 0.5119\n",
            "Epoch 1419/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3354 - accuracy: 0.8818 - val_loss: 3.3524 - val_accuracy: 0.5066\n",
            "Epoch 1420/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3480 - accuracy: 0.8671 - val_loss: 3.6001 - val_accuracy: 0.4538\n",
            "Epoch 1421/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3586 - accuracy: 0.8676 - val_loss: 3.5970 - val_accuracy: 0.4538\n",
            "Epoch 1422/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2649 - accuracy: 0.9072 - val_loss: 3.3943 - val_accuracy: 0.4987\n",
            "Epoch 1423/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2247 - accuracy: 0.9265 - val_loss: 3.3722 - val_accuracy: 0.4908\n",
            "Epoch 1424/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2398 - accuracy: 0.9163 - val_loss: 3.4097 - val_accuracy: 0.4987\n",
            "Epoch 1425/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2662 - accuracy: 0.9152 - val_loss: 3.6018 - val_accuracy: 0.4934\n",
            "Epoch 1426/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3023 - accuracy: 0.8942 - val_loss: 3.3610 - val_accuracy: 0.4934\n",
            "Epoch 1427/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2613 - accuracy: 0.9106 - val_loss: 3.5271 - val_accuracy: 0.4802\n",
            "Epoch 1428/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2367 - accuracy: 0.9225 - val_loss: 3.4229 - val_accuracy: 0.4987\n",
            "Epoch 1429/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2456 - accuracy: 0.9197 - val_loss: 3.5722 - val_accuracy: 0.4776\n",
            "Epoch 1430/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3104 - accuracy: 0.8920 - val_loss: 3.5724 - val_accuracy: 0.5172\n",
            "Epoch 1431/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2869 - accuracy: 0.8976 - val_loss: 3.3958 - val_accuracy: 0.4934\n",
            "Epoch 1432/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3133 - accuracy: 0.8931 - val_loss: 3.8446 - val_accuracy: 0.4934\n",
            "Epoch 1433/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2650 - accuracy: 0.9106 - val_loss: 3.6051 - val_accuracy: 0.4828\n",
            "Epoch 1434/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2853 - accuracy: 0.8971 - val_loss: 3.6017 - val_accuracy: 0.4565\n",
            "Epoch 1435/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2967 - accuracy: 0.8880 - val_loss: 3.4913 - val_accuracy: 0.4934\n",
            "Epoch 1436/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2731 - accuracy: 0.9050 - val_loss: 3.3957 - val_accuracy: 0.4960\n",
            "Epoch 1437/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2975 - accuracy: 0.9005 - val_loss: 3.5551 - val_accuracy: 0.4591\n",
            "Epoch 1438/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2880 - accuracy: 0.9005 - val_loss: 3.6402 - val_accuracy: 0.4749\n",
            "Epoch 1439/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2479 - accuracy: 0.9163 - val_loss: 3.5347 - val_accuracy: 0.4802\n",
            "Epoch 1440/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2492 - accuracy: 0.9152 - val_loss: 3.5057 - val_accuracy: 0.5092\n",
            "Epoch 1441/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2293 - accuracy: 0.9208 - val_loss: 3.4036 - val_accuracy: 0.5198\n",
            "Epoch 1442/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2548 - accuracy: 0.9129 - val_loss: 3.5209 - val_accuracy: 0.4855\n",
            "Epoch 1443/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3210 - accuracy: 0.8829 - val_loss: 3.4350 - val_accuracy: 0.4749\n",
            "Epoch 1444/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3403 - accuracy: 0.8710 - val_loss: 4.0233 - val_accuracy: 0.4776\n",
            "Epoch 1445/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3105 - accuracy: 0.8954 - val_loss: 3.4739 - val_accuracy: 0.5092\n",
            "Epoch 1446/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2706 - accuracy: 0.9129 - val_loss: 3.4173 - val_accuracy: 0.4987\n",
            "Epoch 1447/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3182 - accuracy: 0.8863 - val_loss: 3.4954 - val_accuracy: 0.5145\n",
            "Epoch 1448/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2863 - accuracy: 0.8999 - val_loss: 3.5362 - val_accuracy: 0.4881\n",
            "Epoch 1449/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2900 - accuracy: 0.9033 - val_loss: 3.4902 - val_accuracy: 0.5119\n",
            "Epoch 1450/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2934 - accuracy: 0.9016 - val_loss: 3.7564 - val_accuracy: 0.4459\n",
            "Epoch 1451/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2569 - accuracy: 0.9061 - val_loss: 3.3817 - val_accuracy: 0.5119\n",
            "Epoch 1452/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2633 - accuracy: 0.9010 - val_loss: 3.5271 - val_accuracy: 0.4908\n",
            "Epoch 1453/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2906 - accuracy: 0.8993 - val_loss: 3.3258 - val_accuracy: 0.5409\n",
            "Epoch 1454/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2637 - accuracy: 0.9061 - val_loss: 3.4227 - val_accuracy: 0.5224\n",
            "Epoch 1455/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3122 - accuracy: 0.8891 - val_loss: 3.5509 - val_accuracy: 0.4855\n",
            "Epoch 1456/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2727 - accuracy: 0.9157 - val_loss: 3.5157 - val_accuracy: 0.4828\n",
            "Epoch 1457/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2351 - accuracy: 0.9231 - val_loss: 3.4043 - val_accuracy: 0.4934\n",
            "Epoch 1458/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2917 - accuracy: 0.8948 - val_loss: 3.5346 - val_accuracy: 0.4617\n",
            "Epoch 1459/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.4292 - accuracy: 0.8445 - val_loss: 3.4398 - val_accuracy: 0.5040\n",
            "Epoch 1460/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2634 - accuracy: 0.9146 - val_loss: 3.6117 - val_accuracy: 0.4855\n",
            "Epoch 1461/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2632 - accuracy: 0.9095 - val_loss: 3.4220 - val_accuracy: 0.5066\n",
            "Epoch 1462/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3258 - accuracy: 0.8801 - val_loss: 3.3602 - val_accuracy: 0.5040\n",
            "Epoch 1463/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2788 - accuracy: 0.9061 - val_loss: 3.4128 - val_accuracy: 0.5092\n",
            "Epoch 1464/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2502 - accuracy: 0.9146 - val_loss: 3.4700 - val_accuracy: 0.4987\n",
            "Epoch 1465/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2283 - accuracy: 0.9236 - val_loss: 3.4405 - val_accuracy: 0.4802\n",
            "Epoch 1466/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3105 - accuracy: 0.8790 - val_loss: 3.6953 - val_accuracy: 0.4644\n",
            "Epoch 1467/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.3086 - accuracy: 0.8880 - val_loss: 3.3321 - val_accuracy: 0.5172\n",
            "Epoch 1468/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2525 - accuracy: 0.9157 - val_loss: 3.4051 - val_accuracy: 0.5145\n",
            "Epoch 1469/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3128 - accuracy: 0.8829 - val_loss: 3.4594 - val_accuracy: 0.5040\n",
            "Epoch 1470/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3221 - accuracy: 0.8903 - val_loss: 3.3988 - val_accuracy: 0.4828\n",
            "Epoch 1471/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2617 - accuracy: 0.9129 - val_loss: 3.5165 - val_accuracy: 0.4881\n",
            "Epoch 1472/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2770 - accuracy: 0.8954 - val_loss: 3.6307 - val_accuracy: 0.4855\n",
            "Epoch 1473/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2467 - accuracy: 0.9101 - val_loss: 3.6799 - val_accuracy: 0.4644\n",
            "Epoch 1474/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3163 - accuracy: 0.8886 - val_loss: 3.5580 - val_accuracy: 0.4802\n",
            "Epoch 1475/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2735 - accuracy: 0.9005 - val_loss: 3.3624 - val_accuracy: 0.5092\n",
            "Epoch 1476/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3174 - accuracy: 0.8846 - val_loss: 3.4143 - val_accuracy: 0.4934\n",
            "Epoch 1477/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2440 - accuracy: 0.9118 - val_loss: 3.4481 - val_accuracy: 0.4908\n",
            "Epoch 1478/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3301 - accuracy: 0.8824 - val_loss: 3.5606 - val_accuracy: 0.4987\n",
            "Epoch 1479/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2841 - accuracy: 0.9055 - val_loss: 3.3720 - val_accuracy: 0.5119\n",
            "Epoch 1480/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2331 - accuracy: 0.9191 - val_loss: 3.3726 - val_accuracy: 0.5040\n",
            "Epoch 1481/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3046 - accuracy: 0.8925 - val_loss: 3.6516 - val_accuracy: 0.4697\n",
            "Epoch 1482/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3171 - accuracy: 0.8863 - val_loss: 3.4680 - val_accuracy: 0.4881\n",
            "Epoch 1483/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2612 - accuracy: 0.9078 - val_loss: 3.5224 - val_accuracy: 0.5066\n",
            "Epoch 1484/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3151 - accuracy: 0.8869 - val_loss: 3.6503 - val_accuracy: 0.4512\n",
            "Epoch 1485/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3033 - accuracy: 0.8942 - val_loss: 3.4101 - val_accuracy: 0.5040\n",
            "Epoch 1486/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2485 - accuracy: 0.9135 - val_loss: 3.4388 - val_accuracy: 0.5040\n",
            "Epoch 1487/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2305 - accuracy: 0.9180 - val_loss: 3.4199 - val_accuracy: 0.5013\n",
            "Epoch 1488/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2761 - accuracy: 0.9089 - val_loss: 3.4321 - val_accuracy: 0.4987\n",
            "Epoch 1489/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2566 - accuracy: 0.9123 - val_loss: 3.5452 - val_accuracy: 0.4987\n",
            "Epoch 1490/1500\n",
            "56/56 [==============================] - 2s 45ms/step - loss: 0.2239 - accuracy: 0.9208 - val_loss: 3.6496 - val_accuracy: 0.4749\n",
            "Epoch 1491/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2781 - accuracy: 0.9005 - val_loss: 3.3946 - val_accuracy: 0.5013\n",
            "Epoch 1492/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2760 - accuracy: 0.8971 - val_loss: 3.7117 - val_accuracy: 0.4802\n",
            "Epoch 1493/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2853 - accuracy: 0.8993 - val_loss: 3.5011 - val_accuracy: 0.4749\n",
            "Epoch 1494/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2780 - accuracy: 0.8988 - val_loss: 3.4799 - val_accuracy: 0.4960\n",
            "Epoch 1495/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.3174 - accuracy: 0.8852 - val_loss: 3.4441 - val_accuracy: 0.4934\n",
            "Epoch 1496/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2813 - accuracy: 0.9016 - val_loss: 3.4409 - val_accuracy: 0.4855\n",
            "Epoch 1497/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2462 - accuracy: 0.9152 - val_loss: 3.5571 - val_accuracy: 0.4855\n",
            "Epoch 1498/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2965 - accuracy: 0.8965 - val_loss: 3.7547 - val_accuracy: 0.4776\n",
            "Epoch 1499/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2529 - accuracy: 0.9135 - val_loss: 3.4955 - val_accuracy: 0.4881\n",
            "Epoch 1500/1500\n",
            "56/56 [==============================] - 3s 45ms/step - loss: 0.2420 - accuracy: 0.9191 - val_loss: 3.5460 - val_accuracy: 0.4723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "GvH3tikUYd6O",
        "outputId": "0d14b5cc-f6d3-4efe-92e2-5f25cd18c94d"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1500)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmnyp03e8EAW",
        "outputId": "fc552872-410d-4248-f7aa-f2a281dd7f1c"
      },
      "source": [
        "test_scores = net.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 - 0s - loss: 3.5814 - accuracy: 0.5053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzoZNJpB8deq",
        "outputId": "57e14e4d-35c9-4ad6-ed0d-41a85ff4bf44"
      },
      "source": [
        "print(\"Test loss:\", str(test_scores[0]))\n",
        "print(\"Test accuracy:\", str(test_scores[1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 3.58144474029541\n",
            "Test accuracy: 0.5052631497383118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDBT_81f80UM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}